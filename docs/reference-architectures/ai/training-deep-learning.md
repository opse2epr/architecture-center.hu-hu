---
title: Elosztott-betanítás deep learning-modellek az Azure-ban
description: Ez a referenciaarchitektúra bemutatja, hogyan elosztott-betanítás deep learning-modellek között GPU-kompatibilis virtuális gépek fürtjeinek elvégzésére az Azure Batch AI használatával.
author: njray
ms.date: 01/14/19
ms.custom: azcat-ai
ms.openlocfilehash: 800defeb851f5a31dc730038c3699e1a3d54b923
ms.sourcegitcommit: d5ea427c25f9f7799cc859b99f328739ca2d8c1c
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 01/15/2019
ms.locfileid: "54307837"
---
# <a name="distributed-training-of-deep-learning-models-on-azure"></a><span data-ttu-id="30299-103">Elosztott-betanítás deep learning-modellek az Azure-ban</span><span class="sxs-lookup"><span data-stu-id="30299-103">Distributed training of deep learning models on Azure</span></span>

<span data-ttu-id="30299-104">Ez a referenciaarchitektúra bemutatja, hogyan végezhet elosztott-betanítás deep learning-modellek között GPU-kompatibilis virtuális gépek fürtjeinek.</span><span class="sxs-lookup"><span data-stu-id="30299-104">This reference architecture shows how to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span> <span data-ttu-id="30299-105">A forgatókönyv képbesorolás, de a megoldás is általánosítható más deep learning-forgatókönyvek például a képszegmentáláshoz és objektumfelismeréshez.</span><span class="sxs-lookup"><span data-stu-id="30299-105">The scenario is image classification, but the solution can be generalized for other deep learning scenarios such as segmentation and object detection.</span></span>

<span data-ttu-id="30299-106">Az architektúra egy referenciaimplementációt érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="30299-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Mély tanulás elosztott architektúra][0]

<span data-ttu-id="30299-108">**A forgatókönyv**: Képek besorolása olyan széles körben alkalmazott módszer a számítógépes látástechnológiai, konvolúciós Neurális hálózat (CNN) képzési által gyakran megoldásra.</span><span class="sxs-lookup"><span data-stu-id="30299-108">**Scenario**: Image classification is a widely applied technique in computer vision, often tackled by training a convolutional neural network (CNN).</span></span> <span data-ttu-id="30299-109">Nagy adatkészletekkel különösen nagyméretű modellek esetében a betanítási folyamat eltarthat hetek vagy hónapok egyetlen gpu-alapú.</span><span class="sxs-lookup"><span data-stu-id="30299-109">For particularly large models with large datasets, the training process can take weeks or months on a single GPU.</span></span> <span data-ttu-id="30299-110">Bizonyos esetekben a modellek rendkívül nagy méretűek, hogy azt ne legyen lehetséges, hogy ésszerű köteg méretek a GPU-kiszolgálóra is.</span><span class="sxs-lookup"><span data-stu-id="30299-110">In some situations, the models are so large that it's not possible to fit reasonable batch sizes onto the GPU.</span></span> <span data-ttu-id="30299-111">Ezekben a helyzetekben elosztott képzési használatával lerövidítheti a képzési időt.</span><span class="sxs-lookup"><span data-stu-id="30299-111">Using distributed training in these situations can shorten the training time.</span></span>

<span data-ttu-id="30299-112">Ez az adott esetben egy [ResNet50 CNN modell] [ resnet] tanítása az [Horovod] [ horovod] a a [épít adatkészlet] [ imagenet] és a szintetikus adatok.</span><span class="sxs-lookup"><span data-stu-id="30299-112">In this specific scenario, a [ResNet50 CNN model][resnet] is trained using [Horovod][horovod] on the [Imagenet dataset][imagenet] and on synthetic data.</span></span> <span data-ttu-id="30299-113">A referenciaimplementáció ennek a feladatnak három a népszerű deep learning-keretrendszerek használatával mutatja be: Tensorflow-hoz, Keras és PyTorch.</span><span class="sxs-lookup"><span data-stu-id="30299-113">The reference implementation shows how to accomplish this task using three of the most popular deep learning frameworks: TensorFlow, Keras, and PyTorch.</span></span>

<span data-ttu-id="30299-114">Többféleképpen is egy elosztott módon, beleértve az adat- és modell megközelítések szinkron vagy aszinkron frissítések alapján deep learning-modell betanításához.</span><span class="sxs-lookup"><span data-stu-id="30299-114">There are several ways to train a deep learning model in a distributed fashion, including data-parallel and model-parallel approaches based on synchronous or asynchronous updates.</span></span> <span data-ttu-id="30299-115">A leggyakoribb eset jelenleg az adatok párhuzamos szinkron frissítésekkel.</span><span class="sxs-lookup"><span data-stu-id="30299-115">Currently the most common scenario is data parallel with synchronous updates.</span></span> <span data-ttu-id="30299-116">Ezt a módszert a legegyszerűbb megvalósításához, és használja a legtöbb esetben elegendő.</span><span class="sxs-lookup"><span data-stu-id="30299-116">This approach is the easiest to implement and is sufficient for most use cases.</span></span>

<span data-ttu-id="30299-117">Adat-párhuzamos elosztott szinkron frissítésekkel képzés, a modell replikál a rendszer *n* hardvereszközök.</span><span class="sxs-lookup"><span data-stu-id="30299-117">In data-parallel distributed training with synchronous updates, the model is replicated across *n* hardware devices.</span></span> <span data-ttu-id="30299-118">Egy mini batch képzési minták oszlik *n* micro-kötegek.</span><span class="sxs-lookup"><span data-stu-id="30299-118">A mini-batch of training samples is divided into *n* micro-batches.</span></span> <span data-ttu-id="30299-119">Minden egyes eszköz az előre és visszafelé irányuló pass micro – batch hajt végre.</span><span class="sxs-lookup"><span data-stu-id="30299-119">Each device performs the forward and backward passes for a micro-batch.</span></span> <span data-ttu-id="30299-120">Amikor az eszköz befejezi a folyamatot, és a más eszközök közös a frissítéseket.</span><span class="sxs-lookup"><span data-stu-id="30299-120">When a device finishes the process, it shares the updates with the other devices.</span></span> <span data-ttu-id="30299-121">Ezekkel az értékekkel a teljes mini köteg frissített súlyozású kiszámításához, és a modellek között szinkronizált végpontkészletben.</span><span class="sxs-lookup"><span data-stu-id="30299-121">These values are used to calculate the updated weights of the entire mini-batch, and the weights are synchronized across the models.</span></span> <span data-ttu-id="30299-122">Ebben a forgatókönyvben tárgyalja a [GitHub] [ github] tárház.</span><span class="sxs-lookup"><span data-stu-id="30299-122">This scenario is covered in the [GitHub][github] repository.</span></span>

![Adatok párhuzamos, elosztott betanítás][1]

<span data-ttu-id="30299-124">Ez az architektúra a modell-párhuzamos és aszinkron frissítések is használható.</span><span class="sxs-lookup"><span data-stu-id="30299-124">This architecture can also be used for model-parallel and asynchronous updates.</span></span> <span data-ttu-id="30299-125">Modell-párhuzamos elosztott képzés, a modell között oszlik *n* hardvereszközök, minden eszközön, a modell egy részének tárolására.</span><span class="sxs-lookup"><span data-stu-id="30299-125">In model-parallel distributed training, the model is divided across *n* hardware devices, with each device holding a part of the model.</span></span> <span data-ttu-id="30299-126">A legegyszerűbb megvalósítás minden egyes eszköz rendelkezhet egy réteget, a hálózat, és információkat eszköz alatt az előre és visszafelé között átadott pass.</span><span class="sxs-lookup"><span data-stu-id="30299-126">In the simplest implementation, each device may hold a layer of the network, and information is passed between devices during the forward and backwards pass.</span></span> <span data-ttu-id="30299-127">Ezzel a módszerrel nagyobb Neurális hálózatokat is betanított, de cserébe teljesítmény, mivel eszközök folyamatosan várnak egymással végrehajtásához vagy az előre, vagy visszamenőleges adja át.</span><span class="sxs-lookup"><span data-stu-id="30299-127">Larger neural networks can be trained this way, but at the cost of performance, since devices are constantly waiting for each other to complete either the forward or backwards pass.</span></span> <span data-ttu-id="30299-128">Próbálja meg részben szintetikus átmenetekhez használatával a probléma enyhítése néhány speciális módszerekig.</span><span class="sxs-lookup"><span data-stu-id="30299-128">Some advanced techniques try to partially alleviate this issue by using synthetic gradients.</span></span>

<span data-ttu-id="30299-129">A képzési lépések a következők:</span><span class="sxs-lookup"><span data-stu-id="30299-129">The steps for training are:</span></span>

1. <span data-ttu-id="30299-130">Hozzon létre a parancsprogramokat, amelyek fog futtatunk a fürtön a modell betanítását, majd átviszi a file storage.</span><span class="sxs-lookup"><span data-stu-id="30299-130">Create scripts that will run on the cluster and train your model, then transfer them to file storage.</span></span>

1. <span data-ttu-id="30299-131">A Blob Storage szeretne adatokat írni.</span><span class="sxs-lookup"><span data-stu-id="30299-131">Write the data to Blob Storage.</span></span>

1. <span data-ttu-id="30299-132">Hozzon létre egy Batch AI-fájlkiszolgáló, és töltse le az adatokat Blob Storage-ból rá.</span><span class="sxs-lookup"><span data-stu-id="30299-132">Create a Batch AI file server and download the data from Blob Storage onto it.</span></span>

1. <span data-ttu-id="30299-133">Hozzon létre minden egyes deep learning keretrendszer Docker-tárolót, és helyezze át a tároló-beállításjegyzék (Docker Hub).</span><span class="sxs-lookup"><span data-stu-id="30299-133">Create the Docker containers for each deep learning framework and transfer them to a container registry (Docker Hub).</span></span>

1. <span data-ttu-id="30299-134">Hozzon létre egy Batch AI-készlet, amely a Batch AI-fájlkiszolgáló is csatlakoztatja.</span><span class="sxs-lookup"><span data-stu-id="30299-134">Create a Batch AI pool that also mounts the Batch AI file server.</span></span>

1. <span data-ttu-id="30299-135">Feladatok elküldéséhez.</span><span class="sxs-lookup"><span data-stu-id="30299-135">Submit jobs.</span></span> <span data-ttu-id="30299-136">Minden egyes kér le a megfelelő Docker-rendszerképet és szkriptekben.</span><span class="sxs-lookup"><span data-stu-id="30299-136">Each pulls in the appropriate Docker image and scripts.</span></span>

1. <span data-ttu-id="30299-137">Ha a feladat befejeződött, az összes eredmény írni fájlok tárolására.</span><span class="sxs-lookup"><span data-stu-id="30299-137">Once the job is completed, write all the results to Files storage.</span></span>

## <a name="architecture"></a><span data-ttu-id="30299-138">Architektúra</span><span class="sxs-lookup"><span data-stu-id="30299-138">Architecture</span></span>

<span data-ttu-id="30299-139">Az architektúra az alábbi összetevőkből áll.</span><span class="sxs-lookup"><span data-stu-id="30299-139">This architecture consists of the following components.</span></span>

<span data-ttu-id="30299-140">**[Az Azure Batch AI] [ batch-ai]**  ebben az architektúrában a központi szerepet játszik az erőforrások skálázása felfelé és lefelé megfelelően szükség szerint.</span><span class="sxs-lookup"><span data-stu-id="30299-140">**[Azure Batch AI][batch-ai]** plays the central role in this architecture by scaling resources up and down according to need.</span></span> <span data-ttu-id="30299-141">A Batch AI egy szolgáltatása, amely segít üzembe helyezése és kezelése virtuális gépek fürtjeinek, feladatok ütemezése, gyűjtse össze az eredményeket, méretezni az erőforrásokat, hibáinak a kezelése és létrehozása a megfelelő tárolási.</span><span class="sxs-lookup"><span data-stu-id="30299-141">Batch AI is a service that helps provision and manage clusters of VMs, schedule jobs, gather results, scale resources, handle failures, and create appropriate storage.</span></span> <span data-ttu-id="30299-142">Deep learning számítási feladatokhoz GPU-kompatibilis virtuális gépeket támogatja.</span><span class="sxs-lookup"><span data-stu-id="30299-142">It supports GPU-enabled VMs for deep learning workloads.</span></span> <span data-ttu-id="30299-143">A Python SDK-t és a egy parancssori felület (CLI) a Batch AI érhető el.</span><span class="sxs-lookup"><span data-stu-id="30299-143">A Python SDK and a command-line interface (CLI) are available for Batch AI.</span></span>

> [!NOTE]
> <span data-ttu-id="30299-144">Kivonás alatt áll az Azure Batch AI szolgáltatás márciusi 2019, és az ipari méretekben képzés és pontozás képességek érhetők el mostantól [Azure Machine Learning szolgáltatás][amls].</span><span class="sxs-lookup"><span data-stu-id="30299-144">The Azure Batch AI service is retiring March 2019, and its at-scale training and scoring capabilities are now available in [Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="30299-145">Ez a referenciaarchitektúra hamarosan frissül majd használni a Machine Learning, így az úgynevezett felügyelt számítási célt [Azure Machine Learning Compute] [ aml-compute] képzés, üzembe helyezése és pontozás a machine tanulási modelleket.</span><span class="sxs-lookup"><span data-stu-id="30299-145">This reference architecture will be updated soon to use Machine Learning, which offers a managed compute target called [Azure Machine Learning Compute][aml-compute] for training, deploying, and scoring machine learning models.</span></span>

<span data-ttu-id="30299-146">**[A BLOB storage-] [ azure-blob]**  szolgál az adatok előkészítéséhez.</span><span class="sxs-lookup"><span data-stu-id="30299-146">**[Blob storage][azure-blob]** is used to stage the data.</span></span> <span data-ttu-id="30299-147">Ezek az adatok betanítás során letölti a Batch AI-fájlkiszolgáló.</span><span class="sxs-lookup"><span data-stu-id="30299-147">This data is downloaded to a Batch AI file server during training.</span></span>

<span data-ttu-id="30299-148">**[Az Azure Files] [ files]**  a parancsfájlok, naplókat és az oktatás, a végső eredmények tárolására szolgál.</span><span class="sxs-lookup"><span data-stu-id="30299-148">**[Azure Files][files]** is used to store the scripts, logs, and the final results from the training.</span></span> <span data-ttu-id="30299-149">File storage esetén működik hatékonyan tárolására naplózza és parancsfájlok, de nem legjobb teljesítménnyel működhessen, Blob Storage-ban, így nem használható a data-igényes feladatokhoz.</span><span class="sxs-lookup"><span data-stu-id="30299-149">File storage works well for storing logs and scripts, but is not as performant as Blob Storage, so it shouldn't be used for data-intensive tasks.</span></span>

<span data-ttu-id="30299-150">**[Batch AI-fájlkiszolgáló] [ batch-ai-files]**  egy egycsomópontos NFS-megosztás ebben az architektúrában a betanítási adatok tárolására használt.</span><span class="sxs-lookup"><span data-stu-id="30299-150">**[Batch AI file server][batch-ai-files]** is a single-node NFS share used in this architecture to store the training data.</span></span> <span data-ttu-id="30299-151">A Batch AI az NFS-megosztások hoz létre, és csatlakoztatja, a fürtön.</span><span class="sxs-lookup"><span data-stu-id="30299-151">Batch AI creates an NFS share and mounts it on the cluster.</span></span> <span data-ttu-id="30299-152">Batch AI-fájlkiszolgálók ajánljuk a Előkészíthetők az adatok a fürthöz a szükséges átviteli sebességgel.</span><span class="sxs-lookup"><span data-stu-id="30299-152">Batch AI file servers are the recommended way to serve data to the cluster with the necessary throughput.</span></span>

<span data-ttu-id="30299-153">**[A docker Hub] [ docker]**  a Docker-rendszerképet, amelyet a Batch AI használ a betanítási Futtatás tárolására szolgál.</span><span class="sxs-lookup"><span data-stu-id="30299-153">**[Docker Hub][docker]** is used to store the Docker image that Batch AI uses to run the training.</span></span> <span data-ttu-id="30299-154">A docker Hub az architektúra lett választva, mert egyszerűen használható, és az alapértelmezett lemezkép adattár a Docker-felhasználók.</span><span class="sxs-lookup"><span data-stu-id="30299-154">Docker Hub was chosen for this architecture because it's easy to use and is the default image repository for Docker users.</span></span> <span data-ttu-id="30299-155">[Az Azure Container Registry] [ acr] is használható.</span><span class="sxs-lookup"><span data-stu-id="30299-155">[Azure Container Registry][acr] can also be used.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="30299-156">A teljesítménnyel kapcsolatos megfontolások</span><span class="sxs-lookup"><span data-stu-id="30299-156">Performance considerations</span></span>

<span data-ttu-id="30299-157">Az Azure biztosít a négy [GPU-kompatibilis virtuális gépek típusai] [ gpu] megfelelő deep learning-modellek betanításához.</span><span class="sxs-lookup"><span data-stu-id="30299-157">Azure provides four [GPU-enabled VM types][gpu] suitable for training deep learning models.</span></span> <span data-ttu-id="30299-158">Ezek tartománya az ár, és gyorsabb alacsony, magas a következő:</span><span class="sxs-lookup"><span data-stu-id="30299-158">They range in price and speed from low to high as follows:</span></span>

| <span data-ttu-id="30299-159">**Az Azure Virtuálisgép-sorozatok**</span><span class="sxs-lookup"><span data-stu-id="30299-159">**Azure VM series**</span></span> | <span data-ttu-id="30299-160">**NVIDIA GPU**</span><span class="sxs-lookup"><span data-stu-id="30299-160">**NVIDIA GPU**</span></span> |
|---------------------|----------------|
| <span data-ttu-id="30299-161">NC</span><span class="sxs-lookup"><span data-stu-id="30299-161">NC</span></span>                  | <span data-ttu-id="30299-162">K80</span><span class="sxs-lookup"><span data-stu-id="30299-162">K80</span></span>            |
| <span data-ttu-id="30299-163">ND</span><span class="sxs-lookup"><span data-stu-id="30299-163">ND</span></span>                  | <span data-ttu-id="30299-164">P40</span><span class="sxs-lookup"><span data-stu-id="30299-164">P40</span></span>            |
| <span data-ttu-id="30299-165">NCv2</span><span class="sxs-lookup"><span data-stu-id="30299-165">NCv2</span></span>                | <span data-ttu-id="30299-166">P100</span><span class="sxs-lookup"><span data-stu-id="30299-166">P100</span></span>           |
| <span data-ttu-id="30299-167">NCv3</span><span class="sxs-lookup"><span data-stu-id="30299-167">NCv3</span></span>                | <span data-ttu-id="30299-168">V100</span><span class="sxs-lookup"><span data-stu-id="30299-168">V100</span></span>           |

<span data-ttu-id="30299-169">Azt javasoljuk, hogy a tanítási horizontális felskálázása előtt vertikális felskálázása. Például próbálja meg egyetlen V100 K80s fürtben kísérlet előtt.</span><span class="sxs-lookup"><span data-stu-id="30299-169">We recommended scaling up your training before scaling out. For example, try a single V100 before trying a cluster of K80s.</span></span>

<span data-ttu-id="30299-170">A következő diagram bemutatja a teljesítménybeli különbséget különböző GPU-típusok alapján [teljesítménytesztek eredménye] [ benchmark] tensorflow-hoz és Horovod használata a Batch AI végzett.</span><span class="sxs-lookup"><span data-stu-id="30299-170">The following graph shows the performance differences for different GPU types based on [benchmarking tests][benchmark] carried out using TensorFlow and Horovod on Batch AI.</span></span> <span data-ttu-id="30299-171">A grafikonon látható átviteli 32 GPU-fürtök különböző modellek különböző GPU-és MPI-verziók között.</span><span class="sxs-lookup"><span data-stu-id="30299-171">The graph shows throughput of 32 GPU clusters across various models, on different GPU types and MPI versions.</span></span> <span data-ttu-id="30299-172">Modellek TensorFlow 1.9 lettek megvalósítva</span><span class="sxs-lookup"><span data-stu-id="30299-172">Models were implemented in TensorFlow 1.9</span></span>

![A GPU-fürtökön TensorFlow-modellek átvitelisebesség-eredmény][2]

<span data-ttu-id="30299-174">Az előző táblázatban szereplő minden egyes Virtuálisgép-sorozatok, InfiniBand használatával egy konfigurációt tartalmaz.</span><span class="sxs-lookup"><span data-stu-id="30299-174">Each VM series shown in the previous table includes a configuration with InfiniBand.</span></span> <span data-ttu-id="30299-175">Az InfiniBand-konfigurációk használata elosztott futtatásakor képzésekről, a gyorsabb kommunikáció a csomópontok között.</span><span class="sxs-lookup"><span data-stu-id="30299-175">Use the InfiniBand configurations when you run distributed training, for faster communication between nodes.</span></span> <span data-ttu-id="30299-176">InfiniBand is növeli a méretezési hatékonyságát az oktatás, amelyek kihasználhatják a azt a keretrendszereket.</span><span class="sxs-lookup"><span data-stu-id="30299-176">InfiniBand also increases the scaling efficiency of the training for the frameworks that can take advantage of it.</span></span> <span data-ttu-id="30299-177">További információkért lásd: az Infiniband [összehasonlító becslésére][benchmark].</span><span class="sxs-lookup"><span data-stu-id="30299-177">For details, see the Infiniband [benchmark comparison][benchmark].</span></span>

<span data-ttu-id="30299-178">Bár a Batch AI a Blob storage használatával csatlakoztathatja a [blobfuse] [ blobfuse] adapter, nem javasoljuk a Blob Storage ezzel a módszerrel elosztott képzéshez, mert a teljesítmény nem elég jó kezeléséhez a szükséges átviteli sebességet.</span><span class="sxs-lookup"><span data-stu-id="30299-178">Although Batch AI can mount Blob storage using the [blobfuse][blobfuse] adapter, we don't recommend using Blob Storage this way for distributed training, because the performance isn't good enough to handle the necessary throughput.</span></span> <span data-ttu-id="30299-179">Helyezze át az adatokat egy Batch AI-fájlkiszolgáló helyette, ahogyan az az architektúra diagramját.</span><span class="sxs-lookup"><span data-stu-id="30299-179">Move the data to a Batch AI file server instead, as shown in the architecture diagram.</span></span>

## <a name="scalability-considerations"></a><span data-ttu-id="30299-180">Méretezési szempontok</span><span class="sxs-lookup"><span data-stu-id="30299-180">Scalability considerations</span></span>

<span data-ttu-id="30299-181">Az elosztott képzési méretezési hatékonyságát mindig kevesebb, mint 100 %-os hálózati terhelés miatt &mdash; szinkronizálása eszközök között a teljes modell szűk keresztmetszetté válik.</span><span class="sxs-lookup"><span data-stu-id="30299-181">The scaling efficiency of distributed training is always less than 100 percent due to network overhead &mdash; syncing the entire model between devices becomes a bottleneck.</span></span> <span data-ttu-id="30299-182">Elosztott képzési ezért legjobban megfelel nagy modellek, amelyek nem egy ésszerű kötegmérettel egyetlen gpu-alapú kell képezni, illetve egy egyszerű, párhuzamos módon osztja meg a modell nem javított problémák.</span><span class="sxs-lookup"><span data-stu-id="30299-182">Therefore, distributed training is most suited for large models that cannot be trained using a reasonable batch size on a single GPU, or for problems that cannot be addressed by distributing the model in a simple, parallel way.</span></span>

<span data-ttu-id="30299-183">Elosztott képzési hiperparaméter keresések futtatása nem ajánlott.</span><span class="sxs-lookup"><span data-stu-id="30299-183">Distributed training is not recommended for running hyperparameter searches.</span></span> <span data-ttu-id="30299-184">A méretezési hatékonyságát befolyásolja a teljesítményt, és elosztott kevésbé hatékony, mint a több modell konfiguráció külön-külön képzési teszi.</span><span class="sxs-lookup"><span data-stu-id="30299-184">The scaling efficiency affects performance and makes a distributed approach less efficient than training multiple model configurations separately.</span></span>

<span data-ttu-id="30299-185">Egy méretezési hatékonyság növelése módja a köteg méretének növeléséhez.</span><span class="sxs-lookup"><span data-stu-id="30299-185">One way to increase scaling efficiency is to increase the batch size.</span></span> <span data-ttu-id="30299-186">Amely kell elvégezni, óvatosan, azonban, mert a köteg méretének növelése nélkül a többi paraméter módosításával összeállítása hátrányosan befolyásolhatja a modell végső teljesítményét.</span><span class="sxs-lookup"><span data-stu-id="30299-186">That must be done carefully, however, because increasing the batch size without adjusting the other parameters can hurt the model's final performance.</span></span>

## <a name="storage-considerations"></a><span data-ttu-id="30299-187">A tárterülettel kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="30299-187">Storage considerations</span></span>

<span data-ttu-id="30299-188">Deep learning-modellek betanításakor gyakran kihagyott felmérésére, az adatok tárolására.</span><span class="sxs-lookup"><span data-stu-id="30299-188">When training deep learning models, an often-overlooked aspect is where the data is stored.</span></span> <span data-ttu-id="30299-189">Ha a tároló a GPU-k igényeinek kielégítésére túl lassú, a képzési teljesítmény csökken.</span><span class="sxs-lookup"><span data-stu-id="30299-189">If the storage is too slow to keep up with the demands of the GPUs, training performance can degrade.</span></span>

<span data-ttu-id="30299-190">A Batch AI számos tárolási megoldásokat támogatja.</span><span class="sxs-lookup"><span data-stu-id="30299-190">Batch AI supports many storage solutions.</span></span> <span data-ttu-id="30299-191">Ez az architektúra egy Batch AI-fájlkiszolgáló használja, mert biztosítja a legjobb egyensúlyt a könnyű használat és a teljesítmény között.</span><span class="sxs-lookup"><span data-stu-id="30299-191">This architecture uses a Batch AI file server, because it provides the best tradeoff between ease of use and performance.</span></span> <span data-ttu-id="30299-192">A legjobb teljesítmény érdekében az adatok helyi betölteni.</span><span class="sxs-lookup"><span data-stu-id="30299-192">For best performance, load the data locally.</span></span> <span data-ttu-id="30299-193">Azonban ez nehézkes lehet, mert minden csomópont le kell töltenie az adatok Blob Storage-ból, és az épít adatkészlettel, ez órát is igénybe vehet.</span><span class="sxs-lookup"><span data-stu-id="30299-193">However, this can be cumbersome, because all the nodes must download the data from Blob Storage, and with the ImageNet dataset, this can take hours.</span></span> <span data-ttu-id="30299-194">[Prémium szintű Azure Blob Storage] [ blob] (korlátozott nyilvános előzetes verzió) egy másik megfontolandó jó lehetőség.</span><span class="sxs-lookup"><span data-stu-id="30299-194">[Azure Premium Blob Storage][blob] (limited public preview) is another good option to consider.</span></span>

<span data-ttu-id="30299-195">Csatlakoztatható, Blobok és fájlok tárolási adattárak, az elosztott képzési.</span><span class="sxs-lookup"><span data-stu-id="30299-195">Do not mount Blob and File storage as data stores for distributed training.</span></span> <span data-ttu-id="30299-196">Túl lassú, és akadályozzák a betanítási teljesítményét.</span><span class="sxs-lookup"><span data-stu-id="30299-196">They are too slow and will hinder training performance.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="30299-197">Biztonsági szempontok</span><span class="sxs-lookup"><span data-stu-id="30299-197">Security considerations</span></span>

### <a name="restrict-access-to-azure-blob-storage"></a><span data-ttu-id="30299-198">Az Azure Blob Storage-hozzáférés korlátozása</span><span class="sxs-lookup"><span data-stu-id="30299-198">Restrict access to Azure Blob Storage</span></span>

<span data-ttu-id="30299-199">Ez az architektúra használ [tárfiókkulcsok] [ security-guide] a blobtároló eléréséhez.</span><span class="sxs-lookup"><span data-stu-id="30299-199">This architecture uses [storage account keys][security-guide] to access the Blob storage.</span></span> <span data-ttu-id="30299-200">További ellenőrzésére és védelmére fontolja meg egy közös hozzáférésű jogosultságkód (SAS) helyett.</span><span class="sxs-lookup"><span data-stu-id="30299-200">For further control and protection, consider using a shared access signature (SAS) instead.</span></span> <span data-ttu-id="30299-201">Ez a tároló objektumok korlátozott hozzáférést biztosít anélkül, hogy rögzítse szoftveresen a fiókkulcsok, vagy mentse őket az egyszerű szöveges.</span><span class="sxs-lookup"><span data-stu-id="30299-201">This grants limited access to objects in storage, without needing to hard-code the account keys or save them in plaintext.</span></span> <span data-ttu-id="30299-202">SAS használatával is biztosítható, hogy a tárfiók rendelkezik a megfelelő irányítás, és, hogy célja, hogy hozzáférhessenek a mobileszközeiken csak a személyeknek.</span><span class="sxs-lookup"><span data-stu-id="30299-202">Using a SAS also helps to ensure that the storage account has proper governance, and that access is granted only to the people intended to have it.</span></span>

<span data-ttu-id="30299-203">Forgatókönyvek a több bizalmas adatok győződjön meg arról, hogy a kulcsok összes védettek, mivel ezek a kulcsok teljes hozzáférési jogot az összes bemeneti és kimeneti adatok a munkaterhelési.</span><span class="sxs-lookup"><span data-stu-id="30299-203">For scenarios with more sensitive data, make sure that all of your storage keys are protected, because these keys grant full access to all input and output data from the workload.</span></span>

### <a name="encrypt-data-at-rest-and-in-motion"></a><span data-ttu-id="30299-204">Inaktív és a mozgásban lévő adatok titkosításához</span><span class="sxs-lookup"><span data-stu-id="30299-204">Encrypt data at rest and in motion</span></span>

<span data-ttu-id="30299-205">Olyan esetekben, olyan bizalmas adatokat, az inaktív adatok titkosítása &mdash; storage-ban, hogy az adatokat.</span><span class="sxs-lookup"><span data-stu-id="30299-205">In scenarios that use sensitive data, encrypt the data at rest &mdash; that is, the data in storage.</span></span> <span data-ttu-id="30299-206">SSL használatával minden egyes idő adatok helyeződnek át egyik helyről a másikra, az adatátvitel biztonságos.</span><span class="sxs-lookup"><span data-stu-id="30299-206">Each time data moves from one location to the next, use SSL to secure the data transfer.</span></span> <span data-ttu-id="30299-207">További információkért lásd: a [Azure Storage biztonsági útmutatóját][security-guide].</span><span class="sxs-lookup"><span data-stu-id="30299-207">For more information, see the [Azure Storage security guide][security-guide].</span></span>

### <a name="secure-data-in-a-virtual-network"></a><span data-ttu-id="30299-208">Biztonságos adattárolás a virtuális hálózat</span><span class="sxs-lookup"><span data-stu-id="30299-208">Secure data in a virtual network</span></span>

<span data-ttu-id="30299-209">Éles környezetekben üzemelő példányok fontolja meg a megadott virtuális hálózat egy alhálózatában Batch AI-fürt üzembe helyezésekor.</span><span class="sxs-lookup"><span data-stu-id="30299-209">For production deployments, consider deploying the Batch AI cluster into a subnet of a virtual network that you specify.</span></span> <span data-ttu-id="30299-210">Ez lehetővé teszi a számítási csomópontok, a fürt más virtuális gépekkel vagy egy helyszíni hálózattal biztonságosan kommunikál.</span><span class="sxs-lookup"><span data-stu-id="30299-210">This allows the compute nodes in the cluster to communicate securely with other virtual machines or with an on-premises network.</span></span> <span data-ttu-id="30299-211">Is [szolgáltatásvégpontokat] [ endpoints] hozzáférést biztosít egy virtuális hálózatból, vagy a virtuális hálózaton belül egy egycsomópontos NFS használata a Batch AI blob-tárolóval.</span><span class="sxs-lookup"><span data-stu-id="30299-211">You can also use [service endpoints][endpoints] with blob storage to grant access from a virtual network or use a single-node NFS inside the virtual network with Batch AI.</span></span>

## <a name="monitoring-considerations"></a><span data-ttu-id="30299-212">Felügyeleti szempontok</span><span class="sxs-lookup"><span data-stu-id="30299-212">Monitoring considerations</span></span>

<span data-ttu-id="30299-213">A feladat futtatásakor fontos nyomon követheti, és győződjön meg arról, hogy a dolgok várt módon működik.</span><span class="sxs-lookup"><span data-stu-id="30299-213">While running your job, it's important to monitor the progress and make sure that things are working as expected.</span></span> <span data-ttu-id="30299-214">Azonban ez több aktív csomópontból álló fürtben figyelése kihívást jelenthet.</span><span class="sxs-lookup"><span data-stu-id="30299-214">However, it can be a challenge to monitor across a cluster of active nodes.</span></span>

<span data-ttu-id="30299-215">Az Azure Portalon kezelheti a Batch AI-fájlkiszolgálók vagy, ha a [Azure CLI-vel] [ cli] és a Python SDK-t.</span><span class="sxs-lookup"><span data-stu-id="30299-215">The Batch AI file servers can be managed through the Azure portal or though the [Azure CLI][cli] and Python SDK.</span></span> <span data-ttu-id="30299-216">Megtapasztalhatja, a fürt általános állapotát, navigáljon a **Batch AI** a fürtcsomópontok állapotának vizsgálata az Azure Portalon.</span><span class="sxs-lookup"><span data-stu-id="30299-216">To get a sense of the overall state of the cluster, navigate to **Batch AI** in the Azure portal to inspect the state of the cluster nodes.</span></span> <span data-ttu-id="30299-217">Ha egy csomópont nem aktív, vagy egy feladat sikertelen volt, a hibanaplókat blob storage-bA lesznek mentve, és a is elérhetők az Azure portál **feladatok**.</span><span class="sxs-lookup"><span data-stu-id="30299-217">If a node is inactive or a job fails, the error logs are saved to blob storage, and are also accessible in the Azure Portal under **Jobs**.</span></span>

<span data-ttu-id="30299-218">Naplók való csatlakozással figyelési bővítését [Azure Application Insights] [ ai] vagy különálló, amely lekérdezi a Batch AI-fürtöt, és a feladatok állapotát a folyamat futtatásával.</span><span class="sxs-lookup"><span data-stu-id="30299-218">Enrich monitoring by connecting logs to [Azure Application Insights][ai] or by running separate processes that poll for the state of the Batch AI cluster and its jobs.</span></span>

<span data-ttu-id="30299-219">A Batch AI minden stdout/stderr automatikusan bejelentkezik a Blob storage-fiók társítása.</span><span class="sxs-lookup"><span data-stu-id="30299-219">Batch AI automatically logs all stdout/stderr to the associate Blob storage account.</span></span> <span data-ttu-id="30299-220">Például használja a tárolók navigációs eszköz [Azure Storage Explorer] [ storage-explorer] és a naplófájlok navigáláskor könnyebben szolgáltatással.</span><span class="sxs-lookup"><span data-stu-id="30299-220">Use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] for an easier experience when navigating log files.</span></span>

<span data-ttu-id="30299-221">Akkor is a stream minden egyes feladathoz a naplókat.</span><span class="sxs-lookup"><span data-stu-id="30299-221">It is also possible to stream the logs for each job.</span></span> <span data-ttu-id="30299-222">Ezt a beállítást, lásd a fejlesztési lépéseket a [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="30299-222">For details about this option, see the development steps on [GitHub][github].</span></span>

## <a name="deployment"></a><span data-ttu-id="30299-223">Környezet</span><span class="sxs-lookup"><span data-stu-id="30299-223">Deployment</span></span>

<span data-ttu-id="30299-224">A referenciaimplementációt a jelen architektúra érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="30299-224">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="30299-225">Elosztott-betanítás deep learning-modellek között GPU-kompatibilis virtuális gépek fürtjeinek elvégzésére van ismertetett lépéseket követve.</span><span class="sxs-lookup"><span data-stu-id="30299-225">Follow the steps described there to conduct distributed training of deep learning models across clusters of GPU-enabled VMs.</span></span>

## <a name="next-steps"></a><span data-ttu-id="30299-226">További lépések</span><span class="sxs-lookup"><span data-stu-id="30299-226">Next steps</span></span>

<span data-ttu-id="30299-227">Ez az architektúra a kimenete a betanított modell mentett blob storage-bA.</span><span class="sxs-lookup"><span data-stu-id="30299-227">The output from this architecture is a trained model that is saved to blob storage.</span></span> <span data-ttu-id="30299-228">Ez a modell, valós idejű pontozási vagy kötegelt pontozási is üzembe helyezheti.</span><span class="sxs-lookup"><span data-stu-id="30299-228">You can operationalize this model for either real-time scoring or batch scoring.</span></span> <span data-ttu-id="30299-229">További információkért tekintse meg a következő referenciaarchitektúrákat:</span><span class="sxs-lookup"><span data-stu-id="30299-229">For more information, see the following reference architectures:</span></span>

- <span data-ttu-id="30299-230">[Valós idejű pontozási Python Scikit-ismerje meg, és a deep learning-modellek az Azure-ban][real-time-scoring]</span><span class="sxs-lookup"><span data-stu-id="30299-230">[Real-time scoring of Python Scikit-Learn and deep learning models on Azure][real-time-scoring]</span></span>
- <span data-ttu-id="30299-231">[Kötegelt pontozási az Azure-on deep learning-modellek][batch-scoring]</span><span class="sxs-lookup"><span data-stu-id="30299-231">[Batch scoring on Azure for deep learning models][batch-scoring]</span></span>

[0]: ./_images/distributed_dl_architecture.png
[1]: ./_images/distributed_dl_flow.png
[2]: ./_images/distributed_dl_tests.png
[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[azure-blob]: /azure/storage/blobs/storage-blobs-introduction
[batch-ai]: /azure/batch-ai/overview
[batch-ai-files]: /azure/batch-ai/resource-concepts#file-server
[batch-scoring]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[benchmark]: https://github.com/msalvaris/BatchAIHorovodBenchmark
[blob]: https://azure.microsoft.com/en-gb/blog/introducing-azure-premium-blob-storage-limited-public-preview/
[blobfuse]: https://github.com/Azure/azure-storage-fuse
[cli]: https://github.com/Azure/BatchAI/blob/master/documentation/using-azure-cli-20.md
[docker]: https://hub.docker.com/
[endpoints]: /azure/storage/common/storage-network-security?toc=%2fazure%2fvirtual-network%2ftoc.json#grant-access-from-a-virtual-network
[files]: /azure/storage/files/storage-files-introduction
[github]: https://github.com/Azure/DistributedDeepLearning/
[gpu]: /azure/virtual-machines/windows/sizes-gpu
[horovod]: https://github.com/uber/horovod
[imagenet]: http://www.image-net.org/
[real-time-scoring]: /azure/architecture/reference-architectures/ai/realtime-scoring-python
[resnet]: https://arxiv.org/abs/1512.03385
[security-guide]: /azure/storage/common/storage-security-guide
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows
[tutorial]: https://github.com/Azure/DistributedDeepLearning