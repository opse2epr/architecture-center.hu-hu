---
title: Kötegelt pontozási az R-modellek az Azure-ban
description: Hajtsa végre a kötegelt pontozási az R-modellek használata az Azure Batch és a egy adatkészlet kiskereskedelmi store értékesítési előrejelzés alapján.
author: njray
ms.date: 03/29/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai
ms.openlocfilehash: 4fa57168c337b01c8e7d0fc86ba54fee59a7ae47
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887986"
---
# <a name="batch-scoring-of-r-machine-learning-models-on-azure"></a><span data-ttu-id="cc638-103">Batch-pontozás R gépi tanulási modellek az Azure-ban</span><span class="sxs-lookup"><span data-stu-id="cc638-103">Batch scoring of R machine learning models on Azure</span></span>

<span data-ttu-id="cc638-104">Ez a referenciaarchitektúra bemutatja, hogyan hajtsa végre a kötegelt pontozási az R-modellek Azure Batch használatával.</span><span class="sxs-lookup"><span data-stu-id="cc638-104">This reference architecture shows how to perform batch scoring with R models using Azure Batch.</span></span> <span data-ttu-id="cc638-105">A forgatókönyv kiskereskedelmi store értékesítési előrejelzés alapján, de ez az architektúra bármilyen forgatókönyvhöz alapján történő egy R-modellek használatával nagy scaler generációja igénylő is általánosítva van.</span><span class="sxs-lookup"><span data-stu-id="cc638-105">The scenario is based on retail store sales forecasting, but this architecture can be generalized for any scenario requiring the generation of predictions on a large scaler using R models.</span></span> <span data-ttu-id="cc638-106">Az architektúra egy referenciaimplementációt érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="cc638-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Architektúradiagram][0]

<span data-ttu-id="cc638-108">**A forgatókönyv**: A supermarket lánc termékek értékesítés-előrejelzést a soron következő negyedév keresztül kell.</span><span class="sxs-lookup"><span data-stu-id="cc638-108">**Scenario**: A supermarket chain needs to forecast sales of products over the upcoming quarter.</span></span> <span data-ttu-id="cc638-109">Az előrejelzés lehetővé teszi, hogy a vállalat az ellátási lánc jobban kezelheti, és győződjön meg arról, megfelel-e a tárolók minden egyes termékek iránti igény.</span><span class="sxs-lookup"><span data-stu-id="cc638-109">The forecast allows the company to manage its supply chain better and ensure it can meet demand for products at each of its stores.</span></span> <span data-ttu-id="cc638-110">A vállalat frissíti az előrejelzéseket minden héten elérhetővé válik az előző hét új értékesítési adatait, és a termék értékesítési stratégia a következő negyedév van beállítva.</span><span class="sxs-lookup"><span data-stu-id="cc638-110">The company updates its forecasts every week as new sales data from the previous week becomes available and the product marketing strategy for next quarter is set.</span></span> <span data-ttu-id="cc638-111">Ha meg szeretné becsülni az egyes értékesítési előrejelzések a bizonytalanság ki osztóérték előrejelzések jönnek létre.</span><span class="sxs-lookup"><span data-stu-id="cc638-111">Quantile forecasts are generated to estimate the uncertainty of the individual sales forecasts.</span></span>

<span data-ttu-id="cc638-112">Feldolgozás az alábbi lépésekből áll:</span><span class="sxs-lookup"><span data-stu-id="cc638-112">Processing involves the following steps:</span></span>

1. <span data-ttu-id="cc638-113">Az Azure Logic Apps az előrejelzési kódgenerálási folyamat hetente egyszer aktiválódik.</span><span class="sxs-lookup"><span data-stu-id="cc638-113">An Azure Logic App triggers the forecast generation process once per week.</span></span>

1. <span data-ttu-id="cc638-114">A logikai alkalmazás elindul egy Azure-Tárolópéldányon futtatja az ütemezőt Docker-tároló, amely elindítja a pontozási feladatokat a Batch-fürtön.</span><span class="sxs-lookup"><span data-stu-id="cc638-114">The logic app starts an Azure Container Instance running the scheduler Docker container, which triggers the scoring jobs on the Batch cluster.</span></span>

1. <span data-ttu-id="cc638-115">Pontozó feladatok párhuzamos futtatása a Batch-fürt csomópontjai között.</span><span class="sxs-lookup"><span data-stu-id="cc638-115">Scoring jobs run in parallel across the nodes of the Batch cluster.</span></span> <span data-ttu-id="cc638-116">Minden egyes csomópont:</span><span class="sxs-lookup"><span data-stu-id="cc638-116">Each node:</span></span>

    1. <span data-ttu-id="cc638-117">Lekéri a feldolgozó Docker-rendszerképet a Docker Hubból, és elindít egy tárolót.</span><span class="sxs-lookup"><span data-stu-id="cc638-117">Pulls the worker Docker image from Docker Hub and starts a container.</span></span>

    1. <span data-ttu-id="cc638-118">A bemeneti adatokat olvasó és előre betanított az R-modellek az Azure Blob storage-ból.</span><span class="sxs-lookup"><span data-stu-id="cc638-118">Reads input data and pre-trained R models from Azure Blob storage.</span></span>

    1. <span data-ttu-id="cc638-119">Az előrejelzések betanítják pontszámmodell.</span><span class="sxs-lookup"><span data-stu-id="cc638-119">Scores the data to produce the forecasts.</span></span>

    1. <span data-ttu-id="cc638-120">Az előrejelzési eredmények ír a blob storage-bA.</span><span class="sxs-lookup"><span data-stu-id="cc638-120">Writes the forecast results to blob storage.</span></span>

<span data-ttu-id="cc638-121">Az alábbi ábrán látható négy termékek (SKU) az előre jelzett értékesítési egy tárolóban.</span><span class="sxs-lookup"><span data-stu-id="cc638-121">The figure below shows the forecasted sales for four products (SKUs) in one store.</span></span> <span data-ttu-id="cc638-122">A fekete vonal jelzi az értékesítési előzmények, a szaggatott vonal előrejelzési medián (q50), a rózsaszín sávon kívüli jelöli az erdőtopológia-ötödik és hetvenötödik percentilisei, és a kék sáv az ötödik és kilencven-ötödik percentilisei jelöl.</span><span class="sxs-lookup"><span data-stu-id="cc638-122">The black line is the sales history, the dashed line is the median (q50) forecast, the pink band represents the twenty-fifth and seventy-fifth percentiles, and the blue band represents the fifth and ninety-fifth percentiles.</span></span>

![Értékesítési előrejelzések][1]

## <a name="architecture"></a><span data-ttu-id="cc638-124">Architektúra</span><span class="sxs-lookup"><span data-stu-id="cc638-124">Architecture</span></span>

<span data-ttu-id="cc638-125">Az architektúra az alábbi összetevőkből áll.</span><span class="sxs-lookup"><span data-stu-id="cc638-125">This architecture consists of the following components.</span></span>

<span data-ttu-id="cc638-126">[Az Azure Batch] [ batch] előrejelzési generációs feladatok párhuzamosan futtathatók a fürt a virtuális gépek szolgál.</span><span class="sxs-lookup"><span data-stu-id="cc638-126">[Azure Batch][batch] is used to run forecast generation jobs in parallel on a cluster of virtual machines.</span></span> <span data-ttu-id="cc638-127">Előrejelzés végrehajtott előre betanított gépi tanulási modellek r Azure Batch megvalósított automatikusan méretezheti az virtuális gépek a fürt számára küldött számítási feladatok száma alapján.</span><span class="sxs-lookup"><span data-stu-id="cc638-127">Predictions are made using pre-trained machine learning models implemented in R. Azure Batch can automatically scale the number of VMs based on the number of jobs submitted to the cluster.</span></span> <span data-ttu-id="cc638-128">Minden egyes csomóponton az R-szkriptek pontszámot rendelni az adatok és előrejelzések készítése a Docker-tároló belül fut.</span><span class="sxs-lookup"><span data-stu-id="cc638-128">On each node, an R script runs within a Docker container to score data and generate forecasts.</span></span>

<span data-ttu-id="cc638-129">[Az Azure Blob Storage] [ blob] a bemeneti adatokat, az előre betanított machine learning-modellek és az előrejelzési eredményeket tárolja.</span><span class="sxs-lookup"><span data-stu-id="cc638-129">[Azure Blob Storage][blob] is used to store the input data, the pre-trained machine learning models, and the forecast results.</span></span> <span data-ttu-id="cc638-130">Kínál rendkívül költséghatékony tárolási megoldás, amely szükséges a számítási feladat teljesítményét.</span><span class="sxs-lookup"><span data-stu-id="cc638-130">It delivers very cost-effective storage for the performance that this workload requires.</span></span>

<span data-ttu-id="cc638-131">[Az Azure Container Instances] [ aci] adja meg a kiszolgáló nélküli számítási igény.</span><span class="sxs-lookup"><span data-stu-id="cc638-131">[Azure Container Instances][aci] provide serverless compute on demand.</span></span> <span data-ttu-id="cc638-132">Ebben az esetben a tárolópéldány indításához az előrejelzések készítése a Batch-feladatok ütemezett helyezünk üzembe.</span><span class="sxs-lookup"><span data-stu-id="cc638-132">In this case, a container instance is deployed on a schedule to trigger the Batch jobs that generate the forecasts.</span></span> <span data-ttu-id="cc638-133">A Batch-feladatok egy R parancsfájlt az aktivált a [doAzureParallel][doAzureParallel] csomagot.</span><span class="sxs-lookup"><span data-stu-id="cc638-133">The Batch jobs are triggered from an R script using the [doAzureParallel][doAzureParallel] package.</span></span> <span data-ttu-id="cc638-134">A tárolópéldány automatikusan leáll, miután a feladat befejezve.</span><span class="sxs-lookup"><span data-stu-id="cc638-134">The container instance automatically shuts down once the jobs have finished.</span></span>

<span data-ttu-id="cc638-135">[Az Azure Logic Apps] [ logic-apps] a teljes munkafolyamat-trigger ütemezés szerint a tárolópéldányok üzembe helyezésével.</span><span class="sxs-lookup"><span data-stu-id="cc638-135">[Azure Logic Apps][logic-apps] trigger the entire workflow by deploying the container instances on a schedule.</span></span> <span data-ttu-id="cc638-136">Egy Azure Container Instances-összekötőt a Logic Apps lehetővé teszi, hogy számos olyan kiváltó események üzembe helyezni egy példányt.</span><span class="sxs-lookup"><span data-stu-id="cc638-136">An Azure Container Instances connector in Logic Apps allows an instance to be deployed upon a range of trigger events.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="cc638-137">A teljesítménnyel kapcsolatos megfontolások</span><span class="sxs-lookup"><span data-stu-id="cc638-137">Performance considerations</span></span>

### <a name="containerized-deployment"></a><span data-ttu-id="cc638-138">Tárolóalapú üzembe helyezés</span><span class="sxs-lookup"><span data-stu-id="cc638-138">Containerized deployment</span></span>

<span data-ttu-id="cc638-139">Ebben az architektúrában az összes R-szkriptek futtatása belül [Docker](https://www.docker.com/) tárolók.</span><span class="sxs-lookup"><span data-stu-id="cc638-139">With this architecture, all R scripts run within [Docker](https://www.docker.com/) containers.</span></span> <span data-ttu-id="cc638-140">Ez biztosítja, hogy a parancsfájlok futtatásához konzisztens környezetben, az R ugyanazon verzióját és a csomagok verzióit, minden alkalommal.</span><span class="sxs-lookup"><span data-stu-id="cc638-140">This ensures that the scripts run in a consistent environment, with the same R version and packages versions, every time.</span></span> <span data-ttu-id="cc638-141">Önálló Docker-rendszerképek szolgálnak az ütemezőt és a feldolgozó tárolók, mert mindegyik különböző rendelkezik R csomag függősége.</span><span class="sxs-lookup"><span data-stu-id="cc638-141">Separate Docker images are used for the scheduler and worker containers, because each has a different set of R package dependencies.</span></span>

<span data-ttu-id="cc638-142">Az Azure Container Instances a scheduler tároló futtatásához egy kiszolgáló nélküli környezetet biztosít.</span><span class="sxs-lookup"><span data-stu-id="cc638-142">Azure Container Instances provides a serverless environment to run the scheduler container.</span></span> <span data-ttu-id="cc638-143">A scheduler tároló futtatja az R-szkriptet, amely egy Azure Batch-fürtön futtatott egyéni pontozási feladatok.</span><span class="sxs-lookup"><span data-stu-id="cc638-143">The scheduler container runs an R script that triggers the individual scoring jobs running on an Azure Batch cluster.</span></span>

<span data-ttu-id="cc638-144">A Batch-fürt minden csomópontján fut, a feldolgozó tároló, amely végrehajtja a pontozó szkript.</span><span class="sxs-lookup"><span data-stu-id="cc638-144">Each node of the Batch cluster runs the worker container, which executes the scoring script.</span></span>

### <a name="parallelizing-the-workload"></a><span data-ttu-id="cc638-145">A számítási feladatot párhuzamosan futtatni</span><span class="sxs-lookup"><span data-stu-id="cc638-145">Parallelizing the workload</span></span>

<span data-ttu-id="cc638-146">Amikor kötegelt pontozási R-modellek az adatokat, gondolja át, hogyan párhuzamosíthatja a számítási feladatok.</span><span class="sxs-lookup"><span data-stu-id="cc638-146">When batch scoring data with R models, consider how to parallelize the workload.</span></span> <span data-ttu-id="cc638-147">A bemeneti adatok valamilyen módon kell particionálni a úgy, hogy a pontozási műveletet a fürt csomópontjai között elosztható.</span><span class="sxs-lookup"><span data-stu-id="cc638-147">The input data must be partitioned somehow so that the scoring operation can be distributed  across the cluster nodes.</span></span> <span data-ttu-id="cc638-148">Próbálja meg más megközelítést Fedezze fel a számítási feladatok elosztásához a legjobb választás.</span><span class="sxs-lookup"><span data-stu-id="cc638-148">Try different approaches to discover the best choice for distributing your workload.</span></span> <span data-ttu-id="cc638-149">Eseti alapon vegye figyelembe a következőket:</span><span class="sxs-lookup"><span data-stu-id="cc638-149">On a case-by-case basis, consider the following:</span></span>

- <span data-ttu-id="cc638-150">Könnyen betölthetők és egyetlen csomópont, a memória a feldolgozott adatok mennyiségét.</span><span class="sxs-lookup"><span data-stu-id="cc638-150">How much data can be loaded and processed in the memory of a single node.</span></span>
- <span data-ttu-id="cc638-151">Minden egyes batch-feladat indítása járó többletterhelést.</span><span class="sxs-lookup"><span data-stu-id="cc638-151">The overhead of starting each batch job.</span></span>
- <span data-ttu-id="cc638-152">Az R-modellek betöltése járó többletterhelést.</span><span class="sxs-lookup"><span data-stu-id="cc638-152">The overhead of loading the R models.</span></span>

<span data-ttu-id="cc638-153">Az ehhez a példához használja a forgatókönyvben a modell objektumait nagy, és az egyes termékek Előrejelzés létrehozásához csak néhány másodpercet vesz igénybe.</span><span class="sxs-lookup"><span data-stu-id="cc638-153">In the scenario used for this example, the model objects are large, and it takes only a few seconds to generate a forecast for individual products.</span></span> <span data-ttu-id="cc638-154">Ebből kifolyólag a termékek csoportban, és a csomópontonként egy egyetlen Batch-feladat végrehajtása.</span><span class="sxs-lookup"><span data-stu-id="cc638-154">For this reason, you can group the products and execute a single Batch job per node.</span></span> <span data-ttu-id="cc638-155">Belül minden egyes feladat hurkot állít elő a termékekre vonatkozó előrejelzések egymás után.</span><span class="sxs-lookup"><span data-stu-id="cc638-155">A loop within each job generates forecasts for the products sequentially.</span></span> <span data-ttu-id="cc638-156">Ez a módszer elemről kiderül, hogy a leghatékonyabb párhuzamosíthatja az adott számítási feladatot is.</span><span class="sxs-lookup"><span data-stu-id="cc638-156">This method turns out to be the most efficient way to parallelize this particular workload.</span></span> <span data-ttu-id="cc638-157">Ezzel elkerülheti a számos kisebb a Batch-feladat indítása és az R-modellek ismételten betöltése járó többletterhelést.</span><span class="sxs-lookup"><span data-stu-id="cc638-157">It avoids the overhead of starting many smaller Batch jobs and repeatedly loading the R models.</span></span>

<span data-ttu-id="cc638-158">Egy alternatív módszer is termékenként egy Batch-feladat indításához.</span><span class="sxs-lookup"><span data-stu-id="cc638-158">An alternative approach is to trigger one Batch job per product.</span></span> <span data-ttu-id="cc638-159">Az Azure Batch automatikusan képezi a feladatok várólistáját, és elküldi őket a fürtön kell végrehajtani, amint elérhetővé válnak a csomópontok.</span><span class="sxs-lookup"><span data-stu-id="cc638-159">Azure Batch automatically forms a queue of jobs and submits them to be executed on the cluster as nodes become available.</span></span> <span data-ttu-id="cc638-160">Használat [automatikus skálázást] [ autoscale] , állítsa be a feladatok számától függően a fürtben található csomópontok számát.</span><span class="sxs-lookup"><span data-stu-id="cc638-160">Use [automatic scaling][autoscale] to adjust the number of nodes in the cluster depending on the number of jobs.</span></span> <span data-ttu-id="cc638-161">Ez a megközelítés több értelme, ha minden egyes pontozási művelet, a modell objektumait újraépítésével és a feladatok kezdési járó többletterhelést igazoló egy viszonylag hosszú ideig tart.</span><span class="sxs-lookup"><span data-stu-id="cc638-161">This approach makes more sense if it takes a relatively long time to complete each scoring operation, justifying the overhead of starting the jobs and reloading the model objects.</span></span> <span data-ttu-id="cc638-162">Ez a módszer emellett megvalósítása egyszerűbb, és rugalmasságot biztosít, automatikus méretezés használata – Ha a teljes terhelés mérete nem ismert előre fontos szempont.</span><span class="sxs-lookup"><span data-stu-id="cc638-162">This approach is also simpler to implement and gives you the flexibility to use automatic scaling—an important consideration if the size of the total workload is not known in advance.</span></span>

## <a name="monitoring-and-logging-considerations"></a><span data-ttu-id="cc638-163">Figyelés és naplózás kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="cc638-163">Monitoring and logging considerations</span></span>

### <a name="monitoring-azure-batch-jobs"></a><span data-ttu-id="cc638-164">Azure Batch-feladatok figyelése</span><span class="sxs-lookup"><span data-stu-id="cc638-164">Monitoring Azure Batch jobs</span></span>

<span data-ttu-id="cc638-165">Figyelheti, és a Batch-feladatok leállítása a **feladatok** az Azure Portalon a Batch-fiók panelén.</span><span class="sxs-lookup"><span data-stu-id="cc638-165">Monitor and terminate Batch jobs from the **Jobs** pane of the Batch account in the Azure portal.</span></span> <span data-ttu-id="cc638-166">A batch-fürt, beleértve az egyes csomópontok állapotát a monitorozására a **készletek** ablaktáblán.</span><span class="sxs-lookup"><span data-stu-id="cc638-166">Monitor the batch cluster, including the state of individual nodes, from the **Pools** pane.</span></span>

### <a name="logging-with-doazureparallel"></a><span data-ttu-id="cc638-167">A doAzureParallel naplózása</span><span class="sxs-lookup"><span data-stu-id="cc638-167">Logging with doAzureParallel</span></span>

<span data-ttu-id="cc638-168">A doAzureParallel csomag automatikusan gyűjt minden feladat az Azure Batch elküldve az összes stdout/stderr-naplóit.</span><span class="sxs-lookup"><span data-stu-id="cc638-168">The doAzureParallel package automatically collects logs of all stdout/stderr for every job submitted on Azure Batch.</span></span> <span data-ttu-id="cc638-169">A telepítéskor jönnek létre storage-fiókban találhatók.</span><span class="sxs-lookup"><span data-stu-id="cc638-169">These can be found in the storage account created at setup.</span></span> <span data-ttu-id="cc638-170">Megtekintheti őket, használjon egy tárolási navigációs eszköz például [Azure Storage Explorer] [ storage-explorer] vagy az Azure Portalon.</span><span class="sxs-lookup"><span data-stu-id="cc638-170">To view them, use a storage navigation tool such as [Azure Storage Explorer][storage-explorer] or Azure portal.</span></span>

<span data-ttu-id="cc638-171">Gyors fejlesztés során a Batch-feladatok hibakereséséhez, nyomtassa ki a helyi R munkamenetet használ a naplók a [getJobFiles][getJobFiles] doAzureParallel funkcióját.</span><span class="sxs-lookup"><span data-stu-id="cc638-171">To quickly debug Batch jobs during development, print logs in your local R session using the [getJobFiles][getJobFiles] function of doAzureParallel.</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="cc638-172">Költségekkel kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="cc638-172">Cost considerations</span></span>

<span data-ttu-id="cc638-173">Ez a referenciaarchitektúra a használt számítási erőforrások összetevői a legtöbb költséges.</span><span class="sxs-lookup"><span data-stu-id="cc638-173">The compute resources used in this reference architecture are the most costly components.</span></span> <span data-ttu-id="cc638-174">Ebben a forgatókönyvben egy fix méretű fürt jön létre, amikor a feladat által aktivált, majd állítsa le a feladat befejezése után.</span><span class="sxs-lookup"><span data-stu-id="cc638-174">For this scenario, a cluster of fixed size is created whenever the job is triggered and then shut down after the job has completed.</span></span> <span data-ttu-id="cc638-175">Költsége akkor lesz felszámítva, csak a fürt csomópontjai indítása, futtatása vagy leállítása közben.</span><span class="sxs-lookup"><span data-stu-id="cc638-175">Cost is incurred only while the cluster nodes are starting, running, or shutting down.</span></span> <span data-ttu-id="cc638-176">Ez a megközelítés egy forgatókönyvet, ahol az előrejelzések készítése szükséges számítási erőforrások továbbra is viszonylag állandó feladat feladat ideális.</span><span class="sxs-lookup"><span data-stu-id="cc638-176">This approach is suitable for a scenario where the compute resources required to generate the forecasts remain relatively constant from job to job.</span></span>

<span data-ttu-id="cc638-177">Olyan esetekben, ahol a feladat végrehajtásához szükséges számítási nem ismert előre lehet megfelelő automatikus méretezés használata.</span><span class="sxs-lookup"><span data-stu-id="cc638-177">In scenarios where the amount of compute required to complete the job is not known in advance, it may be more suitable to use automatic scaling.</span></span> <span data-ttu-id="cc638-178">Ezzel a módszerrel a fürt méretét erőforrások méretezése pedig ettől felfelé vagy lefelé a projekt méretétől függően.</span><span class="sxs-lookup"><span data-stu-id="cc638-178">With this approach, the size of the cluster is scaled up or down depending on the size of the job.</span></span> <span data-ttu-id="cc638-179">Az Azure Batch számos meghatározásakor a fürt segítségével beállíthatók úgy automatikus méretezési képletek a [doAzureParallel][doAzureParallel] API-t.</span><span class="sxs-lookup"><span data-stu-id="cc638-179">Azure Batch supports a range of auto-scale formulae which you can set when defining the cluster using the [doAzureParallel][doAzureParallel] API.</span></span>

<span data-ttu-id="cc638-180">Bizonyos esetekben a feladatok között eltelt idő lehet túl rövid, állítsa le és indítsa el a fürtöt.</span><span class="sxs-lookup"><span data-stu-id="cc638-180">For some scenarios, the time between jobs may be too short to shut down and start up the cluster.</span></span> <span data-ttu-id="cc638-181">Ezekben az esetekben tartsa meg a fürtön futó feladatok között, ha szükséges.</span><span class="sxs-lookup"><span data-stu-id="cc638-181">In these cases, keep the cluster running between jobs if appropriate.</span></span>

<span data-ttu-id="cc638-182">Az Azure Batch- és a doAzureParallel támogatja az alacsony prioritású virtuális gépek.</span><span class="sxs-lookup"><span data-stu-id="cc638-182">Azure Batch and doAzureParallel support the use of low-priority VMs.</span></span> <span data-ttu-id="cc638-183">Ezek a virtuális gépek egy jelentős kedvezménnyel, de más magasabb prioritású számítási feladatok által éppen sajátíthatja kockázati kapható.</span><span class="sxs-lookup"><span data-stu-id="cc638-183">These VMs come with a significant discount but risk being appropriated by other higher priority workloads.</span></span> <span data-ttu-id="cc638-184">Ezek a virtuális gépek használatát ezért használata nem ajánlott a kritikus fontosságú éles számítási feladatokhoz.</span><span class="sxs-lookup"><span data-stu-id="cc638-184">The use of these VMs are therefore not recommended for critical production workloads.</span></span> <span data-ttu-id="cc638-185">Azonban azok nagyon hasznos a kísérleti vagy fejlesztési számítási feladatokhoz.</span><span class="sxs-lookup"><span data-stu-id="cc638-185">However, they are very useful for experimental or development workloads.</span></span>

## <a name="deployment"></a><span data-ttu-id="cc638-186">Környezet</span><span class="sxs-lookup"><span data-stu-id="cc638-186">Deployment</span></span>

<span data-ttu-id="cc638-187">Ez a referenciaarchitektúra üzembe helyezéséhez kövesse az ismertetett lépéseket a [GitHub][github] adattárat.</span><span class="sxs-lookup"><span data-stu-id="cc638-187">To deploy this reference architecture, follow the steps described in the [GitHub][github] repo.</span></span>


[0]: ./_images/batch-scoring-r-models.png
[1]: ./_images/sales-forecasts.png
[aci]: /azure/container-instances/container-instances-overview
[autoscale]: /azure/batch/batch-automatic-scaling
[batch]: /azure/batch/batch-technical-overview
[blob]: /azure/storage/blobs/storage-blobs-introduction
[doAzureParallel]: https://github.com/Azure/doAzureParallel/blob/master/docs/32-autoscale.md
[getJobFiles]: /azure/machine-learning/service/how-to-train-ml-models
[github]: https://github.com/Azure/RBatchScoring
[logic-apps]: /azure/logic-apps/logic-apps-overview
[storage-explorer]: /azure/vs-azure-tools-storage-manage-with-storage-explorer?tabs=windows