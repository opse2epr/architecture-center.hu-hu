---
title: Batch-pontozás Python-modellek az Azure-ban
description: Hozzon létre egy méretezhető megoldás, a kötegelt pontozási modellek Azure Machine Learning szolgáltatás használatával párhuzamosan ütemezés szerint.
author: njray
ms.date: 01/30/2019
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: azcat-ai, AI
ms.openlocfilehash: b7607984bcf2c4bd046421aeb6e9d52dd8e7c18e
ms.sourcegitcommit: 1a3cc91530d56731029ea091db1f15d41ac056af
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 04/03/2019
ms.locfileid: "58887743"
---
# <a name="batch-scoring-of-python-machine-learning-models-on-azure"></a><span data-ttu-id="cc8ee-103">Batch-pontozás Python machine learning-modellek az Azure-ban</span><span class="sxs-lookup"><span data-stu-id="cc8ee-103">Batch scoring of Python machine learning models on Azure</span></span>

<span data-ttu-id="cc8ee-104">Ez a referenciaarchitektúra bemutatja, hogyan hozhat létre egy méretezhető megoldás, a kötegelt pontozási számos modellek Azure Machine Learning szolgáltatás használatával párhuzamosan ütemezés szerint.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Machine Learning Service.</span></span> <span data-ttu-id="cc8ee-105">A megoldás sablonként is használható, és különböző problémákat generalize is.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="cc8ee-106">Az architektúra egy referenciaimplementációt érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Batch-pontozás Python-modellek az Azure-ban](./_images/batch-scoring-python.png)

<span data-ttu-id="cc8ee-108">**A forgatókönyv**: Ez a megoldás egy nagy számú egy IoT beállításban, ahol a minden egyes eszköz által érzékelőinek folyamatos működését figyeli.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="cc8ee-109">Minden egyes eszköz feltételezhető, imagenet rendellenességek észlelése modellek, amely képes előre jelezni kell társítani kell-e egy sorozatát mértékegysége, amelyek egy előre meghatározott idő alatt összesítjük, felelnek meg az anomáliadetektálási vagy nem.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-109">Each device is assumed to be associated with pretrained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="cc8ee-110">A valós életből vett példák ennek oka lehet egy adatfolyam érzékelőinek adatai, amelyeket a szűrt és összesítve van használatban a képzés és a valós idejű pontozási előtt kell.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="cc8ee-111">Az egyszerűség kedvéért ez a megoldás ugyanazon adatok fájlt használja a pontozási feladat végrehajtása közben.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-111">For simplicity, this solution uses the same data file when executing scoring jobs.</span></span>

<span data-ttu-id="cc8ee-112">Ez a referenciaarchitektúra a számítási feladatok ütemezett kiváltó lett tervezve.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-112">This reference architecture is designed for workloads that are triggered on a schedule.</span></span> <span data-ttu-id="cc8ee-113">Feldolgozás az alábbi lépésekből áll:</span><span class="sxs-lookup"><span data-stu-id="cc8ee-113">Processing involves the following steps:</span></span>
1.  <span data-ttu-id="cc8ee-114">Az Azure Event Hubs küldése érzékelőinek támogatunk.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-114">Send sensor readings for ingestion to Azure Event Hubs.</span></span>
2.  <span data-ttu-id="cc8ee-115">Hajtsa végre az adatfolyam-feldolgozás és a nyers adatok tárolásához.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-115">Perform stream processing and store the raw data.</span></span>
3.  <span data-ttu-id="cc8ee-116">Az adatok elküldése egy megkezdheti a munkát véve Machine Learning-fürtön.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-116">Send the data to a Machine Learning cluster that is ready to start taking work.</span></span> <span data-ttu-id="cc8ee-117">A fürt minden csomópontján fut egy adott érzékelő pontozási feladat.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-117">Each node in the cluster runs a scoring job for a specific sensor.</span></span> 
4.  <span data-ttu-id="cc8ee-118">Hajtsa végre a pontozási folyamatot, amely a Machine Learning Python-szkriptekkel párhuzamosan fut a pontozási feladatok.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-118">Execute the scoring pipeline, which runs the scoring jobs in parallel using Machine Learning Python scripts.</span></span> <span data-ttu-id="cc8ee-119">A folyamat létrehozását, közzé és idő előre meghatározott időközönként ütemezve.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-119">The pipeline is created, published, and scheduled to run on a predefined interval of time.</span></span>
5.  <span data-ttu-id="cc8ee-120">Hozzon létre előrejelzések, és tárolja őket Blob Storage-későbbi felhasználásra.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-120">Generate predictions and store them in Blob storage for later consumption.</span></span>

## <a name="architecture"></a><span data-ttu-id="cc8ee-121">Architektúra</span><span class="sxs-lookup"><span data-stu-id="cc8ee-121">Architecture</span></span>

<span data-ttu-id="cc8ee-122">Ez az architektúra a következő összetevőkből áll:</span><span class="sxs-lookup"><span data-stu-id="cc8ee-122">This architecture consists of the following components:</span></span>

<span data-ttu-id="cc8ee-123">[Az Azure Event Hubs][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-123">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="cc8ee-124">Az üzenet-feldolgozó szolgáltatás fogadására képes akár több millió eseményt üzenetek / másodperc.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-124">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="cc8ee-125">Ebben az architektúrában az érzékelők adatfolyamot küldeni az event hubs.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-125">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="cc8ee-126">[Az Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-126">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="cc8ee-127">Egy eseményfeldolgozó motor.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-127">An event-processing engine.</span></span> <span data-ttu-id="cc8ee-128">Stream Analytics-feladat beolvassa az adatokat az eseményközpontból érkező adatfolyamok, és elvégzi a adatfolyam-feldolgozás.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-128">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="cc8ee-129">[Az Azure SQL Database][sql-database].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-129">[Azure SQL Database][sql-database].</span></span> <span data-ttu-id="cc8ee-130">A érzékelőinek az adatok betöltése az SQL Database-be.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-130">Data from the sensor readings is loaded into SQL Database.</span></span> <span data-ttu-id="cc8ee-131">Az SQL olyan jól ismert módon (ami táblázatos strukturált és strukturálatlan) feldolgozott, adatfolyamként továbbított adatok tárolására, de más adattárakban is használható.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-131">SQL is a familiar way to store the processed, streamed data (which is tabular and structured), but other data stores can be used.</span></span>

<span data-ttu-id="cc8ee-132">[Az Azure Machine Learning szolgáltatás][amls].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-132">[Azure Machine Learning Service][amls].</span></span> <span data-ttu-id="cc8ee-133">A Machine Learning szolgáltatás egy felhőalapú szolgáltatás betanítási, pontozási, telepítésére és felügyeletére gépi tanulási modellek ipari méretekben.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-133">Machine Learning is a cloud service for training, scoring, deploying, and managing machine learning models at scale.</span></span> <span data-ttu-id="cc8ee-134">A kötegelt pontozási kontextusában a Machine Learning egy olyan fürtjét, virtuális gépek igény szerint egy automatikus skálázási beállítást, ahol a fürt minden csomópontján fut-e egy adott érzékelő pontozási feladat hoz létre.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-134">In the context of batch scoring, Machine Learning creates a cluster of virtual machines on demand with an automatic scaling option, where each node in the cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="cc8ee-135">A pontozó feladatok várólistára és felügyeli a Machine Learning Python-szkript lépések végrehajtása párhuzamosan.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-135">The scoring jobs are executed in parallel as Python-script steps that are queued and managed by Machine Learning.</span></span> <span data-ttu-id="cc8ee-136">Ezeket a lépéseket a Machine Learning létrehozott, közzétett, és a egy előre meghatározott időközönként idő futtatott, ütemezett folyamat részét képezik.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-136">These steps are part of a Machine Learning pipeline that is created, published, and scheduled to run on a predefined interval of time.</span></span>

<span data-ttu-id="cc8ee-137">[Az Azure Blob Storage][storage].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-137">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="cc8ee-138">BLOB-tárolók a pretrained modellek, az adatok és a kimeneti előrejelzéseket tárolására szolgálnak.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-138">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="cc8ee-139">A modellek töltődnek fel a Blob storage-ban a [01_create_resources.ipynb] [ create-resources] notebookot.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-139">The models are uploaded to Blob storage in the [01_create_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="cc8ee-140">Ezek [egy szintű SVM] [ one-class-svm] modellek képzett különböző eszközök eltérő érzékelők értéket jelölő adatokon.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-140">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="cc8ee-141">Ez a megoldás feltételezi, hogy az adatértékek vannak időszakra vonatkozó összesített érték egy rögzített idő.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-141">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="cc8ee-142">[Az Azure Container Registry][acr].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-142">[Azure Container Registry][acr].</span></span> <span data-ttu-id="cc8ee-143">A pontozó Python [parancsfájl] [ pyscript] fut, a fürt, ahol a megfelelő érzékelőktől kapott adatok beolvasása, állít elő, előrejelzéseket és a Blob storage-ban tárolja azokat minden egyes csomóponton létrehozott Docker-tárolókat.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-143">The scoring Python [script][pyscript] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="cc8ee-144">A teljesítménnyel kapcsolatos megfontolások</span><span class="sxs-lookup"><span data-stu-id="cc8ee-144">Performance considerations</span></span>

<span data-ttu-id="cc8ee-145">Standard Python-modellek általánosan elfogadott, hogy a processzorok elegendőek a számítási feladatok kezelésére.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-145">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="cc8ee-146">Ez az architektúra processzorokat használ.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-146">This architecture uses CPUs.</span></span> <span data-ttu-id="cc8ee-147">Azonban a [mély tanulási célú számítási feladatokhoz][deep], gpu-k általában teljesítményben felülmúlják CPU jelentős által &mdash; processzorok marketingre fürt általában szükség hasonló teljesítmény eléréséhez.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-147">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount &mdash; a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-versus-cores"></a><span data-ttu-id="cc8ee-148">Magok és a virtuális gépen párhuzamosan futtatni</span><span class="sxs-lookup"><span data-stu-id="cc8ee-148">Parallelizing across VMs versus cores</span></span>

<span data-ttu-id="cc8ee-149">Futó folyamatok sok modellek pontozása kötegelt módban, a feladatok kell példánylista méretezésnek megfelelően.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-149">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="cc8ee-150">Két módszer is lehetséges:</span><span class="sxs-lookup"><span data-stu-id="cc8ee-150">Two approaches are possible:</span></span>

* <span data-ttu-id="cc8ee-151">Hozzon létre egy nagyobb fürt alacsony költségű virtuális gépek használatával.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-151">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="cc8ee-152">Hozzon létre egy kisebb fürtöt magas végez az egyes elérhető több maggal rendelkező virtuális gépeket.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-152">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="cc8ee-153">Általánosságban véve standard Python-modell pontozása nem az erőforrás-igényű, deep learning-modellek pontozása, és egy kisebb fürtöt tudja hatékonyan kezelni a sorban álló modellek nagy számú kell lennie.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-153">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="cc8ee-154">Növelheti a fürt csomópontok méretei dataset növekedésének megfelelően.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-154">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="cc8ee-155">Az ebben a forgatókönyvben az egyszerűség kedvéért egy pontozási tevékenység belül küldte el gépi tanulási folyamat egyetlen lépésben.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-155">For convenience in this scenario, one scoring task is submitted within a single Machine Learning pipeline step.</span></span> <span data-ttu-id="cc8ee-156">Azonban érdemes lehet hatékonyabb, ha az azonos folyamat lépés belül több adattömbök pontozása.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-156">However, it can be more efficient to score multiple data chunks within the same pipeline step.</span></span> <span data-ttu-id="cc8ee-157">Ezekben az esetekben több adatkészlet olvasása és azok számára, egy egylépéses végrehajtása során a pontozó szkript végrehajtása egyéni kód írása.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-157">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single-step execution.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="cc8ee-158">Eszközkezeléssel kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="cc8ee-158">Management considerations</span></span>

- <span data-ttu-id="cc8ee-159">**Feladatok figyelése**.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-159">**Monitor jobs**.</span></span> <span data-ttu-id="cc8ee-160">Fontos, hogy a futó feladatok előrehaladásának figyeléséhez, de azt az aktív csomópontból álló fürtben figyelése kihívást jelenthet.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-160">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="cc8ee-161">Vizsgálja meg a fürt csomópontjainak állapotát, használja a [az Azure Portal] [ portal] kezelheti a [machine learning-munkaterület][ml-workspace].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-161">To inspect the state of the nodes in the cluster, use the [Azure Portal][portal] to manage the [machine learning workspace][ml-workspace].</span></span> <span data-ttu-id="cc8ee-162">Ha egy csomópont nem aktív, vagy egy feladat sikertelen volt, a hibanaplókat blob storage-bA lesznek mentve, és a folyamatok szakaszban is elérhetők.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-162">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the Pipelines section.</span></span> <span data-ttu-id="cc8ee-163">Gazdagabb figyelés csatlakozzon a naplók [Application Insights][app-insights], vagy a fürt és a feladatok állapotát a lekérdezéséhez külön folyamatok futtatásához.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-163">For richer monitoring, connect logs to [Application Insights][app-insights], or run separate processes to poll for the state of the cluster and its jobs.</span></span>
-   <span data-ttu-id="cc8ee-164">**Naplózás**.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-164">**Logging**.</span></span> <span data-ttu-id="cc8ee-165">Machine Learning szolgáltatás a társított Azure Storage-fiók összes stdout/stderr naplóz.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-165">Machine Learning Service logs all stdout/stderr to the associated Azure Storage account.</span></span> <span data-ttu-id="cc8ee-166">A naplófájlok egyszerűen megtekintéséhez használja a tárolók navigációs eszköz például [Azure Storage Explorer][explorer].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-166">To easily view the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

## <a name="cost-considerations"></a><span data-ttu-id="cc8ee-167">Költségekkel kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="cc8ee-167">Cost considerations</span></span>

<span data-ttu-id="cc8ee-168">Ez a referenciaarchitektúra a használt legköltségesebb összetevői a számítási erőforrásokat.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-168">The most expensive components used in this reference architecture are the compute resources.</span></span> <span data-ttu-id="cc8ee-169">Attól függően, a várólistában a feladatok felfelé és lefelé méretezi a számítási fürt mérete.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-169">The compute cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="cc8ee-170">Automatikus skálázás engedélyezése programozott módon a Python SDK-n keresztül a számítási kiépítési konfigurációjának módosításával.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-170">Enable automatic scaling programmatically through the Python SDK by modifying the compute’s provisioning configuration.</span></span> <span data-ttu-id="cc8ee-171">Vagy használja a [Azure CLI-vel] [ cli] a fürt automatikus skálázási paramétereinek a beállításához.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-171">Or use the [Azure CLI][cli] to set the automatic scaling parameters of the cluster.</span></span>

<span data-ttu-id="cc8ee-172">És nem igényel azonnali feldolgozási munka konfigurálja az automatikus skálázási képletet, hogy az alapértelmezett állapot (minimum) az nulla csomópontból álló fürtben.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-172">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="cc8ee-173">Ezzel a konfigurációval a fürt nullára a csomópontok kezdődik, és ha a várólistán lévő feladatok csak felskálázással.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-173">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="cc8ee-174">Ha a kötegelt pontozási folyamat naponta csak néhány alkalommal történik, vagy kevesebb, mint ez a beállítás lehetővé teszi a jelentős költségmegtakarítást.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-174">If the batch scoring process happens only a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="cc8ee-175">Az automatikus skálázás nem lehet megfelelő, a kötegelt feladatok számához egymáshoz közel túl fordulhat elő.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-175">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="cc8ee-176">A fürt számára le üzemeltethet a idejét is felmerülő költség, így ha egy batch számítási feladatot csak néhány percet az előző feladat befejezése után kezdődik, költséghatékonyabb tartani a fürtön futó feladatok között lehet.</span><span class="sxs-lookup"><span data-stu-id="cc8ee-176">The time that it takes for a cluster to spin up and spin down also incurs a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="cc8ee-177">E pontozási folyamatokat beütemezve egy nagy gyakoriságú (például minden órában), vagy ritkábban függ (például havonta egyszer).</span><span class="sxs-lookup"><span data-stu-id="cc8ee-177">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>


## <a name="deployment"></a><span data-ttu-id="cc8ee-178">Környezet</span><span class="sxs-lookup"><span data-stu-id="cc8ee-178">Deployment</span></span>

<span data-ttu-id="cc8ee-179">Ez a referenciaarchitektúra üzembe helyezéséhez kövesse az ismertetett lépéseket a [GitHub-adattárat][github].</span><span class="sxs-lookup"><span data-stu-id="cc8ee-179">To deploy this reference architecture, follow the steps described in the [GitHub repo][github].</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[aml-compute]: /azure/machine-learning/service/how-to-set-up-training-targets#amlcompute
[amls]: /azure/machine-learning/service/overview-what-is-azure-ml
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[cli]: /cli/azure
[create-resources]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/01_create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Microsoft/AMLBatchScoringPipeline
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[ml-workspace]: /azure/machine-learning/studio/create-workspace
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[pyscript]: https://github.com/Microsoft/AMLBatchScoringPipeline/blob/master/scripts/predict.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
[sql-database]: /azure/sql-database/
[app-insights]: /azure/application-insights/app-insights-overview
