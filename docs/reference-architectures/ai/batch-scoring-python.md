---
title: Batch-pontozás Python-modellek az Azure-ban
description: Hozzon létre egy méretezhető megoldás, a kötegelt pontozási modellek az Azure Batch AI segítségével párhuzamosan ütemezés szerint.
author: njray
ms.date: 12/13/2018
ms.custom: azcat-ai
ms.openlocfilehash: 4c43a3dadab11cb8dcf163cf63618795299283ad
ms.sourcegitcommit: 1f4cdb08fe73b1956e164ad692f792f9f635b409
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 01/08/2019
ms.locfileid: "54111051"
---
# <a name="batch-scoring-of-python-models-on-azure"></a><span data-ttu-id="27e56-103">Batch-pontozás Python-modellek az Azure-ban</span><span class="sxs-lookup"><span data-stu-id="27e56-103">Batch scoring of Python models on Azure</span></span>

<span data-ttu-id="27e56-104">Ez a referenciaarchitektúra bemutatja, hogyan hozhat létre egy méretezhető megoldás, a kötegelt pontozási számos modellt az Azure Batch AI segítségével párhuzamosan ütemezés szerint.</span><span class="sxs-lookup"><span data-stu-id="27e56-104">This reference architecture shows how to build a scalable solution for batch scoring many models on a schedule in parallel using Azure Batch AI.</span></span> <span data-ttu-id="27e56-105">A megoldás sablonként is használható, és különböző problémákat generalize is.</span><span class="sxs-lookup"><span data-stu-id="27e56-105">The solution can be used as a template and can generalize to different problems.</span></span>

<span data-ttu-id="27e56-106">Az architektúra egy referenciaimplementációt érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="27e56-106">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Batch-pontozás Python-modellek az Azure-ban](./_images/batch-scoring-python.png)

<span data-ttu-id="27e56-108">**A forgatókönyv**: Ez a megoldás egy nagy számú egy IoT beállításban, ahol a minden egyes eszköz által érzékelőinek folyamatos működését figyeli.</span><span class="sxs-lookup"><span data-stu-id="27e56-108">**Scenario**: This solution monitors the operation of a large number of devices in an IoT setting where each device sends sensor readings continuously.</span></span> <span data-ttu-id="27e56-109">Minden eszköz rendelkezik előre betanított rendellenességek észlelése, a modellek, hogy kell képes előre jelezni az e sorozata mértékegysége, amelyek egy előre meghatározott idő alatt összesítjük, ha meg szeretné anomáliát vagy nem veszi alapul.</span><span class="sxs-lookup"><span data-stu-id="27e56-109">Each device is assumed to have pre-trained anomaly detection models that need to be used to predict whether a series of measurements, that are aggregated over a predefined time interval, correspond to an anomaly or not.</span></span> <span data-ttu-id="27e56-110">A valós életből vett példák ennek oka lehet egy adatfolyam érzékelőinek adatai, amelyeket a szűrt és összesítve van használatban a képzés és a valós idejű pontozási előtt kell.</span><span class="sxs-lookup"><span data-stu-id="27e56-110">In real-world scenarios, this could be a stream of sensor readings that need to be filtered and aggregated before being used in training or real-time scoring.</span></span> <span data-ttu-id="27e56-111">Az egyszerűség kedvéért a megoldást ugyanazon adatok fájlt használja a pontozási feladat végrehajtása közben.</span><span class="sxs-lookup"><span data-stu-id="27e56-111">For simplicity, the solution uses the same data file when executing scoring jobs.</span></span>

## <a name="architecture"></a><span data-ttu-id="27e56-112">Architektúra</span><span class="sxs-lookup"><span data-stu-id="27e56-112">Architecture</span></span>

<span data-ttu-id="27e56-113">Ez az architektúra a következő összetevőkből áll:</span><span class="sxs-lookup"><span data-stu-id="27e56-113">This architecture consists of the following components:</span></span>

<span data-ttu-id="27e56-114">[Az Azure Event Hubs][event-hubs].</span><span class="sxs-lookup"><span data-stu-id="27e56-114">[Azure Event Hubs][event-hubs].</span></span> <span data-ttu-id="27e56-115">Az üzenet-feldolgozó szolgáltatás fogadására képes akár több millió eseményt üzenetek / másodperc.</span><span class="sxs-lookup"><span data-stu-id="27e56-115">This message ingestion service can ingest millions of event messages per second.</span></span> <span data-ttu-id="27e56-116">Ebben az architektúrában az érzékelők adatfolyamot küldeni az event hubs.</span><span class="sxs-lookup"><span data-stu-id="27e56-116">In this architecture, sensors send a stream of data to the event hub.</span></span>

<span data-ttu-id="27e56-117">[Az Azure Stream Analytics][stream-analytics].</span><span class="sxs-lookup"><span data-stu-id="27e56-117">[Azure Stream Analytics][stream-analytics].</span></span> <span data-ttu-id="27e56-118">Egy eseményfeldolgozó motor.</span><span class="sxs-lookup"><span data-stu-id="27e56-118">An event-processing engine.</span></span> <span data-ttu-id="27e56-119">Stream Analytics-feladat beolvassa az adatokat az eseményközpontból érkező adatfolyamok, és elvégzi a adatfolyam-feldolgozás.</span><span class="sxs-lookup"><span data-stu-id="27e56-119">A Stream Analytics job reads the data streams from the event hub and performs stream processing.</span></span>

<span data-ttu-id="27e56-120">[Az Azure Batch AI][batch-ai].</span><span class="sxs-lookup"><span data-stu-id="27e56-120">[Azure Batch AI][batch-ai].</span></span> <span data-ttu-id="27e56-121">Ez az elosztott számítási motor szolgál taníthat vagy tesztelhet a machine learning és a méretezett AI-modellek az Azure-ban.</span><span class="sxs-lookup"><span data-stu-id="27e56-121">This distributed computing engine is used to train and test machine learning and AI models at scale in Azure.</span></span> <span data-ttu-id="27e56-122">A Batch AI és az automatikus méretezési lehetőség, ahol a Batch AI-fürt minden csomópontján fut-e egy adott érzékelő pontozási feladat igény szerinti virtuális gépeket hoz létre.</span><span class="sxs-lookup"><span data-stu-id="27e56-122">Batch AI creates virtual machines on demand with an automatic scaling option, where each node in the Batch AI cluster runs a scoring job for a specific sensor.</span></span> <span data-ttu-id="27e56-123">A pontozó Python [parancsfájl] [ python-script] fut, a fürt, ahol a megfelelő érzékelőktől kapott adatok beolvasása, állít elő, előrejelzéseket és a Blob storage-ban tárolja azokat minden egyes csomóponton létrehozott Docker-tárolókat.</span><span class="sxs-lookup"><span data-stu-id="27e56-123">The scoring Python [script][python-script] runs in Docker containers that are created on each node of the cluster, where it reads the relevant sensor data, generates predictions and stores them in Blob storage.</span></span>

<span data-ttu-id="27e56-124">[Az Azure Blob Storage][storage].</span><span class="sxs-lookup"><span data-stu-id="27e56-124">[Azure Blob Storage][storage].</span></span> <span data-ttu-id="27e56-125">BLOB-tárolók a pretrained modellek, az adatok és a kimeneti előrejelzéseket tárolására szolgálnak.</span><span class="sxs-lookup"><span data-stu-id="27e56-125">Blob containers are used to store the pretrained models, the data, and the output predictions.</span></span> <span data-ttu-id="27e56-126">A modellek töltődnek fel a Blob storage-ban a [létrehozása\_resources.ipynb] [ create-resources] notebookot.</span><span class="sxs-lookup"><span data-stu-id="27e56-126">The models are uploaded to Blob storage in the [create\_resources.ipynb][create-resources] notebook.</span></span> <span data-ttu-id="27e56-127">Ezek [egy szintű SVM] [ one-class-svm] modellek képzett különböző eszközök eltérő érzékelők értéket jelölő adatokon.</span><span class="sxs-lookup"><span data-stu-id="27e56-127">These [one-class SVM][one-class-svm] models are trained on data that represents values of different sensors for different devices.</span></span> <span data-ttu-id="27e56-128">Ez a megoldás feltételezi, hogy az adatértékek vannak időszakra vonatkozó összesített érték egy rögzített idő.</span><span class="sxs-lookup"><span data-stu-id="27e56-128">This solution assumes that the data values are aggregated over a fixed interval of time.</span></span>

<span data-ttu-id="27e56-129">[Az Azure Logic Apps][logic-apps].</span><span class="sxs-lookup"><span data-stu-id="27e56-129">[Azure Logic Apps][logic-apps].</span></span> <span data-ttu-id="27e56-130">Ez a megoldás létrehoz egy logikai alkalmazást, amely a Batch AI-feladatok óránként fut.</span><span class="sxs-lookup"><span data-stu-id="27e56-130">This solution creates a Logic App that runs hourly Batch AI jobs.</span></span> <span data-ttu-id="27e56-131">A Logic Apps segítségével egyszerűen hozhat létre a munkafolyamat futásidejű és az ütemezés a megoldás.</span><span class="sxs-lookup"><span data-stu-id="27e56-131">Logic Apps provides an easy way to create the runtime workflow and scheduling for the solution.</span></span> <span data-ttu-id="27e56-132">A Batch AI-feladatok elküldése a Python használatával [parancsfájl] [ script] futtató Docker-tárolóban.</span><span class="sxs-lookup"><span data-stu-id="27e56-132">The Batch AI jobs are submitted using a Python [script][script] that also runs in a Docker container.</span></span>

<span data-ttu-id="27e56-133">[Az Azure Container Registry][acr].</span><span class="sxs-lookup"><span data-stu-id="27e56-133">[Azure Container Registry][acr].</span></span> <span data-ttu-id="27e56-134">Docker-rendszerképek a Batch AI és a Logic Apps használja, és hozza létre a rendszer a [létrehozása\_resources.ipynb] [ create-resources] jegyzetfüzet, majd leküldte a tárolójegyzékbe.</span><span class="sxs-lookup"><span data-stu-id="27e56-134">Docker images are used in both Batch AI and Logic Apps and are created in the [create\_resources.ipynb][create-resources] notebook, then pushed to Container Registry.</span></span> <span data-ttu-id="27e56-135">Ez a képek üzemeltethet, és hozza létre a tárolók más Azure-szolgáltatásokon keresztül kényelmes módot biztosít – a Logic Apps és a Batch AI ebben a megoldásban.</span><span class="sxs-lookup"><span data-stu-id="27e56-135">This provides a convenient way to host images and instantiate containers through other Azure services—Logic Apps and Batch AI in this solution.</span></span>

## <a name="performance-considerations"></a><span data-ttu-id="27e56-136">A teljesítménnyel kapcsolatos megfontolások</span><span class="sxs-lookup"><span data-stu-id="27e56-136">Performance considerations</span></span>

<span data-ttu-id="27e56-137">Standard Python-modellek általánosan elfogadott, hogy a processzorok elegendőek a számítási feladatok kezelésére.</span><span class="sxs-lookup"><span data-stu-id="27e56-137">For standard Python models, it's generally accepted that CPUs are sufficient to handle the workload.</span></span> <span data-ttu-id="27e56-138">Ez az architektúra processzorokat használ.</span><span class="sxs-lookup"><span data-stu-id="27e56-138">This architecture uses CPUs.</span></span> <span data-ttu-id="27e56-139">Azonban a [mély tanulási célú számítási feladatokhoz][deep], gpu-k általában teljesítményben felülmúlják CPU jelentős szerint – processzorok marketingre fürt általában szükség hasonló teljesítmény eléréséhez.</span><span class="sxs-lookup"><span data-stu-id="27e56-139">However, for [deep learning workloads][deep], GPUs generally outperform CPUs by a considerable amount—a sizeable cluster of CPUs is usually needed to get comparable performance.</span></span>

### <a name="parallelizing-across-vms-vs-cores"></a><span data-ttu-id="27e56-140">Virtuális gépek és magok közötti párhuzamosan futtatni</span><span class="sxs-lookup"><span data-stu-id="27e56-140">Parallelizing across VMs vs cores</span></span>

<span data-ttu-id="27e56-141">Futó folyamatok sok modellek pontozása kötegelt módban, a feladatok kell példánylista méretezésnek megfelelően.</span><span class="sxs-lookup"><span data-stu-id="27e56-141">When running scoring processes of many models in batch mode, the jobs need to be parallelized across VMs.</span></span> <span data-ttu-id="27e56-142">Két módszer is lehetséges:</span><span class="sxs-lookup"><span data-stu-id="27e56-142">Two approaches are possible:</span></span>

* <span data-ttu-id="27e56-143">Hozzon létre egy nagyobb fürt alacsony költségű virtuális gépek használatával.</span><span class="sxs-lookup"><span data-stu-id="27e56-143">Create a larger cluster using low-cost VMs.</span></span>

* <span data-ttu-id="27e56-144">Hozzon létre egy kisebb fürtöt magas végez az egyes elérhető több maggal rendelkező virtuális gépeket.</span><span class="sxs-lookup"><span data-stu-id="27e56-144">Create a smaller cluster using high performing VMs with more cores available on each.</span></span>

<span data-ttu-id="27e56-145">Általánosságban véve standard Python-modell pontozása nem az erőforrás-igényű, deep learning-modellek pontozása, és egy kisebb fürtöt tudja hatékonyan kezelni a sorban álló modellek nagy számú kell lennie.</span><span class="sxs-lookup"><span data-stu-id="27e56-145">In general, scoring of standard Python models is not as demanding as scoring of deep learning models, and a small cluster should be able to handle a large number of queued models efficiently.</span></span> <span data-ttu-id="27e56-146">Növelheti a fürt csomópontok méretei dataset növekedésének megfelelően.</span><span class="sxs-lookup"><span data-stu-id="27e56-146">You can increase the number of cluster nodes as the dataset sizes increase.</span></span>

<span data-ttu-id="27e56-147">Az ebben a forgatókönyvben az egyszerűség kedvéért egy pontozási tevékenység belül küldte el egy Batch AI-feladat.</span><span class="sxs-lookup"><span data-stu-id="27e56-147">For convenience in this scenario, one scoring task is submitted within a single Batch AI job.</span></span> <span data-ttu-id="27e56-148">Azonban érdemes lehet hatékonyabb, ha egy Batch AI feladaton belül több adattömbök pontozása.</span><span class="sxs-lookup"><span data-stu-id="27e56-148">However, it can be more efficient to score multiple data chunks within the same Batch AI job.</span></span> <span data-ttu-id="27e56-149">Ezekben az esetekben több adatkészlet olvasása és azok számára egy egy Batch AI-feladat végrehajtása során, a pontozó szkript végrehajtása egyéni kód írása.</span><span class="sxs-lookup"><span data-stu-id="27e56-149">In those cases, write custom code to read in multiple datasets and execute the scoring script for those during a single Batch AI job execution.</span></span>

### <a name="file-servers"></a><span data-ttu-id="27e56-150">Fájlkiszolgálók</span><span class="sxs-lookup"><span data-stu-id="27e56-150">File servers</span></span>

<span data-ttu-id="27e56-151">Batch AI használata esetén kiválaszthatja a forgatókönyvhöz szükséges átviteli függően többféle tárolási lehetőség.</span><span class="sxs-lookup"><span data-stu-id="27e56-151">When using Batch AI, you can choose multiple storage options depending on the throughput needed for your scenario.</span></span> <span data-ttu-id="27e56-152">Az alacsony átviteli sebességet megkövetelő számítási feladatokhoz a blob storage használatával kell lennie elegendő.</span><span class="sxs-lookup"><span data-stu-id="27e56-152">For workloads with low throughput requirements, using blob storage should be enough.</span></span> <span data-ttu-id="27e56-153">Másik lehetőségként a Batch AI is támogatja a [Batch AI-fájlkiszolgáló][bai-file-server], egy felügyelt, egycsomópontos NFS, amely automatikusan csatlakoztathatók a fürtcsomópontokon, adja meg a központilag elérhető tárolási helye feladatok.</span><span class="sxs-lookup"><span data-stu-id="27e56-153">Alternatively, Batch AI also supports a [Batch AI File Server][bai-file-server], a managed, single-node NFS, which can be automatically mounted on cluster nodes to provide a centrally accessible storage location for jobs.</span></span> <span data-ttu-id="27e56-154">A legtöbb esetben csak egy fájlkiszolgáló van szükség a munkaterületen, és meg is szét az adatokat a betanítási feladatokhoz más könyvtárban.</span><span class="sxs-lookup"><span data-stu-id="27e56-154">For most cases, only one file server is needed in a workspace, and you can separate data for your training jobs into different directories.</span></span>

<span data-ttu-id="27e56-155">Ha egy egycsomópontos NFS nem megfelelő, a számítási feladatokhoz, Batch AI támogatja-e más tárolási lehetőségeket, ideértve [Azure Files] [ azure-files] és egyéni megoldások, például egy Gluster vagy Lustre fájlrendszer.</span><span class="sxs-lookup"><span data-stu-id="27e56-155">If a single-node NFS isn't appropriate for your workloads, Batch AI supports other storage options, including [Azure Files][azure-files] and custom solutions such as a Gluster or Lustre file system.</span></span>

## <a name="management-considerations"></a><span data-ttu-id="27e56-156">Eszközkezeléssel kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="27e56-156">Management considerations</span></span>

### <a name="monitoring-batch-ai-jobs"></a><span data-ttu-id="27e56-157">Batch AI-feladatok figyelése</span><span class="sxs-lookup"><span data-stu-id="27e56-157">Monitoring Batch AI jobs</span></span>

<span data-ttu-id="27e56-158">Fontos, hogy a futó feladatok előrehaladásának figyeléséhez, de azt az aktív csomópontból álló fürtben figyelése kihívást jelenthet.</span><span class="sxs-lookup"><span data-stu-id="27e56-158">It's important to monitor the progress of running jobs, but it can be a challenge to monitor across a cluster of active nodes.</span></span> <span data-ttu-id="27e56-159">Megtapasztalhatja, a fürt általános állapotát, nyissa meg a **Batch AI** paneljén a [az Azure Portal] [ portal] vizsgálhatja meg a fürt csomópontjainak állapotát.</span><span class="sxs-lookup"><span data-stu-id="27e56-159">To get a sense of the overall state of the cluster, go to the **Batch AI** blade of the [Azure Portal][portal] to inspect the state of the nodes in the cluster.</span></span> <span data-ttu-id="27e56-160">Ha egy csomópont nem aktív, vagy egy feladat sikertelen volt, a hibanaplókat menti, és a blob storage-, és szintén elérhető az **feladatok** a portál panelén.</span><span class="sxs-lookup"><span data-stu-id="27e56-160">If a node is inactive or a job has failed, the error logs are saved to blob storage, and are also accessible in the **Jobs** blade of the portal.</span></span>

<span data-ttu-id="27e56-161">Gazdagabb figyelés csatlakozzon a naplók [Application Insights][ai], vagy a Batch AI-fürtöt és a feladatok állapotának lekérdezéséhez külön folyamatok futtatásához.</span><span class="sxs-lookup"><span data-stu-id="27e56-161">For richer monitoring, connect logs to [Application Insights][ai], or run separate processes to poll for the state of the Batch AI cluster and its jobs.</span></span>

### <a name="logging-in-batch-ai"></a><span data-ttu-id="27e56-162">A Batch AI-naplózás</span><span class="sxs-lookup"><span data-stu-id="27e56-162">Logging in Batch AI</span></span>

<span data-ttu-id="27e56-163">A Batch AI minden stdout/stderr naplók társított Azure storage-fiókhoz.</span><span class="sxs-lookup"><span data-stu-id="27e56-163">Batch AI logs all stdout/stderr to the associated Azure storage account.</span></span> <span data-ttu-id="27e56-164">Egyszerűen megtalálható a naplófájlok, használja a tárolók navigációs eszköz például [Azure Storage Explorer][explorer].</span><span class="sxs-lookup"><span data-stu-id="27e56-164">For easy navigation of the log files, use a storage navigation tool such as [Azure Storage Explorer][explorer].</span></span>

<span data-ttu-id="27e56-165">Ez a referenciaarchitektúra telepítésekor lehetősége van egy egyszerűbb naplózási rendszer beállításához.</span><span class="sxs-lookup"><span data-stu-id="27e56-165">When you deploy this reference architecture, you have the option to set up a simpler logging system.</span></span> <span data-ttu-id="27e56-166">Ezzel a beállítással a különböző feladatok között a naplók ugyanabba a könyvtárba, a blob-tárolóban, ahogy az alábbi lesznek mentve.</span><span class="sxs-lookup"><span data-stu-id="27e56-166">With this option, all the logs across the different jobs are saved to the same directory in your blob container as shown below.</span></span> <span data-ttu-id="27e56-167">Ezek a naplók segítségével figyelheti, mennyi ideig tart minden egyes rendszerképek és feldolgozni, így jobban érti, hogyan optimalizálható a folyamat.</span><span class="sxs-lookup"><span data-stu-id="27e56-167">Use these logs to monitor how long it takes for each job and each image to process, so you have a better sense of how to optimize the process.</span></span>

![Azure Storage Explorer](./_images/batch-scoring-python-monitor.png)

## <a name="cost-considerations"></a><span data-ttu-id="27e56-169">Költségekkel kapcsolatos szempontok</span><span class="sxs-lookup"><span data-stu-id="27e56-169">Cost considerations</span></span>

<span data-ttu-id="27e56-170">Ez a referenciaarchitektúra a használt legköltségesebb összetevői a számítási erőforrásokat.</span><span class="sxs-lookup"><span data-stu-id="27e56-170">The most expensive components used in this reference architecture are the compute resources.</span></span>

<span data-ttu-id="27e56-171">A Batch AI-fürt mérete méretezhető felfelé és lefelé a várólistában a feladatok függően.</span><span class="sxs-lookup"><span data-stu-id="27e56-171">The Batch AI cluster size scales up and down depending on the jobs in the queue.</span></span> <span data-ttu-id="27e56-172">Engedélyezheti a [automatikus skálázást] [ automatic-scaling] a Batch AI és a két módszer egyikével.</span><span class="sxs-lookup"><span data-stu-id="27e56-172">You can enable [automatic scaling][automatic-scaling] with Batch AI in one of two ways.</span></span> <span data-ttu-id="27e56-173">Megteheti szoftveresen, amely konfigurálható a .env fájlban, amely része a [üzembe helyezési lépések][github], vagy a fürt létrehozása után módosíthatja a méretezési képletet közvetlenül a portálon.</span><span class="sxs-lookup"><span data-stu-id="27e56-173">You can do so programmatically, which can be configured in the .env file that is part of the [deployment steps][github], or you can change the scale formula directly in the portal after the cluster is created.</span></span>

<span data-ttu-id="27e56-174">És nem igényel azonnali feldolgozási munka konfigurálja az automatikus skálázási képletet, hogy az alapértelmezett állapot (minimum) az nulla csomópontból álló fürtben.</span><span class="sxs-lookup"><span data-stu-id="27e56-174">For work that doesn't require immediate processing, configure the automatic scaling formula so the default state (minimum) is a cluster of zero nodes.</span></span> <span data-ttu-id="27e56-175">Ezzel a konfigurációval a fürt nullára a csomópontok kezdődik, és ha a várólistán lévő feladatok csak felskálázással.</span><span class="sxs-lookup"><span data-stu-id="27e56-175">With this configuration, the cluster starts with zero nodes and only scales up when it detects jobs in the queue.</span></span> <span data-ttu-id="27e56-176">Ha a kötegelt pontozási folyamat csak néhány alkalommal naponta történik vagy annál kisebb, ez a beállítás lehetővé teszi, hogy jelentős költségmegtakarítást.</span><span class="sxs-lookup"><span data-stu-id="27e56-176">If the batch scoring process only happens a few times a day or less, this setting enables significant cost savings.</span></span>

<span data-ttu-id="27e56-177">Az automatikus skálázás nem lehet megfelelő, a kötegelt feladatok számához egymáshoz közel túl fordulhat elő.</span><span class="sxs-lookup"><span data-stu-id="27e56-177">Automatic scaling may not be appropriate for batch jobs that happen too close to each other.</span></span> <span data-ttu-id="27e56-178">A fürt számára le üzemeltethet a idejét is költségkezelési, így ha egy batch számítási feladatot csak néhány percet az előző feladat befejezése után kezdődik, költséghatékonyabb tartani a fürtön futó feladatok között lehet.</span><span class="sxs-lookup"><span data-stu-id="27e56-178">The time that it takes for a cluster to spin up and spin down also incur a cost, so if a batch workload begins only a few minutes after the previous job ends, it might be more cost effective to keep the cluster running between jobs.</span></span> <span data-ttu-id="27e56-179">E pontozási folyamatokat beütemezve egy nagy gyakoriságú (például minden órában), vagy ritkábban függ (például havonta egyszer).</span><span class="sxs-lookup"><span data-stu-id="27e56-179">That depends on whether scoring processes are scheduled to run at a high frequency (every hour, for example), or less frequently (once a month, for example).</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="27e56-180">A megoldás üzembe helyezése</span><span class="sxs-lookup"><span data-stu-id="27e56-180">Deploy the solution</span></span>

<span data-ttu-id="27e56-181">A referenciaimplementációt a jelen architektúra érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="27e56-181">The reference implementation of this architecture is available on [GitHub][github].</span></span> <span data-ttu-id="27e56-182">Kövesse a beállítási lépéseket nem hozhat létre egy méretezhető megoldás, sok modellek pontozó a Batch AI segítségével párhuzamosan.</span><span class="sxs-lookup"><span data-stu-id="27e56-182">Follow the setup steps there to build a scalable solution for scoring many models in parallel using Batch AI.</span></span>

[acr]: /azure/container-registry/container-registry-intro
[ai]: /azure/application-insights/app-insights-overview
[automatic-scaling]: /azure/batch/batch-automatic-scaling
[azure-files]: /azure/storage/files/storage-files-introduction
[batch-ai]: /azure/batch-ai/
[bai-file-server]: /azure/batch-ai/resource-concepts#file-server
[create-resources]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/create_resources.ipynb
[deep]: /azure/architecture/reference-architectures/ai/batch-scoring-deep-learning
[event-hubs]: /azure/event-hubs/event-hubs-geo-dr
[explorer]: https://azure.microsoft.com/en-us/features/storage-explorer/
[github]: https://github.com/Azure/BatchAIAnomalyDetection
[logic-apps]: /azure/logic-apps/logic-apps-overview
[one-class-svm]: http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
[portal]: https://portal.azure.com
[python-script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/batchai/predict.py
[script]: https://github.com/Azure/BatchAIAnomalyDetection/blob/master/sched/submit_jobs.py
[storage]: /azure/storage/blobs/storage-blobs-overview
[stream-analytics]: /azure/stream-analytics/
