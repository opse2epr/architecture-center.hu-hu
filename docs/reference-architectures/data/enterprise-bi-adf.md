---
title: Automatizált vállalati üzleti intelligenciát (BI)
titleSuffix: Azure Reference Architectures
description: Egy kinyerési, betöltési és átalakítási (ELT) munkafolyamat az Azure-ban az Azure Data Factory használatával az SQL Data Warehouse szolgáltatással automatizálhatja.
author: MikeWasson
ms.date: 11/06/2018
ms.topic: reference-architecture
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: seodec18
ms.openlocfilehash: d52d2a323727760463c0b5694b9116e0ed469c93
ms.sourcegitcommit: c053e6edb429299a0ad9b327888d596c48859d4a
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 03/20/2019
ms.locfileid: "58298890"
---
# <a name="automated-enterprise-bi-with-sql-data-warehouse-and-azure-data-factory"></a><span data-ttu-id="030d5-103">Az SQL Data Warehouse és az Azure Data Factory automatizált vállalati bi-ban</span><span class="sxs-lookup"><span data-stu-id="030d5-103">Automated enterprise BI with SQL Data Warehouse and Azure Data Factory</span></span>

<span data-ttu-id="030d5-104">Ez a referenciaarchitektúra bemutatja, hogyan hajthat végre a növekményes betöltése egy [kinyerése, betöltése és átalakítási (ELT)](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) folyamat.</span><span class="sxs-lookup"><span data-stu-id="030d5-104">This reference architecture shows how to perform incremental loading in an [extract, load, and transform (ELT)](../../data-guide/relational-data/etl.md#extract-load-and-transform-elt) pipeline.</span></span> <span data-ttu-id="030d5-105">Azure Data Factory használatával az ELT folyamatok automatizálásához.</span><span class="sxs-lookup"><span data-stu-id="030d5-105">It uses Azure Data Factory to automate the ELT pipeline.</span></span> <span data-ttu-id="030d5-106">A folyamat növekményes helyezi át a legújabb OLTP adatokat a helyszíni SQL Server-adatbázisból az SQL Data Warehouse-bA.</span><span class="sxs-lookup"><span data-stu-id="030d5-106">The pipeline incrementally moves the latest OLTP data from an on-premises SQL Server database into SQL Data Warehouse.</span></span> <span data-ttu-id="030d5-107">Tranzakciós adatok átalakításának egy táblázatos modell elemzés céljából.</span><span class="sxs-lookup"><span data-stu-id="030d5-107">Transactional data is transformed into a tabular model for analysis.</span></span>

<!-- markdownlint-disable MD034 -->

> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE2Gnz2]

<!-- markdownlint-enable MD034 -->

<span data-ttu-id="030d5-108">Az architektúra egy referenciaimplementációt érhető el az [GitHub][github].</span><span class="sxs-lookup"><span data-stu-id="030d5-108">A reference implementation for this architecture is available on [GitHub][github].</span></span>

![Az SQL Data Warehouse és az Azure Data Factory automatizált vállalati BI architektúra diagramja](./images/enterprise-bi-sqldw-adf.png)

<span data-ttu-id="030d5-110">Ez az architektúra épít látható [Enterprise BI és az SQL Data Warehouse](./enterprise-bi-sqldw.md), de bizonyos funkciók, fontos vállalati adatraktározási forgatókönyvekben.</span><span class="sxs-lookup"><span data-stu-id="030d5-110">This architecture builds on the one shown in [Enterprise BI with SQL Data Warehouse](./enterprise-bi-sqldw.md), but adds some features that are important for enterprise data warehousing scenarios.</span></span>

- <span data-ttu-id="030d5-111">Automation használatával a Data Factory-folyamatot.</span><span class="sxs-lookup"><span data-stu-id="030d5-111">Automation of the pipeline using Data Factory.</span></span>
- <span data-ttu-id="030d5-112">Növekményes betöltés.</span><span class="sxs-lookup"><span data-stu-id="030d5-112">Incremental loading.</span></span>
- <span data-ttu-id="030d5-113">Több adatforrás integrálásával.</span><span class="sxs-lookup"><span data-stu-id="030d5-113">Integrating multiple data sources.</span></span>
- <span data-ttu-id="030d5-114">Bináris adatot, például térinformatikai adatok és lemezképek betöltése.</span><span class="sxs-lookup"><span data-stu-id="030d5-114">Loading binary data such as geospatial data and images.</span></span>

## <a name="architecture"></a><span data-ttu-id="030d5-115">Architektúra</span><span class="sxs-lookup"><span data-stu-id="030d5-115">Architecture</span></span>

<span data-ttu-id="030d5-116">Az architektúra a következőkben leírt összetevőkből áll.</span><span class="sxs-lookup"><span data-stu-id="030d5-116">The architecture consists of the following components.</span></span>

### <a name="data-sources"></a><span data-ttu-id="030d5-117">Adatforrások</span><span class="sxs-lookup"><span data-stu-id="030d5-117">Data sources</span></span>

<span data-ttu-id="030d5-118">**A helyszíni SQL Server**.</span><span class="sxs-lookup"><span data-stu-id="030d5-118">**On-premises SQL Server**.</span></span> <span data-ttu-id="030d5-119">Az adatok helyszíni SQL Server-adatbázis található.</span><span class="sxs-lookup"><span data-stu-id="030d5-119">The source data is located in a SQL Server database on premises.</span></span> <span data-ttu-id="030d5-120">A helyszíni környezetben, az architektúra üzembe helyezése az Azure-ban telepített SQL Server virtuális gép üzembe helyezési szkriptjei szimulálásához.</span><span class="sxs-lookup"><span data-stu-id="030d5-120">To simulate the on-premises environment, the deployment scripts for this architecture provision a virtual machine in Azure with SQL Server installed.</span></span> <span data-ttu-id="030d5-121">A [Wide World Importers OLTP mintaadatbázis] [ wwi] a forrásadatbázis szolgál.</span><span class="sxs-lookup"><span data-stu-id="030d5-121">The [Wide World Importers OLTP sample database][wwi] is used as the source database.</span></span>

<span data-ttu-id="030d5-122">**Külső adatok**.</span><span class="sxs-lookup"><span data-stu-id="030d5-122">**External data**.</span></span> <span data-ttu-id="030d5-123">Adattárházak gyakran előfordul, hogy több adatforrás integrálhatja.</span><span class="sxs-lookup"><span data-stu-id="030d5-123">A common scenario for data warehouses is to integrate multiple data sources.</span></span> <span data-ttu-id="030d5-124">Ez a referenciaarchitektúra egy külső adatkészlet, amely tartalmazza a város feltöltések évek szerint, és integrálja az OLTP adatbázis adataival tölti be.</span><span class="sxs-lookup"><span data-stu-id="030d5-124">This reference architecture loads an external data set that contains city populations by year, and integrates it with the data from the OLTP database.</span></span> <span data-ttu-id="030d5-125">Insights például használhatja ezeket az adatokat: "Nem minden régióban eladások növekedési nagyobb vagy népességnövekedés?"</span><span class="sxs-lookup"><span data-stu-id="030d5-125">You can use this data for insights such as: "Does sales growth in each region match or exceed population growth?"</span></span>

### <a name="ingestion-and-data-storage"></a><span data-ttu-id="030d5-126">Adatfeldolgozási és az adatok tárolása</span><span class="sxs-lookup"><span data-stu-id="030d5-126">Ingestion and data storage</span></span>

<span data-ttu-id="030d5-127">**A BLOB Storage-**.</span><span class="sxs-lookup"><span data-stu-id="030d5-127">**Blob Storage**.</span></span> <span data-ttu-id="030d5-128">A BLOB storage lesz egy átmeneti területre a forrásadatok mielőtt betöltené azokat az SQL Data Warehouse-bA.</span><span class="sxs-lookup"><span data-stu-id="030d5-128">Blob storage is used as a staging area for the source data before loading it into SQL Data Warehouse.</span></span>

<span data-ttu-id="030d5-129">**Azure SQL Data Warehouse**.</span><span class="sxs-lookup"><span data-stu-id="030d5-129">**Azure SQL Data Warehouse**.</span></span> <span data-ttu-id="030d5-130">[Az SQL Data Warehouse](/azure/sql-data-warehouse/) egy elosztott rendszer analytics végre, a nagy mennyiségű adat.</span><span class="sxs-lookup"><span data-stu-id="030d5-130">[SQL Data Warehouse](/azure/sql-data-warehouse/) is a distributed system designed to perform analytics on large data.</span></span> <span data-ttu-id="030d5-131">Támogatja a nagy olyan párhuzamos feldolgozási (MPP), épp ezért kiválóan alkalmas nagy teljesítményű elemzési futtatásához.</span><span class="sxs-lookup"><span data-stu-id="030d5-131">It supports massive parallel processing (MPP), which makes it suitable for running high-performance analytics.</span></span>

<span data-ttu-id="030d5-132">**Az Azure Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="030d5-132">**Azure Data Factory**.</span></span> <span data-ttu-id="030d5-133">[A Data Factory] [ adf] egy felügyelt szolgáltatás, amellyel előkészíthető és automatizálható az adatok áthelyezését és átalakítását.</span><span class="sxs-lookup"><span data-stu-id="030d5-133">[Data Factory][adf] is a managed service that orchestrates and automates data movement and data transformation.</span></span> <span data-ttu-id="030d5-134">Ebben az architektúrában koordinálja a ELT folyamat különböző szakaszaiban.</span><span class="sxs-lookup"><span data-stu-id="030d5-134">In this architecture, it coordinates the various stages of the ELT process.</span></span>

### <a name="analysis-and-reporting"></a><span data-ttu-id="030d5-135">Elemzés és jelentéskészítés</span><span class="sxs-lookup"><span data-stu-id="030d5-135">Analysis and reporting</span></span>

<span data-ttu-id="030d5-136">**Az Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="030d5-136">**Azure Analysis Services**.</span></span> <span data-ttu-id="030d5-137">[Analysis Services](/azure/analysis-services/) egy teljes körűen felügyelt szolgáltatás, amely adatmodellezési képességekkel.</span><span class="sxs-lookup"><span data-stu-id="030d5-137">[Analysis Services](/azure/analysis-services/) is a fully managed service that provides data modeling capabilities.</span></span> <span data-ttu-id="030d5-138">A szemantikai modell betöltött Analysis Services.</span><span class="sxs-lookup"><span data-stu-id="030d5-138">The semantic model is loaded into Analysis Services.</span></span>

<span data-ttu-id="030d5-139">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="030d5-139">**Power BI**.</span></span> <span data-ttu-id="030d5-140">A Power BI egy üzleti elemzési eszközök az üzleti elemzések készítése adatelemzéshez együttese.</span><span class="sxs-lookup"><span data-stu-id="030d5-140">Power BI is a suite of business analytics tools to analyze data for business insights.</span></span> <span data-ttu-id="030d5-141">Ebben az architektúrában a szemantikai modell az Analysis Servicesben tárolt kérdezi le.</span><span class="sxs-lookup"><span data-stu-id="030d5-141">In this architecture, it queries the semantic model stored in Analysis Services.</span></span>

### <a name="authentication"></a><span data-ttu-id="030d5-142">Hitelesítés</span><span class="sxs-lookup"><span data-stu-id="030d5-142">Authentication</span></span>

<span data-ttu-id="030d5-143">**Az Azure Active Directory** (Azure AD) hitelesíti a felhasználók, akik a Power bi-ban az Analysis Services-kiszolgálóhoz csatlakozhat.</span><span class="sxs-lookup"><span data-stu-id="030d5-143">**Azure Active Directory** (Azure AD) authenticates users who connect to the Analysis Services server through Power BI.</span></span>

<span data-ttu-id="030d5-144">A Data Factory használatával is az Azure AD hitelesítése az SQL Data Warehouse, egy szolgáltatásnév vagy a Felügyeltszolgáltatás-identitás (MSI).</span><span class="sxs-lookup"><span data-stu-id="030d5-144">Data Factory can use also use Azure AD to authenticate to SQL Data Warehouse, by using a service principal or Managed Service Identity (MSI).</span></span> <span data-ttu-id="030d5-145">Az egyszerűség kedvéért a központi telepítésre példát az SQL Server-hitelesítést használ.</span><span class="sxs-lookup"><span data-stu-id="030d5-145">For simplicity, the example deployment uses SQL Server authentication.</span></span>

## <a name="data-pipeline"></a><span data-ttu-id="030d5-146">Adatfolyamat</span><span class="sxs-lookup"><span data-stu-id="030d5-146">Data pipeline</span></span>

<span data-ttu-id="030d5-147">A [Azure Data Factory][adf], egy folyamatot a feladat koordinálja a tevékenységek logikus csoportosításai egy &mdash; ebben az esetben be- és az adatok átalakítása az SQL Data Warehouse-bA.</span><span class="sxs-lookup"><span data-stu-id="030d5-147">In [Azure Data Factory][adf], a pipeline is a logical grouping of activities used to coordinate a task &mdash; in this case, loading and transforming data into SQL Data Warehouse.</span></span>

<span data-ttu-id="030d5-148">Ez a referenciaarchitektúra egy fő folyamatot, amely gyermek folyamatok sorozatát futtatja határozza meg.</span><span class="sxs-lookup"><span data-stu-id="030d5-148">This reference architecture defines a master pipeline that runs a sequence of child pipelines.</span></span> <span data-ttu-id="030d5-149">Minden egyes gyermek folyamat adatokat tölt be egy vagy több adattárház táblái.</span><span class="sxs-lookup"><span data-stu-id="030d5-149">Each child pipeline loads data into one or more data warehouse tables.</span></span>

![Képernyőkép az Azure Data Factory-folyamatot](./images/adf-pipeline.png)

## <a name="incremental-loading"></a><span data-ttu-id="030d5-151">Növekményes betöltés</span><span class="sxs-lookup"><span data-stu-id="030d5-151">Incremental loading</span></span>

<span data-ttu-id="030d5-152">Automatikus ETL vagy ELT folyamat futtatásakor a leghatékonyabb csak, mivel az előző futtatása az adatok betöltéséhez.</span><span class="sxs-lookup"><span data-stu-id="030d5-152">When you run an automated ETL or ELT process, it's most efficient to load only the data that changed since the previous run.</span></span> <span data-ttu-id="030d5-153">Ezt nevezzük egy *növekményes betöltés*, és ne pedig a teljes terhelés, az adatok betöltésekor.</span><span class="sxs-lookup"><span data-stu-id="030d5-153">This is called an *incremental load*, as opposed to a full load that loads all of the data.</span></span> <span data-ttu-id="030d5-154">Egy növekményes betöltési végrehajtásához kell azonosítani tudja, mely adatok módosultak.</span><span class="sxs-lookup"><span data-stu-id="030d5-154">To perform an incremental load, you need a way to identify which data has changed.</span></span> <span data-ttu-id="030d5-155">A leggyakrabban használt módszer az, hogy használjon egy *magas vízjelbe beleszámított* érték, ami azt jelenti, hogy nyomon követése a legújabb értékeket néhány oszlop a forrástábla, vagy egy dátum-idő oszlop, vagy egy egyedi egész számokat tartalmazó oszlopot.</span><span class="sxs-lookup"><span data-stu-id="030d5-155">The most common approach is to use a *high water mark* value, which means tracking the latest value of some column in the source table, either a datetime column or a unique integer column.</span></span>

<span data-ttu-id="030d5-156">Az SQL Server 2016 kezdve használhatja [időbeli verziózású táblák](/sql/relational-databases/tables/temporal-tables).</span><span class="sxs-lookup"><span data-stu-id="030d5-156">Starting with SQL Server 2016, you can use [temporal tables](/sql/relational-databases/tables/temporal-tables).</span></span> <span data-ttu-id="030d5-157">Ezek a rendszerverzióval ellátott táblákon, hogy az adatok teljes előzményeit.</span><span class="sxs-lookup"><span data-stu-id="030d5-157">These are system-versioned tables that keep a full history of data changes.</span></span> <span data-ttu-id="030d5-158">Az adatbázismotor automatikusan rögzíti a külön előzménytábla minden módosítási előzményeit.</span><span class="sxs-lookup"><span data-stu-id="030d5-158">The database engine automatically records the history of every change in a separate history table.</span></span> <span data-ttu-id="030d5-159">Az előzményadatok lekérdezheti, ha egy FOR SYSTEM_TIME záradékot ad hozzá egy lekérdezést.</span><span class="sxs-lookup"><span data-stu-id="030d5-159">You can query the historical data by adding a FOR SYSTEM_TIME clause to a query.</span></span> <span data-ttu-id="030d5-160">Belsőleg az adatbázismotor lekérdezi az előzménytáblában, de ez átlátható az alkalmazás.</span><span class="sxs-lookup"><span data-stu-id="030d5-160">Internally, the database engine queries the history table, but this is transparent to the application.</span></span>

> [!NOTE]
> <span data-ttu-id="030d5-161">Az SQL Server korábbi verzióit használhatja [adatváltozás-rögzítési](/sql/relational-databases/track-changes/about-change-data-capture-sql-server) (CDC).</span><span class="sxs-lookup"><span data-stu-id="030d5-161">For earlier versions of SQL Server, you can use [Change Data Capture](/sql/relational-databases/track-changes/about-change-data-capture-sql-server) (CDC).</span></span> <span data-ttu-id="030d5-162">Ez a megközelítés akkor időbeli verziózású táblák,-nál kevesebb kényelmes, mert rendelkezik egy különálló módosítási táblából, és kötetblokkok változásait a napló sorszáma, nem pedig egy időbélyeg.</span><span class="sxs-lookup"><span data-stu-id="030d5-162">This approach is less convenient than temporal tables, because you have to query a separate change table, and changes are tracked by a log sequence number, rather than a timestamp.</span></span>
>

<span data-ttu-id="030d5-163">Historikus táblák dimenzió az adatokat, amelyek idővel hasznosak.</span><span class="sxs-lookup"><span data-stu-id="030d5-163">Temporal tables are useful for dimension data, which can change over time.</span></span> <span data-ttu-id="030d5-164">A ténytáblák általában egy nem módosítható tranzakció, például egy rendelést a táblagépükről, ebben az esetben a rendszer verziójának előzményei tartja értelmetlen képviseli.</span><span class="sxs-lookup"><span data-stu-id="030d5-164">Fact tables usually represent an immutable transaction such as a sale, in which case keeping the system version history doesn't make sense.</span></span> <span data-ttu-id="030d5-165">Ehelyett a tranzakciók általában rendelkeznek egy oszlopot, amely a tranzakció dátuma, amelyek használhatók a küszöbértékek jelöli.</span><span class="sxs-lookup"><span data-stu-id="030d5-165">Instead, transactions usually have a column that represents the transaction date, which can be used as the watermark value.</span></span> <span data-ttu-id="030d5-166">Ha például a Wide World Importers OLTP-adatbázisban, a Sales.Invoices és Sales.InvoiceLines táblát kell egy `LastEditedWhen` mező, amely alapértelmezés szerint a `sysdatetime()`.</span><span class="sxs-lookup"><span data-stu-id="030d5-166">For example, in the Wide World Importers OLTP database, the Sales.Invoices and Sales.InvoiceLines tables have a `LastEditedWhen` field that defaults to `sysdatetime()`.</span></span>

<span data-ttu-id="030d5-167">Itt látható az általános folyamat az ELT folyamatok:</span><span class="sxs-lookup"><span data-stu-id="030d5-167">Here is the general flow for the ELT pipeline:</span></span>

1. <span data-ttu-id="030d5-168">A forrásadatbázis minden táblához nyomon követheti a megszakítási idő, amikor az utolsó ELT feladat futott.</span><span class="sxs-lookup"><span data-stu-id="030d5-168">For each table in the source database, track the cutoff time when the last ELT job ran.</span></span> <span data-ttu-id="030d5-169">Ez az információ Store az adatraktárban.</span><span class="sxs-lookup"><span data-stu-id="030d5-169">Store this information in the data warehouse.</span></span> <span data-ttu-id="030d5-170">(A kezdeti beállítás, minden esetben vannak beállítva: 1-1-1900-hoz ".)</span><span class="sxs-lookup"><span data-stu-id="030d5-170">(On initial setup, all times are set to '1-1-1900'.)</span></span>

2. <span data-ttu-id="030d5-171">Során az adatok exportálása a lépést, a megszakítási idő tárolt eljárások a forrásadatbázis átadott paraméterként.</span><span class="sxs-lookup"><span data-stu-id="030d5-171">During the data export step, the cutoff time is passed as a parameter to a set of stored procedures in the source database.</span></span> <span data-ttu-id="030d5-172">Ezek tárolt eljárások lekérdezést, amelyet a megszakítási idő után létrehozott vagy megváltozott rekordokat.</span><span class="sxs-lookup"><span data-stu-id="030d5-172">These stored procedures query for any records that were changed or created after the cutoff time.</span></span> <span data-ttu-id="030d5-173">A Sales (tény) tábla a `LastEditedWhen` oszlopot használja.</span><span class="sxs-lookup"><span data-stu-id="030d5-173">For the Sales fact table, the `LastEditedWhen` column is used.</span></span> <span data-ttu-id="030d5-174">A dimenzió adatok rendszerverzióval ellátott historikus táblákon szolgálnak.</span><span class="sxs-lookup"><span data-stu-id="030d5-174">For the dimension data, system-versioned temporal tables are used.</span></span>

3. <span data-ttu-id="030d5-175">Ha az adatok migrálása befejeződött, frissítse a tábla tárolja a megszakítási idő.</span><span class="sxs-lookup"><span data-stu-id="030d5-175">When the data migration is complete, update the table that stores the cutoff times.</span></span>

<span data-ttu-id="030d5-176">Emellett akkor is hasznos, jegyezze fel a *leszármaztatási* esetében minden egyes Futtatás ELT.</span><span class="sxs-lookup"><span data-stu-id="030d5-176">It's also useful to record a *lineage* for each ELT run.</span></span> <span data-ttu-id="030d5-177">Egy adott rekord a leszármaztatási társítja, amely az adatok előállított rekordot a ELT, futtassa a.</span><span class="sxs-lookup"><span data-stu-id="030d5-177">For a given record, the lineage associates that record with the ELT run that produced the data.</span></span> <span data-ttu-id="030d5-178">Az egyes ETL futtatások mindegyik táblához, megjeleníti a kezdési és befejezési lapbetöltési idők leszármaztatási új rekord jön létre.</span><span class="sxs-lookup"><span data-stu-id="030d5-178">For each ETL run, a new lineage record is created for every table, showing the starting and ending load times.</span></span> <span data-ttu-id="030d5-179">A leszármaztatási kulcsok minden egyes rekord a dimenzió és a ténytáblákat táblákban tárolódnak.</span><span class="sxs-lookup"><span data-stu-id="030d5-179">The lineage keys for each record are stored in the dimension and fact tables.</span></span>

![Képernyőkép az városa dimenziótábla](./images/city-dimension-table.png)

<span data-ttu-id="030d5-181">Után az adatok egy új batch tölti be az adatraktár, frissítse az Analysis Services táblázatos modellt.</span><span class="sxs-lookup"><span data-stu-id="030d5-181">After a new batch of data is loaded into the warehouse, refresh the Analysis Services tabular model.</span></span> <span data-ttu-id="030d5-182">Lásd: [aszinkron frissítése a REST API-val](/azure/analysis-services/analysis-services-async-refresh).</span><span class="sxs-lookup"><span data-stu-id="030d5-182">See [Asynchronous refresh with the REST API](/azure/analysis-services/analysis-services-async-refresh).</span></span>

## <a name="data-cleansing"></a><span data-ttu-id="030d5-183">Adattisztító</span><span class="sxs-lookup"><span data-stu-id="030d5-183">Data cleansing</span></span>

<span data-ttu-id="030d5-184">Adattisztítás ELT folyamatának részeként kell lennie.</span><span class="sxs-lookup"><span data-stu-id="030d5-184">Data cleansing should be part of the ELT process.</span></span> <span data-ttu-id="030d5-185">Ez a referenciaarchitektúra egy hibás adatforrás a város population táblában, ahol egyes városoknak rendelkezik nulla population például mert nincs adat nem volt elérhető.</span><span class="sxs-lookup"><span data-stu-id="030d5-185">In this reference architecture, one source of bad data is the city population table, where some cities have zero population, perhaps because no data was available.</span></span> <span data-ttu-id="030d5-186">A feldolgozás során az ELT folyamatok eltávolítja a kiválasztott városok az városa population tábla.</span><span class="sxs-lookup"><span data-stu-id="030d5-186">During processing, the ELT pipeline removes those cities from the city population table.</span></span> <span data-ttu-id="030d5-187">Hajtsa végre az előkészítési táblák ahelyett, hogy a külső táblák adattisztító.</span><span class="sxs-lookup"><span data-stu-id="030d5-187">Perform data cleansing on staging tables, rather than external tables.</span></span>

<span data-ttu-id="030d5-188">Íme a tárolt eljárást, amely a várost, a nulla population eltávolítja az városa Population táblából.</span><span class="sxs-lookup"><span data-stu-id="030d5-188">Here is the stored procedure that removes the cities with zero population from the City Population table.</span></span> <span data-ttu-id="030d5-189">(A forrásfájl annak [Itt](https://github.com/mspnp/reference-architectures/blob/master/data/enterprise_bi_sqldw_advanced/azure/sqldw_scripts/citypopulation/%5BIntegration%5D.%5BMigrateExternalCityPopulationData%5D.sql).)</span><span class="sxs-lookup"><span data-stu-id="030d5-189">(You can find the source file [here](https://github.com/mspnp/reference-architectures/blob/master/data/enterprise_bi_sqldw_advanced/azure/sqldw_scripts/citypopulation/%5BIntegration%5D.%5BMigrateExternalCityPopulationData%5D.sql).)</span></span>

```sql
DELETE FROM [Integration].[CityPopulation_Staging]
WHERE RowNumber in (SELECT DISTINCT RowNumber
FROM [Integration].[CityPopulation_Staging]
WHERE POPULATION = 0
GROUP BY RowNumber
HAVING COUNT(RowNumber) = 4)
```

## <a name="external-data-sources"></a><span data-ttu-id="030d5-190">Külső adatforrások</span><span class="sxs-lookup"><span data-stu-id="030d5-190">External data sources</span></span>

<span data-ttu-id="030d5-191">Adattárházak gyakran több forrásból származó adatok egyesíthetők.</span><span class="sxs-lookup"><span data-stu-id="030d5-191">Data warehouses often consolidate data from multiple sources.</span></span> <span data-ttu-id="030d5-192">Ez a referenciaarchitektúra egy külső adatforrás, amely tartalmazza a demográfiai adatokat tölt be.</span><span class="sxs-lookup"><span data-stu-id="030d5-192">This reference architecture loads an external data source that contains demographics data.</span></span> <span data-ttu-id="030d5-193">Ez az adatkészlet érhető el az Azure blob storage-ban részeként a [WorldWideImportersDW](https://github.com/Microsoft/sql-server-samples/tree/master/samples/databases/wide-world-importers/sample-scripts/polybase) minta.</span><span class="sxs-lookup"><span data-stu-id="030d5-193">This dataset is available in Azure blob storage as part of the [WorldWideImportersDW](https://github.com/Microsoft/sql-server-samples/tree/master/samples/databases/wide-world-importers/sample-scripts/polybase) sample.</span></span>

<span data-ttu-id="030d5-194">Az Azure Data Factory másolhatja, közvetlenül a blob storage használatával a [blob storage-összekötő](/azure/data-factory/connector-azure-blob-storage).</span><span class="sxs-lookup"><span data-stu-id="030d5-194">Azure Data Factory can copy directly from blob storage, using the [blob storage connector](/azure/data-factory/connector-azure-blob-storage).</span></span> <span data-ttu-id="030d5-195">Azonban az összekötő számára szükséges kapcsolati karakterlánc vagy közös hozzáférésű jogosultságkódot, így nem használható nyilvános olvasási hozzáférés a blob másolásához.</span><span class="sxs-lookup"><span data-stu-id="030d5-195">However, the connector requires a connection string or a shared access signature, so it can't be used to copy a blob with public read access.</span></span> <span data-ttu-id="030d5-196">Áthidaló megoldásként használhatja a PolyBase külső tábla létrehozása tárt a Blob storage, és másolja a külső táblák az SQL Data Warehouse-bA.</span><span class="sxs-lookup"><span data-stu-id="030d5-196">As a workaround, you can use PolyBase to create an external table over Blob storage and then copy the external tables into SQL Data Warehouse.</span></span>

## <a name="handling-large-binary-data"></a><span data-ttu-id="030d5-197">Nagy méretű bináris adatok kezelése</span><span class="sxs-lookup"><span data-stu-id="030d5-197">Handling large binary data</span></span>

<span data-ttu-id="030d5-198">A forrás-adatbázisban, a városok táblának van egy hely oszlopot tartalmazó egy [földrajzi](/sql/t-sql/spatial-geography/spatial-types-geography) térbeli adatok típusa.</span><span class="sxs-lookup"><span data-stu-id="030d5-198">In the source database, the Cities table has a Location column that holds a [geography](/sql/t-sql/spatial-geography/spatial-types-geography) spatial data type.</span></span> <span data-ttu-id="030d5-199">Az SQL Data Warehouse nem támogatja a **földrajzi** írja be a natív módon, így ez a mező alakítja át egy **varbinary** típus betöltése során.</span><span class="sxs-lookup"><span data-stu-id="030d5-199">SQL Data Warehouse doesn't support the **geography** type natively, so this field is converted to a **varbinary** type during loading.</span></span> <span data-ttu-id="030d5-200">(Lásd: [nem támogatott adattípusok megoldásai](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types#unsupported-data-types).)</span><span class="sxs-lookup"><span data-stu-id="030d5-200">(See [Workarounds for unsupported data types](/azure/sql-data-warehouse/sql-data-warehouse-tables-data-types#unsupported-data-types).)</span></span>

<span data-ttu-id="030d5-201">Azonban a PolyBase támogatja egy oszlop maximális mérete `varbinary(8000)`, ami azt jelenti, hogy néhány adat csonkolódik.</span><span class="sxs-lookup"><span data-stu-id="030d5-201">However, PolyBase supports a maximum column size of `varbinary(8000)`, which means some data could be truncated.</span></span> <span data-ttu-id="030d5-202">A probléma áthidaló felosztása a adatokat adattömbökre exportálás során, és ezután szétbontani módon az adattömböket:</span><span class="sxs-lookup"><span data-stu-id="030d5-202">A workaround for this problem is to break the data up into chunks during export, and then reassemble the chunks, as follows:</span></span>

1. <span data-ttu-id="030d5-203">Hozzon létre egy átmeneti előkészítési táblába, az a hely oszlopban.</span><span class="sxs-lookup"><span data-stu-id="030d5-203">Create a temporary staging table for the Location column.</span></span>

2. <span data-ttu-id="030d5-204">Mindegyik városhoz ossza fel a helyadatok 8000 bájtos adattömböket, ami 1 &ndash; mindegyik városhoz N sorát.</span><span class="sxs-lookup"><span data-stu-id="030d5-204">For each city, split the location data into 8000-byte chunks, resulting in 1 &ndash; N rows for each city.</span></span>

3. <span data-ttu-id="030d5-205">Az adattömbök szétbontani, használja a T-SQL [PIVOT](/sql/t-sql/queries/from-using-pivot-and-unpivot) operátor sorok átalakítása oszlopokat, és majd összefűzi a minden Város oszlop értékeit.</span><span class="sxs-lookup"><span data-stu-id="030d5-205">To reassemble the chunks, use the T-SQL [PIVOT](/sql/t-sql/queries/from-using-pivot-and-unpivot) operator to convert rows into columns and then concatenate the column values for each city.</span></span>

<span data-ttu-id="030d5-206">A kihívás abban áll, hogy minden egyes az városa felosztása egy eltérő mennyiségű sor, a földrajzi adatok méretétől függően.</span><span class="sxs-lookup"><span data-stu-id="030d5-206">The challenge is that each city will be split into a different number of rows, depending on the size of geography data.</span></span> <span data-ttu-id="030d5-207">A PIVOT operátorban működjön minden az városa ugyanannyi sort kell rendelkeznie.</span><span class="sxs-lookup"><span data-stu-id="030d5-207">For the PIVOT operator to work, every city must have the same number of rows.</span></span> <span data-ttu-id="030d5-208">Működnek, a T-SQL-lekérdezés (amelyet meg lehet tekinteni [Itt][MergeLocation]) does néhány trükköket üres értékeket tartalmazó sorok ismételt kitöltésére, hogy minden városhoz azonos számú oszlopot a pivot után.</span><span class="sxs-lookup"><span data-stu-id="030d5-208">To make this work, the T-SQL query (which you can view [here][MergeLocation]) does some tricks to pad out the rows with blank values, so that every city has the same number of columns after the pivot.</span></span> <span data-ttu-id="030d5-209">Az eredményül kapott lekérdezés elemről kiderül, hogy sokkal gyorsabb, mint a sorokat egy ismétlése egyszerre kell.</span><span class="sxs-lookup"><span data-stu-id="030d5-209">The resulting query turns out to be much faster than looping through the rows one at a time.</span></span>

<span data-ttu-id="030d5-210">Ugyanezzel a módszerrel képadatok szolgál.</span><span class="sxs-lookup"><span data-stu-id="030d5-210">The same approach is used for image data.</span></span>

## <a name="slowly-changing-dimensions"></a><span data-ttu-id="030d5-211">Lassan változó dimenzió</span><span class="sxs-lookup"><span data-stu-id="030d5-211">Slowly changing dimensions</span></span>

<span data-ttu-id="030d5-212">Dimenzió adatok viszonylag statikusak, de módosíthatja azt.</span><span class="sxs-lookup"><span data-stu-id="030d5-212">Dimension data is relatively static, but it can change.</span></span> <span data-ttu-id="030d5-213">Termék például egy másik termékkel kategóriához első hozzárendelni.</span><span class="sxs-lookup"><span data-stu-id="030d5-213">For example, a product might get reassigned to a different product category.</span></span> <span data-ttu-id="030d5-214">Nincsenek a lassan változó dimenzió kezelése több megközelítés közül.</span><span class="sxs-lookup"><span data-stu-id="030d5-214">There are several approaches to handling slowly changing dimensions.</span></span> <span data-ttu-id="030d5-215">Egy közös leképezésnek hívott technika [Type 2](https://wikipedia.org/wiki/Slowly_changing_dimension#Type_2:_add_new_row), adjon hozzá egy új rekordot, amikor egy dimenzió módosítások.</span><span class="sxs-lookup"><span data-stu-id="030d5-215">A common technique, called [Type 2](https://wikipedia.org/wiki/Slowly_changing_dimension#Type_2:_add_new_row), is to add a new record whenever a dimension changes.</span></span>

<span data-ttu-id="030d5-216">A Type 2 megközelítés megvalósításához dimenziótáblák kell további oszlopokat, amelyek egy adott rekord érvényes dátumtartományt.</span><span class="sxs-lookup"><span data-stu-id="030d5-216">In order to implement the Type 2 approach, dimension tables need additional columns that specify the effective date range for a given record.</span></span> <span data-ttu-id="030d5-217">Is a forrásadatbázisból elsődleges kulcsok többszörözni, így a táblát egy mesterséges elsődleges kulccsal kell rendelkeznie.</span><span class="sxs-lookup"><span data-stu-id="030d5-217">Also, primary keys from the source database will be duplicated, so the dimension table must have an artificial primary key.</span></span>

<span data-ttu-id="030d5-218">Az alábbi képen látható a Dimension.City tábla.</span><span class="sxs-lookup"><span data-stu-id="030d5-218">The following image shows the Dimension.City table.</span></span> <span data-ttu-id="030d5-219">A `WWI City ID` oszlop az elsődleges kulcsot a forrásadatbázisból.</span><span class="sxs-lookup"><span data-stu-id="030d5-219">The `WWI City ID` column is the primary key from the source database.</span></span> <span data-ttu-id="030d5-220">A `City Key` oszlop egy az ETL-folyamat során létrehozott mesterséges kulcsot.</span><span class="sxs-lookup"><span data-stu-id="030d5-220">The `City Key` column is an artificial key generated during the ETL pipeline.</span></span> <span data-ttu-id="030d5-221">Figyelje meg, hogy a tábla rendelkezik `Valid From` és `Valid To` oszlopot, így tartományának megadása, ha minden sor volt érvényes.</span><span class="sxs-lookup"><span data-stu-id="030d5-221">Also notice that the table has `Valid From` and `Valid To` columns, which define the range when each row was valid.</span></span> <span data-ttu-id="030d5-222">Aktuális értékek rendelkezik egy `Valid To` egyenlő "9999-12-31'.</span><span class="sxs-lookup"><span data-stu-id="030d5-222">Current values have a `Valid To` equal to '9999-12-31'.</span></span>

![Képernyőkép az városa dimenziótábla](./images/city-dimension-table.png)

<span data-ttu-id="030d5-224">Ez a megközelítés az az előnye, megőrzi az előzményadatok, amely elemzéshez hasznos lehet.</span><span class="sxs-lookup"><span data-stu-id="030d5-224">The advantage of this approach is that it preserves historical data, which can be valuable for analysis.</span></span> <span data-ttu-id="030d5-225">Azonban azt is jelenti az ugyanazon entitás több sor lesz.</span><span class="sxs-lookup"><span data-stu-id="030d5-225">However, it also means there will be multiple rows for the same entity.</span></span> <span data-ttu-id="030d5-226">Például az alábbiakban a megfelelő rekordok `WWI City ID` = 28561:</span><span class="sxs-lookup"><span data-stu-id="030d5-226">For example, here are the records that match `WWI City ID` = 28561:</span></span>

![A második képernyőképet az városa dimenziótábla](./images/city-dimension-table-2.png)

<span data-ttu-id="030d5-228">Az egyes értékesítési egyedkapcsolat szeretné a tény társítása az városa dimenziótábla, egyetlen sor invoice Date megfelelő.</span><span class="sxs-lookup"><span data-stu-id="030d5-228">For each Sales fact, you want to associate that fact with a single row in City dimension table, corresponding to the invoice date.</span></span> <span data-ttu-id="030d5-229">Az ETL-folyamat részeként egy további oszlop létrehozása, amely</span><span class="sxs-lookup"><span data-stu-id="030d5-229">As part of the ETL process, create an additional column that</span></span> 

<span data-ttu-id="030d5-230">A következő T-SQL-lekérdezést hoz létre egy ideiglenes táblát, amely összekapcsolja minden számlán a megfelelő várost kulcsot az városa dimenzió táblából.</span><span class="sxs-lookup"><span data-stu-id="030d5-230">The following T-SQL query creates a temporary table that associates each invoice with the correct City Key from the City dimension table.</span></span>

```sql
CREATE TABLE CityHolder
WITH (HEAP , DISTRIBUTION = HASH([WWI Invoice ID]))
AS
SELECT DISTINCT s1.[WWI Invoice ID] AS [WWI Invoice ID],
                c.[City Key] AS [City Key]
    FROM [Integration].[Sale_Staging] s1
    CROSS APPLY (
                SELECT TOP 1 [City Key]
                    FROM [Dimension].[City]
                WHERE [WWI City ID] = s1.[WWI City ID]
                    AND s1.[Last Modified When] > [Valid From]
                    AND s1.[Last Modified When] <= [Valid To]
                ORDER BY [Valid From], [City Key] DESC
                ) c

```

<span data-ttu-id="030d5-231">Ez a táblázat egy oszlopot a értékesítés ténytáblában feltöltésére szolgál:</span><span class="sxs-lookup"><span data-stu-id="030d5-231">This table is used to populate a column in the Sales fact table:</span></span>

```sql
UPDATE [Integration].[Sale_Staging]
SET [Integration].[Sale_Staging].[WWI Customer ID] =  CustomerHolder.[WWI Customer ID]
```

<span data-ttu-id="030d5-232">Ez az oszlop lehetővé teszi, hogy a Power BI lekérdezés keresse meg a megfelelő várost rekordot egy megadott értékesítési számla.</span><span class="sxs-lookup"><span data-stu-id="030d5-232">This column enables a Power BI query to find the correct City record for a given sales invoice.</span></span>

## <a name="security-considerations"></a><span data-ttu-id="030d5-233">Biztonsági szempontok</span><span class="sxs-lookup"><span data-stu-id="030d5-233">Security considerations</span></span>

<span data-ttu-id="030d5-234">A fokozott biztonság érdekében használhat [virtuális hálózati Szolgáltatásvégpontok](/azure/virtual-network/virtual-network-service-endpoints-overview) biztonságossá tétele Azure-szolgáltatási erőforrások a virtuális hálózaton.</span><span class="sxs-lookup"><span data-stu-id="030d5-234">For additional security, you can use [Virtual Network service endpoints](/azure/virtual-network/virtual-network-service-endpoints-overview) to secure Azure service resources to only your virtual network.</span></span> <span data-ttu-id="030d5-235">Ezzel eltávolítja ezeket az erőforrásokat, így csak a virtuális hálózatból érkező forgalom nyilvános internetkapcsolaton keresztüli hozzáférés teljes mértékben.</span><span class="sxs-lookup"><span data-stu-id="030d5-235">This fully removes public Internet access to those resources, allowing traffic only from your virtual network.</span></span>

<span data-ttu-id="030d5-236">Ezzel a módszerrel hozhat létre egy Vnetet az Azure-ban, és hozzon létre saját Szolgáltatásvégpontok az Azure-szolgáltatásokhoz.</span><span class="sxs-lookup"><span data-stu-id="030d5-236">With this approach, you create a VNet in Azure and then create private service endpoints for Azure services.</span></span> <span data-ttu-id="030d5-237">Ezeket a szolgáltatásokat majd korlátozva vannak a forgalom a virtuális hálózatról.</span><span class="sxs-lookup"><span data-stu-id="030d5-237">Those services are then restricted to traffic from that virtual network.</span></span> <span data-ttu-id="030d5-238">Is elérheti azokat a helyszíni hálózatból egy átjárón keresztül.</span><span class="sxs-lookup"><span data-stu-id="030d5-238">You can also reach them from your on-premises network through a gateway.</span></span>

<span data-ttu-id="030d5-239">Vegye figyelembe a következő korlátozások vonatkoznak:</span><span class="sxs-lookup"><span data-stu-id="030d5-239">Be aware of the following limitations:</span></span>

- <span data-ttu-id="030d5-240">A időben Ez a referenciaarchitektúra lett létrehozva, a virtuális hálózati Szolgáltatásvégpontok Azure Storage és Azure SQL Data warehouse-ba, de az Azure Analysis Service a nem támogatott.</span><span class="sxs-lookup"><span data-stu-id="030d5-240">At the time this reference architecture was created, VNet service endpoints are supported for Azure Storage and Azure SQL Data Warehouse, but not for Azure Analysis Service.</span></span> <span data-ttu-id="030d5-241">A legfrissebb állapotának [Itt](https://azure.microsoft.com/updates/?product=virtual-network).</span><span class="sxs-lookup"><span data-stu-id="030d5-241">Check the latest status [here](https://azure.microsoft.com/updates/?product=virtual-network).</span></span>

- <span data-ttu-id="030d5-242">Ha a Szolgáltatásvégpontok engedélyezve vannak az Azure Storage, a PolyBase nem adatmásolás Storage-ból az SQL Data Warehouse-bA.</span><span class="sxs-lookup"><span data-stu-id="030d5-242">If service endpoints are enabled for Azure Storage, PolyBase cannot copy data from Storage into SQL Data Warehouse.</span></span> <span data-ttu-id="030d5-243">Nincs egy megoldás erre a problémára.</span><span class="sxs-lookup"><span data-stu-id="030d5-243">There is a mitigation for this issue.</span></span> <span data-ttu-id="030d5-244">További információkért lásd: [hatását a virtuális hálózati Szolgáltatásvégpontok használatával és az Azure storage](/azure/sql-database/sql-database-vnet-service-endpoint-rule-overview?toc=%2fazure%2fvirtual-network%2ftoc.json#impact-of-using-vnet-service-endpoints-with-azure-storage).</span><span class="sxs-lookup"><span data-stu-id="030d5-244">For more information, see [Impact of using VNet Service Endpoints with Azure storage](/azure/sql-database/sql-database-vnet-service-endpoint-rule-overview?toc=%2fazure%2fvirtual-network%2ftoc.json#impact-of-using-vnet-service-endpoints-with-azure-storage).</span></span>

- <span data-ttu-id="030d5-245">Adatok áthelyezése a helyszínről az Azure Storage-ba, szüksége lesz a nyilvános IP-címeket a helyszíni vagy ExpressRoute.</span><span class="sxs-lookup"><span data-stu-id="030d5-245">To move data from on-premises into Azure Storage, you will need to whitelist public IP addresses from your on-premises or ExpressRoute.</span></span> <span data-ttu-id="030d5-246">További információkért lásd: [virtuális hálózatok biztonságossá tétele Azure-szolgáltatások](/azure/virtual-network/virtual-network-service-endpoints-overview#securing-azure-services-to-virtual-networks).</span><span class="sxs-lookup"><span data-stu-id="030d5-246">For details, see [Securing Azure services to virtual networks](/azure/virtual-network/virtual-network-service-endpoints-overview#securing-azure-services-to-virtual-networks).</span></span>

- <span data-ttu-id="030d5-247">Ahhoz, hogy az Analysis Services adatokat olvasni az SQL Data Warehouse, Windows virtuális gép üzembe helyezése a virtuális hálózathoz, amely tartalmazza az SQL Data Warehouse szolgáltatásvégpontot.</span><span class="sxs-lookup"><span data-stu-id="030d5-247">To enable Analysis Services to read data from SQL Data Warehouse, deploy a Windows VM to the virtual network that contains the SQL Data Warehouse service endpoint.</span></span> <span data-ttu-id="030d5-248">Telepítés [Azure a helyszíni adatátjáró](/azure/analysis-services/analysis-services-gateway) a virtuális gépen.</span><span class="sxs-lookup"><span data-stu-id="030d5-248">Install [Azure On-premises Data Gateway](/azure/analysis-services/analysis-services-gateway) on this VM.</span></span> <span data-ttu-id="030d5-249">Kapcsolódjon az Azure elemzési szolgáltatás az átjárót.</span><span class="sxs-lookup"><span data-stu-id="030d5-249">Then connect your Azure Analysis service to the data gateway.</span></span>

## <a name="deploy-the-solution"></a><span data-ttu-id="030d5-250">A megoldás üzembe helyezése</span><span class="sxs-lookup"><span data-stu-id="030d5-250">Deploy the solution</span></span>

<span data-ttu-id="030d5-251">A telepítés, és futtassa a referenciaimplementációt, kövesse a lépéseket a [GitHub információs][github].</span><span class="sxs-lookup"><span data-stu-id="030d5-251">To the deploy and run the reference implementation, follow the steps in the [GitHub readme][github].</span></span> <span data-ttu-id="030d5-252">A következőket helyezi üzembe:</span><span class="sxs-lookup"><span data-stu-id="030d5-252">It deploys the following:</span></span>

- <span data-ttu-id="030d5-253">Windows virtuális gép egy helyszíni adatbázis-kiszolgáló szimulálásához.</span><span class="sxs-lookup"><span data-stu-id="030d5-253">A Windows VM to simulate an on-premises database server.</span></span> <span data-ttu-id="030d5-254">Ez magában foglalja az SQL Server 2017-ben és a kapcsolódó eszközök, Power BI Desktop együtt.</span><span class="sxs-lookup"><span data-stu-id="030d5-254">It includes SQL Server 2017 and related tools, along with Power BI Desktop.</span></span>
- <span data-ttu-id="030d5-255">Azure storage-fiókkal, amely biztosít a Blob storage, az SQL Server-adatbázisból exportált adatok tárolásához.</span><span class="sxs-lookup"><span data-stu-id="030d5-255">An Azure storage account that provides Blob storage to hold data exported from the SQL Server database.</span></span>
- <span data-ttu-id="030d5-256">Egy Azure SQL Data Warehouse-példányhoz.</span><span class="sxs-lookup"><span data-stu-id="030d5-256">An Azure SQL Data Warehouse instance.</span></span>
- <span data-ttu-id="030d5-257">Az Azure Analysis Services-példányt.</span><span class="sxs-lookup"><span data-stu-id="030d5-257">An Azure Analysis Services instance.</span></span>
- <span data-ttu-id="030d5-258">Az Azure Data Factory és a Data Factory-folyamatot a ELT-feladathoz.</span><span class="sxs-lookup"><span data-stu-id="030d5-258">Azure Data Factory and the Data Factory pipeline for the ELT job.</span></span>

## <a name="related-resources"></a><span data-ttu-id="030d5-259">Kapcsolódó források (lehet, hogy a cikkek angol nyelvűek)</span><span class="sxs-lookup"><span data-stu-id="030d5-259">Related resources</span></span>

<span data-ttu-id="030d5-260">Tekintse át az alábbiakat érdemes [Azure példaforgatókönyvek](/azure/architecture/example-scenario) , amelyek bemutatják, hogy egyes technológiákat használó adott megoldások:</span><span class="sxs-lookup"><span data-stu-id="030d5-260">You may want to review the following [Azure example scenarios](/azure/architecture/example-scenario) that demonstrate specific solutions using some of the same technologies:</span></span>

- [<span data-ttu-id="030d5-261">Adattárház és analitika értékesítés és marketing</span><span class="sxs-lookup"><span data-stu-id="030d5-261">Data warehousing and analytics for sales and marketing</span></span>](/azure/architecture/example-scenario/data/data-warehouse)
- [<span data-ttu-id="030d5-262">Hibrid ETL a meglévő helyszíni SSIS és az Azure Data Factory</span><span class="sxs-lookup"><span data-stu-id="030d5-262">Hybrid ETL with existing on-premises SSIS and Azure Data Factory</span></span>](/azure/architecture/example-scenario/data/hybrid-etl-with-adf)

<!-- links -->

[adf]: /azure/data-factory
[github]: https://github.com/mspnp/azure-data-factory-sqldw-elt-pipeline
[MergeLocation]: https://github.com/mspnp/reference-architectures/blob/master/data/enterprise_bi_sqldw_advanced/azure/sqldw_scripts/city/%5BIntegration%5D.%5BMergeLocation%5D.sql
[wwi]: /sql/sample/world-wide-importers/wide-world-importers-oltp-database
