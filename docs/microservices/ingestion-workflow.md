---
title: Adatfeldolgozást és mikroszolgáltatások munkafolyamata
description: Adatfeldolgozást és mikroszolgáltatások munkafolyamata
author: MikeWasson
ms.date: 12/08/2017
ms.openlocfilehash: 6477c3f2b0cc6d37dcd4637dc0dde4f7a6e3cc74
ms.sourcegitcommit: 94c769abc3d37d4922135ec348b5da1f4bbcaa0a
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 12/13/2017
ms.locfileid: "26678730"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="26577-103">Mikroszolgáltatások tervezése: adatfeldolgozást és a munkafolyamat</span><span class="sxs-lookup"><span data-stu-id="26577-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="26577-104">Mikroszolgáltatások gyakran olyan munkafolyamatot, amely egyetlen tranzakció több szolgáltatáshoz is rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="26577-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="26577-105">A munkafolyamat megbízható; kell lennie. nem lehet tranzakciók elveszíti vagy részben befejezett állapotban hagyja őket.</span><span class="sxs-lookup"><span data-stu-id="26577-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="26577-106">Nagyon fontos is a bejövő kérelmek adatfeldolgozást átviteli sebességét.</span><span class="sxs-lookup"><span data-stu-id="26577-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="26577-107">A sok kisméretű szolgáltatások kommunikál egymással a bejövő kérelmek kapacitásnövelés is ne terhelje tovább a értekezleteire kommunikációt.</span><span class="sxs-lookup"><span data-stu-id="26577-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span> 

![](./images/ingestion-workflow.png)

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="26577-108">A dron kézbesítési munkafolyamatot</span><span class="sxs-lookup"><span data-stu-id="26577-108">The drone delivery workflow</span></span>

<span data-ttu-id="26577-109">A dron továbbítási alkalmazást hozhat létre a következő műveleteket kell elvégezni egy kézbesítési ütemezése:</span><span class="sxs-lookup"><span data-stu-id="26577-109">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="26577-110">Tekintse meg a felhasználói fiókhoz (fiókszolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="26577-110">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="26577-111">Hozzon létre egy új csomag entitás (csomag szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="26577-111">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="26577-112">Jelölőnégyzet külső szállítására a kézbesítéshez szükséges-e a felvételi és kézbesítési helyeken alapuló (külső szállítására szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="26577-112">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="26577-113">Ütemezhet egy dron felvételhez (dron szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="26577-113">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="26577-114">Hozzon létre egy új kézbesítési entitás (kézbesítési szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="26577-114">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="26577-115">Ez az a teljes alkalmazás alapszolgáltatásai, ezért a végpont folyamat, valamint megbízható performant kell lennie.</span><span class="sxs-lookup"><span data-stu-id="26577-115">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="26577-116">Egyes adott kihívásokkal kell figyelembe venni:</span><span class="sxs-lookup"><span data-stu-id="26577-116">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="26577-117">**Terheléskiegyenlítés**.</span><span class="sxs-lookup"><span data-stu-id="26577-117">**Load leveling**.</span></span> <span data-ttu-id="26577-118">Túl sok ügyfél kérést is ne terhelje tovább a rendszer értekezleteire hálózati forgalmat.</span><span class="sxs-lookup"><span data-stu-id="26577-118">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="26577-119">Azt is is ne terhelje tovább háttér függőségek, például a tároló- és távoli szolgáltatások.</span><span class="sxs-lookup"><span data-stu-id="26577-119">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="26577-120">Ezek a szolgáltatások hívja, ellennyomás létrehozásakor a rendszer szabályozásával előfordulhat, hogy reagálni.</span><span class="sxs-lookup"><span data-stu-id="26577-120">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="26577-121">Ezért fontos a kérelmeket a rendszer által a üzembe egy puffer vagy feldolgozásra várólista beérkező terhelés.</span><span class="sxs-lookup"><span data-stu-id="26577-121">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span> 

- <span data-ttu-id="26577-122">**Garantált kézbesítés**.</span><span class="sxs-lookup"><span data-stu-id="26577-122">**Guaranteed delivery**.</span></span> <span data-ttu-id="26577-123">Bármely ügyfél kérelmeket elkerüléséhez az adatfeldolgozást összetevő kell garantálja, legalább egyszeri üzenetek.</span><span class="sxs-lookup"><span data-stu-id="26577-123">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span> 

- <span data-ttu-id="26577-124">**Hibakezelés**.</span><span class="sxs-lookup"><span data-stu-id="26577-124">**Error handling**.</span></span> <span data-ttu-id="26577-125">Ha a szolgáltatások egy hibakódot ad vissza, vagy nem átmeneti hibát tapasztal, a kézbesítés nem lehet ütemezni.</span><span class="sxs-lookup"><span data-stu-id="26577-125">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="26577-126">Hibakód utalhat a várható hibaállapotot (például a felhasználói fiók fel van függesztve) vagy egy váratlan kiszolgálóhiba (HTTP 5xx).</span><span class="sxs-lookup"><span data-stu-id="26577-126">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="26577-127">Elképzelhető, hogy a szolgáltatás is érhető el, amely a hálózati hívás túllépi az időkorlátot.</span><span class="sxs-lookup"><span data-stu-id="26577-127">A service might also be unavailable, causing the network call to time out.</span></span> 

<span data-ttu-id="26577-128">Először megnézzük a egyenlet adatfeldolgozást oldalán &mdash; hogyan a rendszer magas teljesítmény bejövő felhasználói kérelmek fogadására képes.</span><span class="sxs-lookup"><span data-stu-id="26577-128">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="26577-129">Azt fogja fontolja meg a dron továbbítási alkalmazást hozhat létre hogyan valósíthatja meg a megbízható munkafolyamat.</span><span class="sxs-lookup"><span data-stu-id="26577-129">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="26577-130">Változik, hogy a kialakítás az adatfeldolgozást alrendszer befolyásolja a munkafolyamat háttér.</span><span class="sxs-lookup"><span data-stu-id="26577-130">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span> 

## <a name="ingestion"></a><span data-ttu-id="26577-131">Adatfeldolgozást</span><span class="sxs-lookup"><span data-stu-id="26577-131">Ingestion</span></span>

<span data-ttu-id="26577-132">Üzleti követelmények alapján, a fejlesztői csapat meghatározott szempontjából a következő művelet követelmények:</span><span class="sxs-lookup"><span data-stu-id="26577-132">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="26577-133">10e kérelmek/másodperc fenntartható átviteli sebességet.</span><span class="sxs-lookup"><span data-stu-id="26577-133">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="26577-134">Tudja kezelni a teljesítményt, legfeljebb 50K másodpercenkénti nélkül ügyfél kérelmeket, vagy időtúllépés miatt.</span><span class="sxs-lookup"><span data-stu-id="26577-134">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="26577-135">Kisebb, mint 500ms várakozási ideje a a 99th PERCENTILIS visszaadása.</span><span class="sxs-lookup"><span data-stu-id="26577-135">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="26577-136">A követelmény alkalmi igényeiben jelentkező forgalmának kezeléséhez tervezési kihívást mutatja be.</span><span class="sxs-lookup"><span data-stu-id="26577-136">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="26577-137">Elméletileg a rendszer sikerült horizontálisan a maximális várt forgalom kezeléséhez.</span><span class="sxs-lookup"><span data-stu-id="26577-137">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="26577-138">Azonban kiépítése, hogy számos olyan forrás nagyon hatékony.</span><span class="sxs-lookup"><span data-stu-id="26577-138">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="26577-139">Az esetek többségében az alkalmazást nem kell, hogy mekkora kapacitást, nem lenne üresjárati mag, költségszámítás money érték hozzáadása nélkül.</span><span class="sxs-lookup"><span data-stu-id="26577-139">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="26577-140">A jobb megoldás, a bejövő kéréseket kerüljenek a puffert, és lehetővé teszik a terhelés leveler összekötőként puffer.</span><span class="sxs-lookup"><span data-stu-id="26577-140">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="26577-141">Ezzel a kialakítással a adatfeldolgozást szolgáltatás képes kezelni a maximális adatfeldolgozást sebességét rövid időszakokra kell lennie, de a háttér-szolgáltatások csak kell a maximális fenntartható terhelés kezelésére.</span><span class="sxs-lookup"><span data-stu-id="26577-141">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="26577-142">Pufferelés első végén, a háttér-szolgáltatások nem kell kezelni a forgalom nagy teljesítményt.</span><span class="sxs-lookup"><span data-stu-id="26577-142">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="26577-143">A dron továbbítási alkalmazást hozhat létre, a szükséges léptékű [Azure Event Hubs](/azure/event-hubs/) a terhelés simítás jó választás.</span><span class="sxs-lookup"><span data-stu-id="26577-143">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="26577-144">Az Event Hubs alacsony késéssel és nagy teljesítményt biztosít, és egy költséghatékony megoldást a következő magas adatfeldolgozást kötetek.</span><span class="sxs-lookup"><span data-stu-id="26577-144">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span> 

<span data-ttu-id="26577-145">A tesztelés során a egy Standard csomagra eseményközpont 32 partíciók és 100 átviteli egységek használtuk.</span><span class="sxs-lookup"><span data-stu-id="26577-145">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="26577-146">Megfigyelhető, hogy hamarosan 32 KB-os esemény / másodperc adatfeldolgozást, késéssel 90ms körül.</span><span class="sxs-lookup"><span data-stu-id="26577-146">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="26577-147">Jelenleg az alapértelmezett érték 20 átviteli egység, de az Azure-ügyfél kérhetnek további átviteli egységek tervátalakítási egy támogatási kérést.</span><span class="sxs-lookup"><span data-stu-id="26577-147">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="26577-148">Lásd: [Event Hubs kvóták](/azure/event-hubs/event-hubs-quotas) további információt.</span><span class="sxs-lookup"><span data-stu-id="26577-148">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="26577-149">Csakúgy, mint a metrikák sok tényezők befolyásolhatják a teljesítményt, például az üzenet terhelés méretének, így nem értelmezi őket egy alapként.</span><span class="sxs-lookup"><span data-stu-id="26577-149">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="26577-150">További átviteli van szükség, ha az adatfeldolgozást szolgáltatás shard egynél több eseményközpont között is.</span><span class="sxs-lookup"><span data-stu-id="26577-150">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="26577-151">A még nagyobb átviteli sebességet [Event Hubs dedikált](/azure/event-hubs/event-hubs-dedicated-overview) biztosít egy bérlői központi telepítéseket is érkező másodpercenként több mint 2 millió esemény.</span><span class="sxs-lookup"><span data-stu-id="26577-151">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="26577-152">Fontos megérteni, hogyan Event Hubs ilyen magas teljesítmény érhető el, mert, amely hatással van, hogyan ügyfél foglaljanak Eseményközpontokból származó üzenetek.</span><span class="sxs-lookup"><span data-stu-id="26577-152">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="26577-153">Az Event Hubs nem valósítja meg a *várólista*.</span><span class="sxs-lookup"><span data-stu-id="26577-153">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="26577-154">Ahelyett, hogy, amely egy *eseményfelhasználó*.</span><span class="sxs-lookup"><span data-stu-id="26577-154">Rather, it implements an *event stream*.</span></span> 

<span data-ttu-id="26577-155">A várólistához egy egyedi felhasználói eltávolítása egy üzenetet az üzenetsorból, és a következő fogyasztói az üzenet nem jelenik.</span><span class="sxs-lookup"><span data-stu-id="26577-155">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="26577-156">Várólisták ezért használatát teszik lehetővé a [versengő fogyasztók mintát](../patterns/competing-consumers.md) párhuzamosan üzenetek feldolgozásához, és a méretezhetőség javítása.</span><span class="sxs-lookup"><span data-stu-id="26577-156">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="26577-157">Nagyobb rugalmasság a fogyasztó tárolja a zárolást az üzenet és zárolás feloldása, amikor az üzenet feldolgozása megtörtént.</span><span class="sxs-lookup"><span data-stu-id="26577-157">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="26577-158">Ha a fogyasztó nem sikerül &mdash; például a csomóponton futó összeomlások &mdash; a zárolás végrehajtásának időkorlátja, és az üzenet vissza a várólista-kiszolgálóra kerül.</span><span class="sxs-lookup"><span data-stu-id="26577-158">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span> 

![](./images/queue-semantics.png)

<span data-ttu-id="26577-159">Az Event Hubs, másrészt adatfolyam szemantikáját használja.</span><span class="sxs-lookup"><span data-stu-id="26577-159">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="26577-160">A fogyasztók olvashatja a streamet egymástól függetlenül saját tempójában.</span><span class="sxs-lookup"><span data-stu-id="26577-160">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="26577-161">Mindegyik felhasználó felelős nyomon követése céljából az aktuális pozíciót az adatfolyamban.</span><span class="sxs-lookup"><span data-stu-id="26577-161">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="26577-162">A fogyasztó az egyes előre meghatározott időközönként állandó tároló kell írni a jelenlegi állapotában.</span><span class="sxs-lookup"><span data-stu-id="26577-162">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="26577-163">Így ha a fogyasztó (például a fogyasztói összeomlik vagy az állomás nem tud) hibát észlel, majd új példányt folytathatja az adatfolyam olvasásakor az utolsó rögzített hely.</span><span class="sxs-lookup"><span data-stu-id="26577-163">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="26577-164">Ez a folyamat *ellenőrzőpontok*.</span><span class="sxs-lookup"><span data-stu-id="26577-164">This process is called *checkpointing*.</span></span> 

<span data-ttu-id="26577-165">A megfelelő teljesítmény érdekében egy végfelhasználói általában nem ellenőrzőpont után minden üzenetet.</span><span class="sxs-lookup"><span data-stu-id="26577-165">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="26577-166">Ehelyett az egyes rögzített időközönként, például a feldolgozást követően az ellenőrzőpontok  *n*  üzeneteket, vagy minden  *n*  másodperc.</span><span class="sxs-lookup"><span data-stu-id="26577-166">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="26577-167">Következésképpen a fogyasztó nem sikerül, ha egyes események előfordulhat, hogy feldolgozni kétszer, mert egy új példány mindig szerzi be a legutóbbi ellenőrzőponttól.</span><span class="sxs-lookup"><span data-stu-id="26577-167">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="26577-168">Nincs olyan kompromisszumot: gyakori ellenőrzőpontokat hátrányosan befolyásolhatja a teljesítményt, de a ritka ellenőrzőpontokat jelenti azt, egy meghibásodás után fog visszajátszásos a további események.</span><span class="sxs-lookup"><span data-stu-id="26577-168">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>  

![](./images/stream-semantics.png)
 
<span data-ttu-id="26577-169">Az Event Hubs nem versengő fogyasztó számára készült.</span><span class="sxs-lookup"><span data-stu-id="26577-169">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="26577-170">Bár több felhasználóból adatfolyam tudja olvasni, minden egyes halad át a adatfolyam egymástól függetlenül.</span><span class="sxs-lookup"><span data-stu-id="26577-170">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="26577-171">Ehelyett az Event Hubs egy particionált felhasználói mintát használ.</span><span class="sxs-lookup"><span data-stu-id="26577-171">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="26577-172">Az eseményközpontok legfeljebb 32-partíciókkal rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="26577-172">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="26577-173">Horizontális skálázhatóságot az érhető el egy külön végfelhasználói hozzárendelése minden partíció.</span><span class="sxs-lookup"><span data-stu-id="26577-173">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="26577-174">Ez mit jelent a dron kézbesítési munkafolyamat?</span><span class="sxs-lookup"><span data-stu-id="26577-174">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="26577-175">Ahhoz, hogy a teljes előnye, hogy az Event Hubs, a kézbesítési ütemezési nem Várjon, amíg minden üzenetet dolgozható fel, mielőtt a Tovább gombra.</span><span class="sxs-lookup"><span data-stu-id="26577-175">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="26577-176">Ha mégis meghaladja, az idő, Várakozás a hálózati hívás befejezéséhez fog legmagasabbak.</span><span class="sxs-lookup"><span data-stu-id="26577-176">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="26577-177">Ehelyett kell kötegek párhuzamosan, a háttér-szolgáltatásokhoz való aszinkron hívásokkal üzenetek feldolgozásához.</span><span class="sxs-lookup"><span data-stu-id="26577-177">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="26577-178">Megtanulhatja, mivel a megfelelő ellenőrzőpont-stratégia kiválasztása az is fontos.</span><span class="sxs-lookup"><span data-stu-id="26577-178">As we'll see, choosing the right checkpointing strategy is also important.</span></span>  

## <a name="workflow"></a><span data-ttu-id="26577-179">Munkafolyamat</span><span class="sxs-lookup"><span data-stu-id="26577-179">Workflow</span></span>

<span data-ttu-id="26577-180">Olvasási és az üzenetek feldolgozása három lehetséges nézett azt: Event Processor Host, Service Bus-üzenetsorok és az IOT hubbal reagálni könyvtár.</span><span class="sxs-lookup"><span data-stu-id="26577-180">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="26577-181">IOT hubbal reagálni választottuk, de megértéséhez Event Processor Host kezdődnie segíti.</span><span class="sxs-lookup"><span data-stu-id="26577-181">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span> 

### <a name="event-processor-host"></a><span data-ttu-id="26577-182">Event Processor Host</span><span class="sxs-lookup"><span data-stu-id="26577-182">Event Processor Host</span></span>

<span data-ttu-id="26577-183">Event Processor Host készült üzenet kötegelés.</span><span class="sxs-lookup"><span data-stu-id="26577-183">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="26577-184">Az alkalmazás megvalósítja a `IEventProcessor` felületet, és a Processor Host létrehoz egy esemény processzorpéldány minden partíció esetében az eseményközpontba.</span><span class="sxs-lookup"><span data-stu-id="26577-184">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="26577-185">Az Event Processor Host majd meghívja a minden esemény processzor `ProcessEventsAsync` eseményüzeneteket kötegekben metódust.</span><span class="sxs-lookup"><span data-stu-id="26577-185">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="26577-186">Az alkalmazás vezérlők az ellenőrzőpont belül a `ProcessEventsAsync` metódust, és az Event Processor Host ellenőrzőpontot ír az Azure storage.</span><span class="sxs-lookup"><span data-stu-id="26577-186">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span> 

<span data-ttu-id="26577-187">A partíciókon belül Event Processor Host megvárja-e a `ProcessEventsAsync` vissza a következő mérési adatköteget való ismételt hívása előtt.</span><span class="sxs-lookup"><span data-stu-id="26577-187">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="26577-188">Ezt a módszert használja egyszerűbbé teszi a programozási modellel, mert a feldolgozás eseménykód nem szükséges ismételten belépő.</span><span class="sxs-lookup"><span data-stu-id="26577-188">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="26577-189">Azonban azt is jelenti, hogy a eseményfeldolgozóhoz kezeli egy kötegelt egyszerre, és ez a sebesség, amellyel a Processor Host üzenetek is szivattyú gates.</span><span class="sxs-lookup"><span data-stu-id="26577-189">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE] 
> <span data-ttu-id="26577-190">A Processor Host ténylegesen nem *Várjon, amíg* abban az értelemben az egy szál blokkolás.</span><span class="sxs-lookup"><span data-stu-id="26577-190">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="26577-191">A `ProcessEventsAsync` metódus aszinkron, ezért a Processor Host teheti más feladatok, amíg befejeződik az metódus.</span><span class="sxs-lookup"><span data-stu-id="26577-191">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="26577-192">De azt nem az adott partíció üzenetek egy másik köteg mindaddig, amíg a metódus visszaadja.</span><span class="sxs-lookup"><span data-stu-id="26577-192">But it won't deliver another batch of messages for that partition until the method returns.</span></span> 

<span data-ttu-id="26577-193">A dron alkalmazásban az üzenetkötegek párhuzamosan lehet feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="26577-193">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="26577-194">De a teljes kötegelt befejezéséhez Várakozás a szűk keresztmetszetek is okozhatnak.</span><span class="sxs-lookup"><span data-stu-id="26577-194">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="26577-195">Feldolgozási csak lehet gyorsaságának a leglassabb üzenet egy kötegben.</span><span class="sxs-lookup"><span data-stu-id="26577-195">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="26577-196">Válaszidők bármilyen változása a "hosszú utóhívás," ahol néhány lassú válaszok húzza le az egész rendszert hozhat létre.</span><span class="sxs-lookup"><span data-stu-id="26577-196">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="26577-197">A teljesítménytesztek bemutatta, hogy azt nem érte el az ezzel a megközelítéssel cél átviteli sebességet.</span><span class="sxs-lookup"><span data-stu-id="26577-197">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="26577-198">Ez a does *nem* jelenti azt, hogy Event Processor Host használata kerülendő.</span><span class="sxs-lookup"><span data-stu-id="26577-198">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="26577-199">A magas teljesítmény kerülje a hosszan futó feladatokat belül, de a `ProcesssEventsAsync` metódust.</span><span class="sxs-lookup"><span data-stu-id="26577-199">But for high throughput, avoid doing any long-running tasks inside the `ProcesssEventsAsync` method.</span></span> <span data-ttu-id="26577-200">Gyors feldolgozása egyes kötegekben.</span><span class="sxs-lookup"><span data-stu-id="26577-200">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="26577-201">Reagálni IOT hubbal</span><span class="sxs-lookup"><span data-stu-id="26577-201">IotHub React</span></span> 

<span data-ttu-id="26577-202">[IOT hubbal reagálni](https://github.com/Azure/toketi-iothubreact) események olvasása az Eseményközpont Akka adatfolyamok könyvtár.</span><span class="sxs-lookup"><span data-stu-id="26577-202">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="26577-203">Akka adatfolyamok egy adatfolyam-alapú programozási keretrendszerről, amely megvalósítja a [reaktív adatfolyamok](http://www.reactive-streams.org/) megadását.</span><span class="sxs-lookup"><span data-stu-id="26577-203">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](http://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="26577-204">Is biztosítja az adatfolyam-továbbítási hatékony folyamatok, ahol minden adatfolyam műveleteket aszinkron módon történik, és az adatcsatorna szabályosan kezeli ellennyomás létrehozásához.</span><span class="sxs-lookup"><span data-stu-id="26577-204">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="26577-205">Ellennyomás akkor fordul elő, amikor egy eseményforrás eredményez, mint az alárendelt fogyasztók fogadhatja gyorsabban események &mdash; amelyhez pontosan a helyzet akkor, ha a a dron kézbesítési rendszer rendelkezik a csúcs a forgalom.</span><span class="sxs-lookup"><span data-stu-id="26577-205">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="26577-206">Ha a háttérkiszolgáló szolgáltatások lassabban go, IOT hubbal reagálni lelassulnak.</span><span class="sxs-lookup"><span data-stu-id="26577-206">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="26577-207">Ha kapacitás nő, IOT hubbal reagálni fogja leküldeni a több üzenet a feldolgozási folyamaton keresztül.</span><span class="sxs-lookup"><span data-stu-id="26577-207">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="26577-208">Az Event Hubs eseményeit streaming nagyon természetes programozási modellt Akka adatfolyamokat is.</span><span class="sxs-lookup"><span data-stu-id="26577-208">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="26577-209">Helyett egy kötegelt események ismétlése, határozza meg, amely minden esemény alkalmazandó, és tájékoztassa kezelni a streaming Akka adatfolyamok műveletkészlet.</span><span class="sxs-lookup"><span data-stu-id="26577-209">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="26577-210">Akka adatfolyamok határozza meg a folyamatos átviteli folyamat *források*, *Forgalomáramlás*, és *fogadók esetében*.</span><span class="sxs-lookup"><span data-stu-id="26577-210">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="26577-211">Forrás hoz létre egy kimeneti adatfolyamba, a folyamat egy bemeneti adatfolyam feldolgozza, és hozza létre a kimeneti adatfolyamokat, és a fogadó fel adatfolyam nélkül állít elő kimenetet.</span><span class="sxs-lookup"><span data-stu-id="26577-211">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="26577-212">A kód itt látható a Feladatütemező szolgáltatás, amely beállítja a Akka adatfolyamok folyamat:</span><span class="sxs-lookup"><span data-stu-id="26577-212">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="26577-213">Ezt a kódot állít be az Event Hubs.</span><span class="sxs-lookup"><span data-stu-id="26577-213">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="26577-214">A `map` utasítás minden eseményüzenet deserializes egy Java-osztály egy kézbesítési kérelem jelölő be.</span><span class="sxs-lookup"><span data-stu-id="26577-214">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="26577-215">A `filter` utasítás eltávolítja minden `null` be az adatfolyamból objektumok; ebben az esetben, ha egy üzenet nem deszerializálható megóvja.</span><span class="sxs-lookup"><span data-stu-id="26577-215">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="26577-216">A `via` utasítás csatlakoztatja a forrás egy folyamatot, amely minden kézbesítési kérést dolgoz fel.</span><span class="sxs-lookup"><span data-stu-id="26577-216">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="26577-217">A `to` metódus az ellenőrzőpont fogadó, IOT hubbal reagálni rendszerbe beépített csatlakoztatja a folyamatot.</span><span class="sxs-lookup"><span data-stu-id="26577-217">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="26577-218">IOT hubbal reagálni használja egy másik ellenőrzőpontok stratégia esemény Host processzor-nál.</span><span class="sxs-lookup"><span data-stu-id="26577-218">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="26577-219">Az ellenőrzőpontok a ellenőrzőpont fogadó, amely a lezáró szakasza a folyamatnak írja.</span><span class="sxs-lookup"><span data-stu-id="26577-219">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="26577-220">Akka adatfolyamokat a kialakítása lehetővé teszi, hogy a folytatáshoz a streamelési adatok, miközben a fogadó ír az ellenőrzőpont-feldolgozási folyamat.</span><span class="sxs-lookup"><span data-stu-id="26577-220">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="26577-221">Ez azt jelenti, hogy a felsőbb rétegbeli feldolgozás szakaszában nem kell várnia az ellenőrzőpontok használatával fordulhat elő.</span><span class="sxs-lookup"><span data-stu-id="26577-221">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="26577-222">Konfigurálhatja az ellenőrzőpontok létrehozása után egy időtúllépési, vagy egy bizonyos számú üzenetek feldolgozása után.</span><span class="sxs-lookup"><span data-stu-id="26577-222">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="26577-223">A `deliveryProcessor` hoz létre a Akka adatfolyamok folyamata:</span><span class="sxs-lookup"><span data-stu-id="26577-223">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>  

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(), 
                        delivery.getMessageFromDevice().properties());
        
        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }
                                
        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="26577-224">A folyamat meghívja a statikus `processDeliveryRequestAsync` módszer, amely a minden üzenet feldolgozásakor a tényleges munkát.</span><span class="sxs-lookup"><span data-stu-id="26577-224">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="26577-225">Az IOT hubbal reagálni skálázás</span><span class="sxs-lookup"><span data-stu-id="26577-225">Scaling with IoTHub React</span></span>

<span data-ttu-id="26577-226">A Feladatütemező szolgáltatás célja, hogy a tároló feltünteti olvassa be az egyetlen partícióra.</span><span class="sxs-lookup"><span data-stu-id="26577-226">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="26577-227">Például, ha az Event Hubs 32-partíciókkal rendelkezik, a Feladatütemező szolgáltatás telepítése 32 replikával.</span><span class="sxs-lookup"><span data-stu-id="26577-227">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="26577-228">Ez lehetővé teszi a magas fokú rugalmasságot biztosít horizontális skálázás tekintetében.</span><span class="sxs-lookup"><span data-stu-id="26577-228">This allows for a lot of flexibility in terms of horizontal scaling.</span></span> 

<span data-ttu-id="26577-229">Attól függően, hogy a fürt méretét a fürt egyik csomópontjában levő rendelkezhet egynél több Feladatütemező szolgáltatás pod fut rajta.</span><span class="sxs-lookup"><span data-stu-id="26577-229">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="26577-230">De ha a Feladatütemező szolgáltatás több erőforrást igényel, a fürt kiterjeszthető, ahhoz, hogy a három munkaállomás-csoporttal szét több csomópontot.</span><span class="sxs-lookup"><span data-stu-id="26577-230">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="26577-231">A teljesítménytesztek bemutatta, hogy a Feladatütemező szolgáltatás határa memória - és szál-, így teljesítmény alárendelve nagy mértékben a Virtuálisgép-méretet és az egyes csomópontok három munkaállomás-csoporttal.</span><span class="sxs-lookup"><span data-stu-id="26577-231">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="26577-232">Minden példány tudnia kell, amely az Event Hubs partícióazonosító olvasni.</span><span class="sxs-lookup"><span data-stu-id="26577-232">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="26577-233">Konfigurálhatja a számát, azt előnyt a [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) Kubernetes erőforrástípus.</span><span class="sxs-lookup"><span data-stu-id="26577-233">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="26577-234">Az egy StatefulSet három munkaállomás-csoporttal rendelkezik, amely tartalmazza az tartozó numerikus index állandó azonosítóval.</span><span class="sxs-lookup"><span data-stu-id="26577-234">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="26577-235">Pontosabban, a pod értéke `<statefulset name>-<index>`, és ezt az értéket a tárolóhoz a Kubernetes keresztül érhető el [lefelé API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span><span class="sxs-lookup"><span data-stu-id="26577-235">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="26577-236">Futásidőben a Feladatütemező szolgáltatás a pod felhasználónevét olvassa be, és a pod index használja, mint a partícióazonosító.</span><span class="sxs-lookup"><span data-stu-id="26577-236">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="26577-237">Horizontális a Feladatütemező szolgáltatás még tovább szükség esetén sikerült event hub partíciónként több pod rendelhet, hogy több három munkaállomás-csoporttal mindegyik partíció olvas.</span><span class="sxs-lookup"><span data-stu-id="26577-237">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="26577-238">Azonban ebben az esetben minden példány volna olvasni az események a hozzárendelt partícióban.</span><span class="sxs-lookup"><span data-stu-id="26577-238">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="26577-239">Ismétlődő feldolgozásának elkerülése érdekében meg kell a kivonatolási algoritmust használja, hogy az egyes példányok kihagyja az üzenetek egy része felett.</span><span class="sxs-lookup"><span data-stu-id="26577-239">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="26577-240">Ezzel a módszerrel több olvasók felhasználhat az adatfolyam, de minden üzenetet csak egy példány dolgoz fel.</span><span class="sxs-lookup"><span data-stu-id="26577-240">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span> 
 
![](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="26577-241">Service Bus-üzenetsorok</span><span class="sxs-lookup"><span data-stu-id="26577-241">Service Bus queues</span></span>

<span data-ttu-id="26577-242">Egy harmadik beállítás, amely azt tekinti az üzenetek átmásolni az Event Hubs egy Service Bus-üzenetsorba, és majd a Feladatütemező szolgáltatás elolvasta az üzeneteket a Service Bus.</span><span class="sxs-lookup"><span data-stu-id="26577-242">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="26577-243">A bejövő kéréseket írása az csak a másolja őket a Service Bus Event Hubsban furcsa tűnhet.</span><span class="sxs-lookup"><span data-stu-id="26577-243">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="26577-244">Azonban az ötletére lett-e használni a különböző szintjeiről minden egyes szolgáltatás: használja az Event Hubs nagy forgalom igényeiben jelentkező befogadására közben a várólista szemantikáját a Service Bus számára, a munkaterhelés versengő fogyasztók mintával feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="26577-244">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="26577-245">Ne feledje, hogy a cél a folyamatos átviteli kisebb, mint a várható terhelést, így feldolgozásra a Service Bus-üzenetsorba nem kell lennie az üzenet olyan gyors adatfeldolgozást.</span><span class="sxs-lookup"><span data-stu-id="26577-245">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>
 
<span data-ttu-id="26577-246">Ezt a módszert használja az a koncepció igazolása megvalósítási érhető el, 4 KB-os műveletek másodpercenkénti száma.</span><span class="sxs-lookup"><span data-stu-id="26577-246">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="26577-247">Ezeket a teszteket, amelyek még nem tette tényleges munka, de egyszerűen hozzáadni a szolgáltatás várakozási ideje a rögzített méretű utánzatait háttér szolgáltatások használt.</span><span class="sxs-lookup"><span data-stu-id="26577-247">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="26577-248">Vegye figyelembe, hogy a teljesítmény számok volt sokkal kisebb, mint a Service Bus elméleti maximum.</span><span class="sxs-lookup"><span data-stu-id="26577-248">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="26577-249">Az eltérés okai a következők:</span><span class="sxs-lookup"><span data-stu-id="26577-249">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="26577-250">Nem rendelkezik a különböző ügyfél-paraméterek, például a kapcsolat készlet kapacitása, párhuzamos folyamatkezelést biztosítja, a lehívott, valamint a Köteg mérete fokának optimális értékeit.</span><span class="sxs-lookup"><span data-stu-id="26577-250">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="26577-251">A hálózati i/o-szűk keresztmetszeteket.</span><span class="sxs-lookup"><span data-stu-id="26577-251">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="26577-252">Használja a [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mód helyett [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), amely volt szükség, annak érdekében, legalább egyszeri üzenetek kézbesítését.</span><span class="sxs-lookup"><span data-stu-id="26577-252">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="26577-253">További teljesítménytesztek előfordulhat, hogy az alapvető ok észlelt és engedélyezett a problémák megoldásához.</span><span class="sxs-lookup"><span data-stu-id="26577-253">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="26577-254">Azonban IOT hubbal reagálni teljesül, a teljesítmény cél, válassza ezt a beállítást.</span><span class="sxs-lookup"><span data-stu-id="26577-254">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="26577-255">Említett, a Service Bus ehhez a forgatókönyvhöz kivitelezhető lehetőség.</span><span class="sxs-lookup"><span data-stu-id="26577-255">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="26577-256">Hibák kezelése</span><span class="sxs-lookup"><span data-stu-id="26577-256">Handling failures</span></span> 

<span data-ttu-id="26577-257">Nincsenek három általános osztályok nem kell figyelembe venni.</span><span class="sxs-lookup"><span data-stu-id="26577-257">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="26577-258">Előfordulhat, hogy az alárendelt szolgáltatás nem átmeneti hiba, amely minden, amely nem valószínű, hogy eltűnik önmagában hiba.</span><span class="sxs-lookup"><span data-stu-id="26577-258">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="26577-259">Nem tranziens hibák normál hibaállapotokat, például egy metódusnak érvénytelen a megadott tartalmazza.</span><span class="sxs-lookup"><span data-stu-id="26577-259">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="26577-260">Is, nem kezelt kivételeket az alkalmazáskód vagy egy folyamat összeomló.</span><span class="sxs-lookup"><span data-stu-id="26577-260">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="26577-261">Ilyen hiba akkor fordul elő, ha a teljes üzleti tranzakció hibaként kell megjelölni.</span><span class="sxs-lookup"><span data-stu-id="26577-261">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="26577-262">Elképzelhető, hogy más lépéseket ugyanabban a tranzakcióban már sikeresen telepített szükségessé.</span><span class="sxs-lookup"><span data-stu-id="26577-262">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="26577-263">(Kompenzációs tranzakciók lásd alább.)</span><span class="sxs-lookup"><span data-stu-id="26577-263">(See Compensating Transactions, below.)</span></span>
 
2. <span data-ttu-id="26577-264">Az alárendelt szolgáltatás problémákat tapasztalhat a például a hálózati időtúllépés átmeneti hiba történt.</span><span class="sxs-lookup"><span data-stu-id="26577-264">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="26577-265">Ezek a hibák gyakran megoldhatók egyszerűen újra próbálkozik a hívást.</span><span class="sxs-lookup"><span data-stu-id="26577-265">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="26577-266">Ha egy bizonyos számú kísérlet után továbbra is sikertelen a művelet, nem átmeneti hiba figyelembe.</span><span class="sxs-lookup"><span data-stu-id="26577-266">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span> 

3. <span data-ttu-id="26577-267">A Feladatütemező szolgáltatás előfordulhat, hogy fault (például azért, mert a csomópont összeomlik).</span><span class="sxs-lookup"><span data-stu-id="26577-267">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="26577-268">Ebben az esetben Kubernetes megjelenik a szolgáltatás egy új példányát.</span><span class="sxs-lookup"><span data-stu-id="26577-268">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="26577-269">Már folyamatban lévő tranzakciók, kell folytatni.</span><span class="sxs-lookup"><span data-stu-id="26577-269">However, any transactions that were already in progress must be resumed.</span></span> 

## <a name="compensating-transactions"></a><span data-ttu-id="26577-270">Kompenzációs tranzakciók</span><span class="sxs-lookup"><span data-stu-id="26577-270">Compensating transactions</span></span>

<span data-ttu-id="26577-271">Nem átmeneti hiba akkor fordul elő, ha az aktuális tranzakció lehet egy *részben sikertelen* állapotba, ahol egy vagy több lépése már sikeresen befejeződött.</span><span class="sxs-lookup"><span data-stu-id="26577-271">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="26577-272">Például ha a dron szolgáltatás már ütemezve egy dron, a dron kell szakítható meg.</span><span class="sxs-lookup"><span data-stu-id="26577-272">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="26577-273">Ebben az esetben az alkalmazást kell visszavonja a lépéseket, a sikeresen telepített egy [Compensating tranzakció](../patterns/compensating-transaction.md).</span><span class="sxs-lookup"><span data-stu-id="26577-273">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="26577-274">Bizonyos esetekben kell erre a külső rendszerek vagy akár egy kézi művelet szerint.</span><span class="sxs-lookup"><span data-stu-id="26577-274">In some cases, this must be done by an external system or even by a manual process.</span></span> 

<span data-ttu-id="26577-275">Ha tranzakciók kompenzációs logika összetett, érdemes lehet külön szolgáltatás létrehozása a folyamat felelős.</span><span class="sxs-lookup"><span data-stu-id="26577-275">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="26577-276">Az a dron továbbítási alkalmazást hozhat létre a Feladatütemező szolgáltatás egy dedikált várólista, a sikertelen műveleteket helyezi.</span><span class="sxs-lookup"><span data-stu-id="26577-276">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="26577-277">Egy külön mikroszolgáltatási, a felügyelő nevű olvassa be ebből a várólistából, és meghívja a API törlése a szolgáltatásokat, amelyeket a helyesbítéshez.</span><span class="sxs-lookup"><span data-stu-id="26577-277">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="26577-278">Ez a módosítás a [Feladatütemező ügynök felügyelő mintát][scheduler-agent-supervisor].</span><span class="sxs-lookup"><span data-stu-id="26577-278">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="26577-279">A felügyeleti szolgáltatás eltarthat más műveleteket is, például szöveg vagy e-mail a felhasználó értesítése, vagy egy riasztást küldjön egy műveletek irányítópultot.</span><span class="sxs-lookup"><span data-stu-id="26577-279">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span> 

![](./images/supervisor.png)

## <a name="idempotent-vs-non-idempotent-operations"></a><span data-ttu-id="26577-280">Az Idempotent vs az idempotent műveletek</span><span class="sxs-lookup"><span data-stu-id="26577-280">Idempotent vs non-idempotent operations</span></span>

<span data-ttu-id="26577-281">Minden kérést elveszhetnek, a Feladatütemező szolgáltatás biztosítania kell, hogy minden üzenet legalább egyszer feldolgozása.</span><span class="sxs-lookup"><span data-stu-id="26577-281">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="26577-282">Az Event Hubs képes garantálni, legalább egyszeri kézbesítési, ha az ügyfél ellenőrzőpontokat megfelelően.</span><span class="sxs-lookup"><span data-stu-id="26577-282">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="26577-283">A Feladatütemező szolgáltatás összeomlik, ha egy vagy több ügyfél kérelmeket feldolgozó közepén lehet.</span><span class="sxs-lookup"><span data-stu-id="26577-283">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="26577-284">Azokat az üzeneteket a rendszer az ütemező egy másik példánya észlelnie, majd újra fel kell dolgozni.</span><span class="sxs-lookup"><span data-stu-id="26577-284">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="26577-285">Mi történik, ha a kérés feldolgozása kétszer van?</span><span class="sxs-lookup"><span data-stu-id="26577-285">What happens if a request is processed twice?</span></span> <span data-ttu-id="26577-286">Fontos munka duplikálását elkerülje.</span><span class="sxs-lookup"><span data-stu-id="26577-286">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="26577-287">Amikor az összes a rendszer két dronok az ugyanazon csomag küldése nem szeretnénk.</span><span class="sxs-lookup"><span data-stu-id="26577-287">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="26577-288">Egyik módszer az, hogy az idempotent összes műveletek.</span><span class="sxs-lookup"><span data-stu-id="26577-288">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="26577-289">Egy műveletet az idempotent esetén többször hívható az anélkül további mellékhatásokkal első hívása után.</span><span class="sxs-lookup"><span data-stu-id="26577-289">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="26577-290">Más szóval ügyfél hívhat meg a műveletet egyszer, kétszer, vagy többször, és az eredmény ugyanaz lesz.</span><span class="sxs-lookup"><span data-stu-id="26577-290">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="26577-291">Alapvetően a szolgáltatás figyelmen kívül hagyja-ismétlődő hívások.</span><span class="sxs-lookup"><span data-stu-id="26577-291">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="26577-292">A mellékhatással működő kell lennie az idempotent mód esetén a szolgáltatás képes észlelni az ismétlődő hívások kell lennie.</span><span class="sxs-lookup"><span data-stu-id="26577-292">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="26577-293">Például lehet a hívó hozzárendelés azonosítója ahelyett, hogy a szolgáltatás létrehozása egy új.</span><span class="sxs-lookup"><span data-stu-id="26577-293">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="26577-294">A szolgáltatás majd ellenőrizheti az ismétlődő azonosító.</span><span class="sxs-lookup"><span data-stu-id="26577-294">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="26577-295">A HTTP-specifikáció szerint, hogy GET, PUT és DELETE módszerek idempotent kell lennie.</span><span class="sxs-lookup"><span data-stu-id="26577-295">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="26577-296">POST metódus nem garantált, hogy az idempotent lehet.</span><span class="sxs-lookup"><span data-stu-id="26577-296">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="26577-297">Ha a POST metódussal hoz létre egy új erőforrást, akkor általában nem garantálja, hogy a művelet nem idempotent.</span><span class="sxs-lookup"><span data-stu-id="26577-297">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span> 

<span data-ttu-id="26577-298">Nincs mindig egyszerű idempotent metódus írása.</span><span class="sxs-lookup"><span data-stu-id="26577-298">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="26577-299">Lehetősége van az ütemezőt, hogy minden tranzakció tartós tárolójában előrehaladását úgy követheti nyomon.</span><span class="sxs-lookup"><span data-stu-id="26577-299">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="26577-300">Amikor egy üzenetet feldolgozza, lenne, a tartós tárolójában állapotát.</span><span class="sxs-lookup"><span data-stu-id="26577-300">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="26577-301">Minden lépés után azt kellene írni a eredménye.</span><span class="sxs-lookup"><span data-stu-id="26577-301">After each step, it would write the result to the store.</span></span> <span data-ttu-id="26577-302">Ez a megközelítés a teljesítményre gyakorolt hatása lehet.</span><span class="sxs-lookup"><span data-stu-id="26577-302">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="26577-303">Példa: Az Idempotent műveletek</span><span class="sxs-lookup"><span data-stu-id="26577-303">Example: Idempotent operations</span></span>

<span data-ttu-id="26577-304">A HTTP-specifikáció szerint PUT módszerek idempotent kell lennie.</span><span class="sxs-lookup"><span data-stu-id="26577-304">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="26577-305">A meghatározás meghatározza, hogy az idempotent ily módon:</span><span class="sxs-lookup"><span data-stu-id="26577-305">The specification defines idempotent this way:</span></span>

>  <span data-ttu-id="26577-306">A kérési metódust akkor tekinthető "idempotent", ha a tervezett hatása a kiszolgálón, ez a módszer több azonos kérelmek megegyezik a hatás egyetlen ilyen kérelem.</span><span class="sxs-lookup"><span data-stu-id="26577-306">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the   same as the effect for a single such request.</span></span> <span data-ttu-id="26577-307">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="26577-307">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="26577-308">Fontos PUT és a FELADÁS egy vagy több szemantikájú új entitás létrehozásakor közötti különbségek megértése.</span><span class="sxs-lookup"><span data-stu-id="26577-308">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="26577-309">Mindkét esetben az ügyfél elküldi egy entitást képviselő alakot a kérés törzsében.</span><span class="sxs-lookup"><span data-stu-id="26577-309">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="26577-310">Az URI azonosító szerinti azonban különböző.</span><span class="sxs-lookup"><span data-stu-id="26577-310">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="26577-311">A POST metódus az URI új entitás, például egy gyűjtemény szülő erőforrását jelöli.</span><span class="sxs-lookup"><span data-stu-id="26577-311">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="26577-312">Például hozzon létre egy új kézbesítési, az URI azonosító lehet `/api/deliveries`.</span><span class="sxs-lookup"><span data-stu-id="26577-312">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="26577-313">A kiszolgáló az entitások, és hozzárendeli egy új URI, például a `/api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="26577-313">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="26577-314">Ezt az URI eredmény abban az esetben a helyet megjelölő fejlécet a válasz.</span><span class="sxs-lookup"><span data-stu-id="26577-314">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="26577-315">Minden alkalommal, amikor az ügyfél elküldi a kérelmet, a kiszolgáló hoz létre egy új entitást egy új URI.</span><span class="sxs-lookup"><span data-stu-id="26577-315">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="26577-316">Egy PUT metódust az URI azonosítja az entitást.</span><span class="sxs-lookup"><span data-stu-id="26577-316">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="26577-317">Már létezik egy entitás, hogy az URI-azonosítóhoz, ha a kiszolgáló lecseréli a meglévő entitás a verziót a kérelemben.</span><span class="sxs-lookup"><span data-stu-id="26577-317">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="26577-318">Ha adott URI nem entitás létezik, a kiszolgáló létrehoz egy.</span><span class="sxs-lookup"><span data-stu-id="26577-318">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="26577-319">Tegyük fel az ügyfél elküldi a PUT kérelmek `api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="26577-319">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="26577-320">Feltételezve, hogy nincs kézbesítését, hogy az URI-azonosítójú, a kiszolgáló létrehoz egy újat.</span><span class="sxs-lookup"><span data-stu-id="26577-320">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="26577-321">Miután az ügyfél elküldi a kérésben újra, ha a kiszolgáló lecseréli a meglévő entitás.</span><span class="sxs-lookup"><span data-stu-id="26577-321">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="26577-322">Ez a kézbesítési szolgáltatás végrehajtása a PUT metódust.</span><span class="sxs-lookup"><span data-stu-id="26577-322">Here is the Delivery service's implementation of the PUT method.</span></span> 

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="26577-323">Várható, hogy legtöbb kérelem létrehoz egy új entitást, így optimistically metódushívások `CreateAsync` a tárház objektum, majd kezeli az erőforrás helyette frissítésével duplikált-resource kivételei.</span><span class="sxs-lookup"><span data-stu-id="26577-323">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span> 

> [!div class="nextstepaction"]
> [<span data-ttu-id="26577-324">API-átjárókkal</span><span class="sxs-lookup"><span data-stu-id="26577-324">API gateways</span></span>](./gateway.md)

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md