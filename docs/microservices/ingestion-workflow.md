---
title: Adatfeldolgozás és munkafolyamatok a mikroszolgáltatások
description: Adatfeldolgozás és munkafolyamatok a mikroszolgáltatások
author: MikeWasson
ms.date: 10/23/2018
ms.topic: guide
ms.service: architecture-center
ms.subservice: reference-architecture
ms.custom: microservices
ms.openlocfilehash: a36d2b4c7bfd2b26d5e1de44ddd8005fbce4bdd2
ms.sourcegitcommit: 579c39ff4b776704ead17a006bf24cd4cdc65edd
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 04/17/2019
ms.locfileid: "59640855"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="c7bea-103">Mikroszolgáltatások tervezése: Adatfeldolgozás és munkafolyamatok</span><span class="sxs-lookup"><span data-stu-id="c7bea-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="c7bea-104">Mikroszolgáltatások gyakran rendelkeznek egy munkafolyamatot egy tranzakció több szolgáltatást is.</span><span class="sxs-lookup"><span data-stu-id="c7bea-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="c7bea-105">A munkafolyamat megbízható; kell lennie. nem lehet tranzakció megszakad vagy részlegesen befejezett állapotban hagyja őket.</span><span class="sxs-lookup"><span data-stu-id="c7bea-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="c7bea-106">Emellett fontos szabályozni azt a bejövő kérelmek feldolgozási sebességet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="c7bea-107">Sok kis szolgáltatással kommunikál egymással a bejövő kérések hirtelen kiugrásai túlterhelhetik futó a szolgáltatások közötti kommunikációt eredményezhet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span>

![A betöltési munkafolyamatának ábrája](./images/ingestion-workflow.png)

> [!NOTE]
> <span data-ttu-id="c7bea-109">Ez a cikk egy mikroszolgáltatás-alapú referenciaimplementációt nevű alapul a [Drone Delivery alkalmazás](./design/index.md).</span><span class="sxs-lookup"><span data-stu-id="c7bea-109">This article is based on a microservices reference implementation called the [Drone Delivery application](./design/index.md).</span></span>

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="c7bea-110">A drone delivery munkafolyamat</span><span class="sxs-lookup"><span data-stu-id="c7bea-110">The drone delivery workflow</span></span>

<span data-ttu-id="c7bea-111">A Drone Delivery alkalmazást a következő műveleteket kell elvégezni egy kézbesítési ütemezése:</span><span class="sxs-lookup"><span data-stu-id="c7bea-111">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="c7bea-112">Ellenőrizze a felhasználói fiókhoz (szolgáltatásának) állapotát.</span><span class="sxs-lookup"><span data-stu-id="c7bea-112">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="c7bea-113">Hozzon létre egy új csomag entitás (csomag szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="c7bea-113">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="c7bea-114">Ellenőrzés külső bárminemű a szállítási, szükséges-e a begyűjtés és a továbbítás helyeken alapuló (külső közlekedési szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="c7bea-114">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="c7bea-115">Ütemezzen egy drónt felvételre (Drónos szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="c7bea-115">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="c7bea-116">Hozzon létre egy új kézbesítési entitás (Tartalomkézbesítési szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="c7bea-116">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="c7bea-117">Ez a központi eleme a teljes alkalmazást, így a teljes körű folyamatot, valamint megbízható, nagy teljesítményű kell lennie.</span><span class="sxs-lookup"><span data-stu-id="c7bea-117">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="c7bea-118">Egyes adott kihívást vonhat:</span><span class="sxs-lookup"><span data-stu-id="c7bea-118">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="c7bea-119">**Terheléskiegyenlítés**.</span><span class="sxs-lookup"><span data-stu-id="c7bea-119">**Load leveling**.</span></span> <span data-ttu-id="c7bea-120">Túl sok ügyfél kérést túlterhelhetik eredményezhet hálózati forgalmat a rendszer.</span><span class="sxs-lookup"><span data-stu-id="c7bea-120">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="c7bea-121">Azt is túlterhelhetik háttérrendszer függőségeit, például a storage vagy a távoli szolgáltatások.</span><span class="sxs-lookup"><span data-stu-id="c7bea-121">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="c7bea-122">Ezek a szolgáltatások meghívása őket, a rendszer ellennyomás létrehozása szabályozás előfordulhat, hogy reagálni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-122">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="c7bea-123">Ezért fontos a kérelmeket a rendszer egy puffer, vagy a feldolgozáshoz várólistára helyezésével érkező terhelés.</span><span class="sxs-lookup"><span data-stu-id="c7bea-123">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span>

- <span data-ttu-id="c7bea-124">**Garantált kézbesítés**.</span><span class="sxs-lookup"><span data-stu-id="c7bea-124">**Guaranteed delivery**.</span></span> <span data-ttu-id="c7bea-125">Az Adatbetöltési összetevő bármely ügyfél kérelmeket elkerüléséhez biztosítania kell, legalább egyszeri kézbesítési üzenetek.</span><span class="sxs-lookup"><span data-stu-id="c7bea-125">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span>

- <span data-ttu-id="c7bea-126">**Hibakezelés**.</span><span class="sxs-lookup"><span data-stu-id="c7bea-126">**Error handling**.</span></span> <span data-ttu-id="c7bea-127">Ha a szolgáltatások egy hibakódot ad vissza, vagy nem átmeneti hibát tapasztal, a tartalomkézbesítési nem lehet ütemezni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-127">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="c7bea-128">Egy hibakódot jelezheti a várt hibát (például a felhasználói fiók fel van függesztve) vagy egy váratlan kiszolgálóhiba (HTTP 5xx).</span><span class="sxs-lookup"><span data-stu-id="c7bea-128">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="c7bea-129">Elképzelhető, hogy egy szolgáltatás még nem érhető el, a hálózati hívás időtúllépés miatt.</span><span class="sxs-lookup"><span data-stu-id="c7bea-129">A service might also be unavailable, causing the network call to time out.</span></span>

<span data-ttu-id="c7bea-130">Először áttekintjük az Adatbetöltési oldala egyenlet &mdash; hogyan a rendszer a bejövő felhasználói kérések magasabb átviteli sebességen feldolgozására képes.</span><span class="sxs-lookup"><span data-stu-id="c7bea-130">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="c7bea-131">Azt fogjuk fontolja meg a drone delivery alkalmazás hogyan valósíthat meg egy megbízható munkafolyamatot.</span><span class="sxs-lookup"><span data-stu-id="c7bea-131">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="c7bea-132">Azt tapasztaltuk, hogy az Adatbetöltési alrendszer a kialakítás befolyásolja a munkafolyamat-háttérrendszer.</span><span class="sxs-lookup"><span data-stu-id="c7bea-132">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span>

## <a name="ingestion"></a><span data-ttu-id="c7bea-133">Adatbetöltési</span><span class="sxs-lookup"><span data-stu-id="c7bea-133">Ingestion</span></span>

<span data-ttu-id="c7bea-134">Üzleti követelmények alapján, a fejlesztői csapat azonosítja a következő nem funkcionális követelmények támogatunk:</span><span class="sxs-lookup"><span data-stu-id="c7bea-134">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="c7bea-135">10e kérelmek/s folyamatos teljesítményt.</span><span class="sxs-lookup"><span data-stu-id="c7bea-135">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="c7bea-136">Tudja kezelni az adatforgalmi csúcsokhoz legfeljebb 50 ezer/mp nélkül ügyfél kérelmeket, vagy túllépik az időkorlátot.</span><span class="sxs-lookup"><span data-stu-id="c7bea-136">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="c7bea-137">Kisebb, mint 500ms késés 99 %-a.</span><span class="sxs-lookup"><span data-stu-id="c7bea-137">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="c7bea-138">A követelmény alkalmanként adatforgalmi kiugrások kezelésére tervezési kihívást mutat be.</span><span class="sxs-lookup"><span data-stu-id="c7bea-138">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="c7bea-139">Elméletileg a rendszer sikerült horizontálisan a maximális várt forgalom kezeléséhez.</span><span class="sxs-lookup"><span data-stu-id="c7bea-139">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="c7bea-140">Azonban kiépítése, hogy számos erőforrás nagyon hatékony.</span><span class="sxs-lookup"><span data-stu-id="c7bea-140">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="c7bea-141">A legtöbb esetben az alkalmazás nem kell, hogy mekkora kapacitást, így lesz tétlen Processzormagok költségszámítási money érték hozzáadása nélkül.</span><span class="sxs-lookup"><span data-stu-id="c7bea-141">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="c7bea-142">Jobb módszer, hogy a bejövő kérelmek elhelyezi egy puffer, és lehetővé teszik a puffer terheléselosztóként jár el.</span><span class="sxs-lookup"><span data-stu-id="c7bea-142">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="c7bea-143">Ezzel a kialakítással kell, hogy a szolgáltatás tudja kezelni a maximális feldolgozási sebességét rövid időszakokra, de a háttérszolgáltatások csak a maximális fenntartható terhelés kezeléséhez van szükség.</span><span class="sxs-lookup"><span data-stu-id="c7bea-143">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="c7bea-144">Az előtér: pufferelés, a háttérszolgáltatások nem kell nagy adatforgalmi kiugrások kezelésére.</span><span class="sxs-lookup"><span data-stu-id="c7bea-144">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="c7bea-145">A Drone Delivery alkalmazást szükséges méreten [Azure Event Hubs](/azure/event-hubs/) terheléskiegyenlítési esetében megfelelő választás.</span><span class="sxs-lookup"><span data-stu-id="c7bea-145">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="c7bea-146">Az Event Hubs biztosít alacsony késéssel és nagy átviteli sebességet, és a egy költséghatékony megoldás Adatbetöltési nagy mennyiségben.</span><span class="sxs-lookup"><span data-stu-id="c7bea-146">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span>

<span data-ttu-id="c7bea-147">Tesztelés használtuk egy Standard szintű event hubs átviteli egységeket 100 és 32 partícióval.</span><span class="sxs-lookup"><span data-stu-id="c7bea-147">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="c7bea-148">Megállapítottuk, hogy körülbelül 32 ezer esemény / s betöltési, körül 90ms késéssel.</span><span class="sxs-lookup"><span data-stu-id="c7bea-148">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="c7bea-149">Az alapértelmezett korlát jelenleg 20 átviteli egység, de az Azure-ügyfelek kérhet további átviteli egységek ügyfélszolgálatunknak küldött támogatási kérést.</span><span class="sxs-lookup"><span data-stu-id="c7bea-149">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="c7bea-150">Lásd: [Event Hubs-kvótákról](/azure/event-hubs/event-hubs-quotas) további információt.</span><span class="sxs-lookup"><span data-stu-id="c7bea-150">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="c7bea-151">A metrikák, a számos tényező befolyásolhatja a teljesítményt, például az üzenetek hasznos adatainak mérete, mivel így nem értelmezi őket alapként.</span><span class="sxs-lookup"><span data-stu-id="c7bea-151">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="c7bea-152">További átviteli van szükség, ha a feldolgozó szolgáltatás szegmens egynél több eseményközpont között is.</span><span class="sxs-lookup"><span data-stu-id="c7bea-152">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="c7bea-153">A még nagyobb átviteli sebességet [Event Hubs dedikált](/azure/event-hubs/event-hubs-dedicated-overview) kínál egybérlős üzemelő példánya, amely a bejövő képes kezelni másodpercenként több mint 2 millió esemény.</span><span class="sxs-lookup"><span data-stu-id="c7bea-153">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="c7bea-154">Fontos megérteni, hogyan érheti el az Event Hubs, az ilyen nagy teljesítményű, mert, amely hatással van, hogy egy ügyfél foglaljanak Event hubs szolgáltatástól érkező üzenetek.</span><span class="sxs-lookup"><span data-stu-id="c7bea-154">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="c7bea-155">Az Event Hubs nem valósít meg egy *várólista*.</span><span class="sxs-lookup"><span data-stu-id="c7bea-155">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="c7bea-156">Ehelyett valósít meg egy *eseménystream*.</span><span class="sxs-lookup"><span data-stu-id="c7bea-156">Rather, it implements an *event stream*.</span></span>

<span data-ttu-id="c7bea-157">Az üzenetsor az egyes fogyasztók távolíthatja el egy üzenetet az üzenetsorból, és a következő fogyasztói az üzenet nem jelenik meg.</span><span class="sxs-lookup"><span data-stu-id="c7bea-157">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="c7bea-158">Üzenetsorok azt ezért lehetővé teszik, hogy egy [versengő felhasználók mintája](../patterns/competing-consumers.md) üzenetek párhuzamos feldolgozását, és a méretezhetőség javítása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-158">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="c7bea-159">A nagyobb rugalmasság érdekében a fogyasztó az üzenet a zárolási tárolja, és a zárolás feloldása, ha az üzenet feldolgozása megtörtént.</span><span class="sxs-lookup"><span data-stu-id="c7bea-159">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="c7bea-160">Ha a feldolgozó meghibásodik &mdash; például a csomóponton futó szoftverleállások &mdash; zárolási túllépi az időkorlátot, és az üzenet vissza alakzatot a várólistára kerül.</span><span class="sxs-lookup"><span data-stu-id="c7bea-160">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span>

![Várólista szemantika ábrája](./images/queue-semantics.png)

<span data-ttu-id="c7bea-162">Az Event Hubs, másrészről, használja a streamelési szemantikáját.</span><span class="sxs-lookup"><span data-stu-id="c7bea-162">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="c7bea-163">A fogyasztók olvashatja a streamet, egymástól függetlenül saját tempójában.</span><span class="sxs-lookup"><span data-stu-id="c7bea-163">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="c7bea-164">Mindegyik felhasználó az aktuális pozícióját az adatfolyamban nyomon gondoskodik a felelős.</span><span class="sxs-lookup"><span data-stu-id="c7bea-164">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="c7bea-165">A fogyasztó kell írni az aktuális pozícióját adattárolásra néhány előre meghatározott időközönként.</span><span class="sxs-lookup"><span data-stu-id="c7bea-165">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="c7bea-166">Így ha az ügyfél egy tartalék (például a fogyasztói szoftverleállások vagy a gazdagép nem), majd egy új példányt folytathatja a utolsó feljegyzett beosztás érkező adatfolyam olvasása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-166">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="c7bea-167">Ez a folyamat *ellenőrzőpontok*.</span><span class="sxs-lookup"><span data-stu-id="c7bea-167">This process is called *checkpointing*.</span></span>

<span data-ttu-id="c7bea-168">Teljesítménybeli megfontolások miatt az olyan fogyasztói általában nem ellenőrzőpont után minden üzenetet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-168">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="c7bea-169">Ehelyett azt rögzített időköz, például a feldolgozás után ad hozzá ellenőrzőpontokat *n* üzeneteket, vagy minden *n* másodperc.</span><span class="sxs-lookup"><span data-stu-id="c7bea-169">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="c7bea-170">Következtében ha egy feldolgozó nem jár sikerrel, néhány esemény előfordulhat, hogy első feldolgozása kétszer, mert egy új példányt mindig szerzi be a legutóbbi ellenőrzőponttól.</span><span class="sxs-lookup"><span data-stu-id="c7bea-170">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="c7bea-171">Nincs a kompromisszummal jár: Gyakori ellenőrzőpontok összeállítása hátrányosan befolyásolhatja a teljesítményt, de a ritka ellenőrzőpontok jelenti azt, további események fog játszani hiba után.</span><span class="sxs-lookup"><span data-stu-id="c7bea-171">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>

![A stream szemantika ábrája](./images/stream-semantics.png)

<span data-ttu-id="c7bea-173">Az Event Hubs nem versengő fogyasztó számára készült.</span><span class="sxs-lookup"><span data-stu-id="c7bea-173">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="c7bea-174">Több fogyasztó tudja olvasni a stream, bár egyes is járja a stream egymástól függetlenül.</span><span class="sxs-lookup"><span data-stu-id="c7bea-174">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="c7bea-175">Ehelyett az Event Hubs egy particionált felhasználói mintát használ.</span><span class="sxs-lookup"><span data-stu-id="c7bea-175">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="c7bea-176">Az event hub legfeljebb 32 partícióval rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="c7bea-176">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="c7bea-177">Horizontális skálázás külön fogyasztók rendel mindegyik partíció érhető el.</span><span class="sxs-lookup"><span data-stu-id="c7bea-177">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="c7bea-178">Ez mit jelent a drone delivery munkafolyamat?</span><span class="sxs-lookup"><span data-stu-id="c7bea-178">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="c7bea-179">A teljes kiaknázásához az Event Hubs lekéréséhez a kézbesítési ütemezési minden üzenet feldolgozása után áthelyezni a következő nem várja.</span><span class="sxs-lookup"><span data-stu-id="c7bea-179">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="c7bea-180">Ebben az esetben, amely azt fogják tölteni legtöbbször a Várakozás a hálózati hívások végrehajtásához.</span><span class="sxs-lookup"><span data-stu-id="c7bea-180">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="c7bea-181">Ehelyett azt kell feldolgoznia az üzenetek aszinkron hívásokat a háttérszolgáltatások használatával párhuzamosan kötegek.</span><span class="sxs-lookup"><span data-stu-id="c7bea-181">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="c7bea-182">Ahogy láthatjuk, a megfelelő ellenőrzőpont-stratégia kiválasztása az is fontos.</span><span class="sxs-lookup"><span data-stu-id="c7bea-182">As we'll see, choosing the right checkpointing strategy is also important.</span></span>

## <a name="workflow"></a><span data-ttu-id="c7bea-183">Munkafolyamat</span><span class="sxs-lookup"><span data-stu-id="c7bea-183">Workflow</span></span>

<span data-ttu-id="c7bea-184">Megvizsgáltunk, beolvasása, illetve az üzenetek feldolgozására három lehetőség: Event Processor Host, Service Bus-üzenetsorok és a IoTHub React könyvtárban.</span><span class="sxs-lookup"><span data-stu-id="c7bea-184">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="c7bea-185">Választottuk IoTHub reagálni, de ennek megértéséhez segít az Event Processor Host indítása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-185">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span>

### <a name="event-processor-host"></a><span data-ttu-id="c7bea-186">Event Processor Host</span><span class="sxs-lookup"><span data-stu-id="c7bea-186">Event Processor Host</span></span>

<span data-ttu-id="c7bea-187">Event Processor Host üzenet kötegelés lett tervezve.</span><span class="sxs-lookup"><span data-stu-id="c7bea-187">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="c7bea-188">Az alkalmazás megvalósítja a `IEventProcessor` felületet, és a processzor gazdagép hoz létre egy esemény processzorpéldány minden partíció esetében az eseményközpontban.</span><span class="sxs-lookup"><span data-stu-id="c7bea-188">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="c7bea-189">Az Event Processor Host ekkor meghívja a minden egyes eseményfeldolgozó `ProcessEventsAsync` eseményüzenetek váró metódust.</span><span class="sxs-lookup"><span data-stu-id="c7bea-189">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="c7bea-190">Az ellenőrzőpont belül az Alkalmazásvezérlés a `ProcessEventsAsync` metódust, és az Event Processor Host ellenőrzőpontot ír az Azure storage.</span><span class="sxs-lookup"><span data-stu-id="c7bea-190">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span>

<span data-ttu-id="c7bea-191">Egy partíción belül Event Processor Host megvárja, amíg `ProcessEventsAsync` vissza úgy, a következő köteg meghívása előtt.</span><span class="sxs-lookup"><span data-stu-id="c7bea-191">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="c7bea-192">Ez a megközelítés leegyszerűsíti a programozási modell, mert a feldolgozás eseménykód nem kell ismételten belépő.</span><span class="sxs-lookup"><span data-stu-id="c7bea-192">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="c7bea-193">Azonban azt is jelenti, hogy az eseményfeldolgozó kezeli egy kötegelt egyszerre, és ez gates a sebesség, amellyel a Processor Host pump is a üzeneteket.</span><span class="sxs-lookup"><span data-stu-id="c7bea-193">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE]
> <span data-ttu-id="c7bea-194">A processzor gazdagép ténylegesen nem *várjon* abban az értelemben, a szál blokkolása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-194">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="c7bea-195">A `ProcessEventsAsync` metódus aszinkron, ezért az Processor Host végezhet egyéb műveleteket, amíg befejeződik a metódus.</span><span class="sxs-lookup"><span data-stu-id="c7bea-195">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="c7bea-196">De azt nem az adott partíció egy másik üzenetköteget mindaddig, amíg a metódus adja vissza.</span><span class="sxs-lookup"><span data-stu-id="c7bea-196">But it won't deliver another batch of messages for that partition until the method returns.</span></span>

<span data-ttu-id="c7bea-197">A drone alkalmazásban egy üzenetköteget párhuzamosan lehet feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-197">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="c7bea-198">De Várakozás a teljes kötegelt végrehajtásához a szűk keresztmetszetet is okozhatnak.</span><span class="sxs-lookup"><span data-stu-id="c7bea-198">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="c7bea-199">Feldolgozási csak lehet olyan gyors kötegelt belül a leglassabb üzenetnek számít.</span><span class="sxs-lookup"><span data-stu-id="c7bea-199">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="c7bea-200">Válaszidők bármilyen változása hozhat létre egy "hosszú tail," ahol néhány lassúak a válaszok húzza le az egész rendszert.</span><span class="sxs-lookup"><span data-stu-id="c7bea-200">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="c7bea-201">A teljesítménytesztek kimutatta, hogy azt nem érte el a célként megadott átviteli sebességet, ezzel a megközelítéssel.</span><span class="sxs-lookup"><span data-stu-id="c7bea-201">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="c7bea-202">Ez a kód *nem* jelenti azt, hogy lehetőleg ne Event Processor Host használatával.</span><span class="sxs-lookup"><span data-stu-id="c7bea-202">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="c7bea-203">A nagy teljesítményű, kerülje bármely hosszú lefutású feladat található, de a `ProcessEventsAsync` metódust.</span><span class="sxs-lookup"><span data-stu-id="c7bea-203">But for high throughput, avoid doing any long-running tasks inside the `ProcessEventsAsync` method.</span></span> <span data-ttu-id="c7bea-204">Az egyes kötegek gyorsan feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-204">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="c7bea-205">IotHub React</span><span class="sxs-lookup"><span data-stu-id="c7bea-205">IotHub React</span></span>

<span data-ttu-id="c7bea-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) Akka Streamek könyvtár az Eseményközpontból érkező események olvasását.</span><span class="sxs-lookup"><span data-stu-id="c7bea-206">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="c7bea-207">Akka Streamek egy stream-alapú programozási keretrendszerről, amely megvalósítja a [reaktív Streamek](https://www.reactive-streams.org/) specifikációnak.</span><span class="sxs-lookup"><span data-stu-id="c7bea-207">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="c7bea-208">Hatékony streamelési folyamatok létrehozásával, ahol az összes streamelési műveleteket aszinkron módon történik, és a folyamat szabályosan kezeli ellennyomás hozhat létre egy megoldást kínál.</span><span class="sxs-lookup"><span data-stu-id="c7bea-208">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="c7bea-209">Ellennyomás akkor történik, ha az eseményforrás eredményez, mint az alárendelt fogyasztók fogadhatja gyorsabb ütemben események &mdash; amelynek pontosan az a helyzet akkor, ha a a drone delivery rendszer nevű kategóriáé a forgalom.</span><span class="sxs-lookup"><span data-stu-id="c7bea-209">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="c7bea-210">Ha háttérszolgáltatások lassabban, IoTHub React lelassulnak.</span><span class="sxs-lookup"><span data-stu-id="c7bea-210">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="c7bea-211">Kapacitás nő, ha IoTHub React fogja leküldeni a további üzeneteket, a folyamat keresztül.</span><span class="sxs-lookup"><span data-stu-id="c7bea-211">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="c7bea-212">Streamelés az Event hubs-Eseményközpontok eseményeinek nagyon természetes programozási modellt Akka Streameket is.</span><span class="sxs-lookup"><span data-stu-id="c7bea-212">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="c7bea-213">Helyett hurkolás események kötegelt keresztül, számos műveletet minden egyes esemény érvényesek, és lehetővé teszik a Akka Streamek kezelni, a streamelési határozza meg.</span><span class="sxs-lookup"><span data-stu-id="c7bea-213">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="c7bea-214">Akka Streamek határozza meg, hogy a streamelési folyamat *források*, *folyamatok*, és *fogadók*.</span><span class="sxs-lookup"><span data-stu-id="c7bea-214">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="c7bea-215">Egy adatforrás generál egy kimeneti adatfolyamba, egy folyamatot egy bemeneti stream feldolgozza, és létrehozza a kimeneti adatfolyamokat és egy fogadó felhasznál egy stream nélkül állít elő kimenetet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-215">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="c7bea-216">A Scheduler szolgáltatás, amely beállítja a Akka Streamek folyamat a következő kódot:</span><span class="sxs-lookup"><span data-stu-id="c7bea-216">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="c7bea-217">Ez a kód az Event Hubs konfigurálja a forrásaként.</span><span class="sxs-lookup"><span data-stu-id="c7bea-217">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="c7bea-218">A `map` utasítás deserializes egyes eseményüzenet be egy Java-osztály, amely egy kézbesítési kérést jelöli.</span><span class="sxs-lookup"><span data-stu-id="c7bea-218">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="c7bea-219">A `filter` utasítás eltávolítja az összes `null` az adatfolyamból objektumokat; ez az eset, amikor egy üzenet nem lehet deszerializálni elleni őröket.</span><span class="sxs-lookup"><span data-stu-id="c7bea-219">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="c7bea-220">A `via` utasítás csatlakoztatja a forrás egy folyamatot, amely minden egyes kézbesítési kérést dolgoz fel.</span><span class="sxs-lookup"><span data-stu-id="c7bea-220">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="c7bea-221">A `to` metódus csatlakoztatja a ellenőrzőpont gyűjtő, amely IoTHub React be van építve a folyamatot.</span><span class="sxs-lookup"><span data-stu-id="c7bea-221">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="c7bea-222">IoTHub React eseményfeldolgozó állomás, mint más ellenőrzőpontok stratégiát alkalmaz.</span><span class="sxs-lookup"><span data-stu-id="c7bea-222">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="c7bea-223">Ellenőrzőpontok a ellenőrzőpont gyűjtő, amely az a folyamat leállítása szakasz által írt.</span><span class="sxs-lookup"><span data-stu-id="c7bea-223">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="c7bea-224">Akka Streamek kialakítása lehetővé teszi, hogy a folyamat folytatásához a streamelési adatok, miközben a fogadó ír az ellenőrző pont.</span><span class="sxs-lookup"><span data-stu-id="c7bea-224">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="c7bea-225">Ez azt jelenti, hogy a felsőbb rétegbeli feldolgozás szakaszában nem várja meg, megtörténjen ellenőrzőpontok használata szükséges.</span><span class="sxs-lookup"><span data-stu-id="c7bea-225">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="c7bea-226">Konfigurálhatja az ellenőrzőpontok használata után időtúllépés vagy után adott számú üzenetet dolgozott.</span><span class="sxs-lookup"><span data-stu-id="c7bea-226">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="c7bea-227">A `deliveryProcessor` metódus a Akka Streamek folyamatot hoz létre:</span><span class="sxs-lookup"><span data-stu-id="c7bea-227">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(),
                        delivery.getMessageFromDevice().properties());

        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }

        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="c7bea-228">A folyamat meghívja a statikus `processDeliveryRequestAsync` metódushoz, amely a tényleges munkát üzenetek feldolgozására.</span><span class="sxs-lookup"><span data-stu-id="c7bea-228">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="c7bea-229">IoTHub reacttel méretezése</span><span class="sxs-lookup"><span data-stu-id="c7bea-229">Scaling with IoTHub React</span></span>

<span data-ttu-id="c7bea-230">A Scheduler szolgáltatás célja, hogy az egyes tárolópéldányok egyetlen partícióról olvas.</span><span class="sxs-lookup"><span data-stu-id="c7bea-230">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="c7bea-231">Például, ha az Event Hubs 32 partícióval rendelkezik, a Feladatütemező szolgáltatás üzembe helyezése 32 replikákkal rendelkező.</span><span class="sxs-lookup"><span data-stu-id="c7bea-231">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="c7bea-232">Ez lehetővé teszi nagy rugalmasságot biztosít a horizontális skálázást tekintetében.</span><span class="sxs-lookup"><span data-stu-id="c7bea-232">This allows for a lot of flexibility in terms of horizontal scaling.</span></span>

<span data-ttu-id="c7bea-233">Attól függően, a fürt méretét a fürtben egy csomópont lehet egynél több Scheduler szolgáltatás pod rajta való futtatásához.</span><span class="sxs-lookup"><span data-stu-id="c7bea-233">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="c7bea-234">Azonban ha a Scheduler szolgáltatás több erőforrást igényel, a fürt kiterjeszthető, annak érdekében, hogy a podok szét több csomópontot.</span><span class="sxs-lookup"><span data-stu-id="c7bea-234">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="c7bea-235">A teljesítménytesztek kimutatta, hogy a Scheduler szolgáltatás memória és a hozzászóláslánc-kötött, így teljesítmény nagy mértékben alárendelve, a virtuális gép mérete és a csomópontonként podok számát.</span><span class="sxs-lookup"><span data-stu-id="c7bea-235">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="c7bea-236">Minden példány tudnia kell, amely az Event Hubs particionálása olvasni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-236">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="c7bea-237">A partíciószám konfigurálásához meggyőződtünk előnye a [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) erőforrástípust a Kubernetesben.</span><span class="sxs-lookup"><span data-stu-id="c7bea-237">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="c7bea-238">Egy StatefulSet podok egy állandó azonosítója, amely tartalmaz egy numerikus indexszel rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="c7bea-238">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="c7bea-239">Pontosabban, a pod név `<statefulset name>-<index>`, és ez az érték érhető el a tárolóhoz, a Kubernetes használatával [lefelé irányuló API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span><span class="sxs-lookup"><span data-stu-id="c7bea-239">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="c7bea-240">Futási időben a Scheduler szolgáltatás beolvassa a podnév, és a pod index használja, mint a partícióazonosító.</span><span class="sxs-lookup"><span data-stu-id="c7bea-240">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="c7bea-241">Ha horizontális felskálázási még tovább a Scheduler szolgáltatás, hozzárendelhet egynél több pod event hub partíciónként, úgy, hogy az egyes partíciók több podok olvas.</span><span class="sxs-lookup"><span data-stu-id="c7bea-241">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="c7bea-242">Azonban ebben az esetben minden példány volna olvasni az események a hozzárendelt partícióban.</span><span class="sxs-lookup"><span data-stu-id="c7bea-242">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="c7bea-243">Ismétlődő feldolgozási elkerülése érdekében kell egy kivonatoló algoritmus használatára, hogy minden példány kihagyja az üzeneteket egy része felett.</span><span class="sxs-lookup"><span data-stu-id="c7bea-243">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="c7bea-244">Ezzel a módszerrel több olvasók használhatnak fel, a streamet, de minden üzenetet csak egy példány dolgoz fel.</span><span class="sxs-lookup"><span data-stu-id="c7bea-244">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span>

![Event hub-kivonatolás ábrája](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="c7bea-246">Service Bus-üzenetsorok</span><span class="sxs-lookup"><span data-stu-id="c7bea-246">Service Bus queues</span></span>

<span data-ttu-id="c7bea-247">Egy harmadik lehetőség, hogy mi számít az Event hubs szolgáltatástól érkező üzenetek másolása egy Service Bus-üzenetsorba, és majd a Scheduler szolgáltatás elolvasta az üzenetet a Service Bus.</span><span class="sxs-lookup"><span data-stu-id="c7bea-247">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="c7bea-248">Úgy tűnhet, meglepő írásakor a bejövő kérelmek csak, hogy másolja őket a Service Bus Event hubsba.</span><span class="sxs-lookup"><span data-stu-id="c7bea-248">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="c7bea-249">Azonban a cél volt, hogy az egyes szolgáltatások különböző előnyeit kihasználva: Az Event Hubs használatával a Service Bus egy versengő felhasználók mintája a számítási feladatok feldolgozásához a várólista szemantikát kihasználva számára a nagy forgalom, az adatforgalmi csúcsokhoz.</span><span class="sxs-lookup"><span data-stu-id="c7bea-249">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="c7bea-250">Ne feledje, hogy a célt a vendégteljesítmény kisebb, mint a várható terhelés, így feldolgozási a Service Bus-üzenetsorba nem kell lennie olyan gyors üzenetbetöltés.</span><span class="sxs-lookup"><span data-stu-id="c7bea-250">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>

<span data-ttu-id="c7bea-251">Ezzel a módszerrel proof-of-concept-implementáció érhető el, a 4 KB műveletek száma másodpercenként.</span><span class="sxs-lookup"><span data-stu-id="c7bea-251">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="c7bea-252">Ezeket a teszteket, amelyek bármely valós munkát nem tette meg, de egyszerűen hozzáadott egy rögzített mértékű késés szolgáltatásonként utánzatként funkcionáló háttérszolgáltatások használja.</span><span class="sxs-lookup"><span data-stu-id="c7bea-252">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="c7bea-253">Vegye figyelembe, hogy a teljesítmény-számok is sokkal kevesebb, mint a Service Bus elméleti maximális.</span><span class="sxs-lookup"><span data-stu-id="c7bea-253">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="c7bea-254">Az eltérés okai a következők:</span><span class="sxs-lookup"><span data-stu-id="c7bea-254">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="c7bea-255">Nem rendelkezik a különböző ügyfél-paraméterek, például a készlet kapcsolathoz megadott korlátot, a párhuzamos feldolgozás, a lehívott száma és a kötegméret fokú optimális értékeit.</span><span class="sxs-lookup"><span data-stu-id="c7bea-255">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="c7bea-256">A hálózati szűk I/O keresztmetszetek.</span><span class="sxs-lookup"><span data-stu-id="c7bea-256">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="c7bea-257">Felhasználása [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mód helyett [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), amely volt szükség, legalább egyszeri kézbesítési üzenetek biztosítása érdekében.</span><span class="sxs-lookup"><span data-stu-id="c7bea-257">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="c7bea-258">További teljesítménytesztek előfordulhat, hogy az alapvető ok felderítése és számunkra, hogy a problémák megoldásához.</span><span class="sxs-lookup"><span data-stu-id="c7bea-258">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="c7bea-259">Azonban IotHub React teljesül, a teljesítmény célt, ezért választottuk ezt a lehetőséget.</span><span class="sxs-lookup"><span data-stu-id="c7bea-259">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="c7bea-260">Mindemellett a Service Bus az ebben a forgatókönyvben kivitelezhető lehetőség.</span><span class="sxs-lookup"><span data-stu-id="c7bea-260">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="c7bea-261">Hibák</span><span class="sxs-lookup"><span data-stu-id="c7bea-261">Handling failures</span></span>

<span data-ttu-id="c7bea-262">Nincsenek fontolja meg a hiba három általános osztályba.</span><span class="sxs-lookup"><span data-stu-id="c7bea-262">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="c7bea-263">Előfordulhat, hogy az alárendelt szolgáltatás nem átmeneti hiba, amely minden hiba, amely nem valószínű, hogy megszabadítja önmagában.</span><span class="sxs-lookup"><span data-stu-id="c7bea-263">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="c7bea-264">Nem átmeneti hibák közé tartozik a normál hiba feltételek, például egy érvénytelen bemenet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-264">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="c7bea-265">Is, nem kezelt kivételeket az alkalmazáskód vagy egy folyamat összeomlik.</span><span class="sxs-lookup"><span data-stu-id="c7bea-265">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="c7bea-266">Az ilyen típusú hiba akkor fordul elő, ha a teljes üzleti tranzakció sikertelen kell megjelölni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-266">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="c7bea-267">Ugyanabban a tranzakcióban, amely sikeresen további lépések visszavonása szükség lehet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-267">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="c7bea-268">(A kompenzáló tranzakció, lásd alább.)</span><span class="sxs-lookup"><span data-stu-id="c7bea-268">(See Compensating Transactions, below.)</span></span>

2. <span data-ttu-id="c7bea-269">Egy alárendelt szolgáltatás például egy hálózati időtúllépés átmeneti hibát tapasztalhat.</span><span class="sxs-lookup"><span data-stu-id="c7bea-269">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="c7bea-270">Ezek a hibák gyakran megoldhatók egyszerűen hívása újrapróbálása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-270">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="c7bea-271">Ha a művelet egy bizonyos számú kísérlet után is sikertelen, figyelembe vette nem átmeneti hiba.</span><span class="sxs-lookup"><span data-stu-id="c7bea-271">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span>

3. <span data-ttu-id="c7bea-272">A Scheduler szolgáltatás előfordulhat, hogy tartalék (például azért, mert összeomlik, egy csomópont).</span><span class="sxs-lookup"><span data-stu-id="c7bea-272">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="c7bea-273">Ebben az esetben a Kubernetes megjelenik a szolgáltatás egy új példányát.</span><span class="sxs-lookup"><span data-stu-id="c7bea-273">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="c7bea-274">Azonban már folyamatban lévő tranzakciók kell folytatni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-274">However, any transactions that were already in progress must be resumed.</span></span>

## <a name="compensating-transactions"></a><span data-ttu-id="c7bea-275">Kompenzáló tranzakciók</span><span class="sxs-lookup"><span data-stu-id="c7bea-275">Compensating transactions</span></span>

<span data-ttu-id="c7bea-276">Nem átmeneti hiba történik, ha az aktuális tranzakció lehet egy *részben sikertelen* állapot, ahol egy vagy több lépést már sikeresen befejeződött.</span><span class="sxs-lookup"><span data-stu-id="c7bea-276">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="c7bea-277">Például ha a Drone szolgáltatás már ütemezve egy drónt, a drone kell megszakítva.</span><span class="sxs-lookup"><span data-stu-id="c7bea-277">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="c7bea-278">Ebben az esetben az alkalmazásnak kell, hogy sikeres volt-e, a lépések visszavonása egy [kompenzáló tranzakció](../patterns/compensating-transaction.md).</span><span class="sxs-lookup"><span data-stu-id="c7bea-278">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="c7bea-279">Bizonyos esetekben ez kell elvégezni egy külső rendszer, vagy akár egy manuális folyamat.</span><span class="sxs-lookup"><span data-stu-id="c7bea-279">In some cases, this must be done by an external system or even by a manual process.</span></span>

<span data-ttu-id="c7bea-280">Ha a kompenzáló tranzakciók logika összetett, érdemes lehet külön szolgáltatás létrehozása felelős a folyamat.</span><span class="sxs-lookup"><span data-stu-id="c7bea-280">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="c7bea-281">A Drone Delivery alkalmazás a Scheduler szolgáltatás sikertelen műveletek be egy dedikált üzenetsorba helyezi.</span><span class="sxs-lookup"><span data-stu-id="c7bea-281">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="c7bea-282">Külön mikroszolgáltatások, a felügyelő nevű ebből az üzenetsorból olvas, és meghívja a lemondás API a meghiúsult lépések kompenzációjához szükséges szolgáltatásokat.</span><span class="sxs-lookup"><span data-stu-id="c7bea-282">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="c7bea-283">Ez a kapcsolat egy változata a [Feladatütemező ügynök felügyeleti mintájának][scheduler-agent-supervisor].</span><span class="sxs-lookup"><span data-stu-id="c7bea-283">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="c7bea-284">A felügyeleti szolgáltatás előfordulhat, hogy más műveletek is, például szöveg vagy e-mailt a felhasználó értesítése, vagy riasztást küldeni a műveleti irányítópult.</span><span class="sxs-lookup"><span data-stu-id="c7bea-284">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span>

![A felügyelő mikroszolgáltatás bemutató ábra.](./images/supervisor.png)

## <a name="idempotent-versus-non-idempotent-operations"></a><span data-ttu-id="c7bea-286">Idempotens, és nem idempotens műveletek</span><span class="sxs-lookup"><span data-stu-id="c7bea-286">Idempotent versus non-idempotent operations</span></span>

<span data-ttu-id="c7bea-287">Kérések elveszhetnek, a Feladatütemező szolgáltatás biztosítania kell, hogy minden üzenet legalább egyszer feldolgozása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-287">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="c7bea-288">Az Event Hubs tud garantálni, legalább egyszeri kézbesítési, ha az ügyfél ellenőrzőpontokat megfelelően.</span><span class="sxs-lookup"><span data-stu-id="c7bea-288">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="c7bea-289">A Scheduler szolgáltatás összeomlik, ha lehet feldolgozni az egy vagy több ügyfél küldött kérelmeket közepén.</span><span class="sxs-lookup"><span data-stu-id="c7bea-289">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="c7bea-290">Ezeket az üzeneteket fog dolgozza fel az ütemező egy másik példánya, és újra fel kell dolgozni.</span><span class="sxs-lookup"><span data-stu-id="c7bea-290">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="c7bea-291">Mi történik, ha a kérés feldolgozása kétszer van?</span><span class="sxs-lookup"><span data-stu-id="c7bea-291">What happens if a request is processed twice?</span></span> <span data-ttu-id="c7bea-292">Fontos elkerülhető a munka.</span><span class="sxs-lookup"><span data-stu-id="c7bea-292">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="c7bea-293">Amikor az összes a rendszer két drónok esetében ugyanaz a csomag küldése nem szeretnénk.</span><span class="sxs-lookup"><span data-stu-id="c7bea-293">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="c7bea-294">Egyik lehetőség, hogy úgy tervezze meg az összes, hogy idempotensek legyenek.</span><span class="sxs-lookup"><span data-stu-id="c7bea-294">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="c7bea-295">Egy művelet idempotens esetén többször hívható az első hívása után további mellékhatásai előállító nélkül.</span><span class="sxs-lookup"><span data-stu-id="c7bea-295">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="c7bea-296">Más szóval egy ügyfél hívhat meg a műveletet egyszer, kétszer, vagy több alkalommal, és az eredmény ugyanaz lesz.</span><span class="sxs-lookup"><span data-stu-id="c7bea-296">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="c7bea-297">A szolgáltatás lényegében, figyelmen kívül hagyja ismétlődő hívásokat.</span><span class="sxs-lookup"><span data-stu-id="c7bea-297">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="c7bea-298">Az, hogy idempotensek lesznek hatásai mód esetén a szolgáltatás képes észlelni a duplikált hívások kell lennie.</span><span class="sxs-lookup"><span data-stu-id="c7bea-298">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="c7bea-299">Például rendelkezhet a hívó hozzárendelése a azonosító ahelyett, hogy a szolgáltatás hozzon létre egy új.</span><span class="sxs-lookup"><span data-stu-id="c7bea-299">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="c7bea-300">A szolgáltatás is tekintse meg az ismétlődő azonosítók.</span><span class="sxs-lookup"><span data-stu-id="c7bea-300">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="c7bea-301">A HTTP-specifikációnak megállapítja, hogy a GET, PUT és DELETE-metódusok idempotensnek kell lenniük.</span><span class="sxs-lookup"><span data-stu-id="c7bea-301">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="c7bea-302">POST metódus nem garantált, hogy idempotensek legyenek.</span><span class="sxs-lookup"><span data-stu-id="c7bea-302">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="c7bea-303">Ha egy POST-metódus új erőforrást hoz létre, nincs általánosan garancia arra, hogy-e a művelet idempotens.</span><span class="sxs-lookup"><span data-stu-id="c7bea-303">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span>

<span data-ttu-id="c7bea-304">Nem mindig idempotens metódus írása könnyen érthető megjegyzésblokkok írására.</span><span class="sxs-lookup"><span data-stu-id="c7bea-304">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="c7bea-305">Egy másik lehetőség, a Scheduler az olyan tartós tárban minden egyes tranzakciót az előrehaladását úgy követheti nyomon.</span><span class="sxs-lookup"><span data-stu-id="c7bea-305">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="c7bea-306">Minden alkalommal, amikor feldolgozza az üzenetet, lenne az állapotát a tartós tárolóban.</span><span class="sxs-lookup"><span data-stu-id="c7bea-306">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="c7bea-307">Minden lépése után azt kellene írni a az eredményt.</span><span class="sxs-lookup"><span data-stu-id="c7bea-307">After each step, it would write the result to the store.</span></span> <span data-ttu-id="c7bea-308">Előfordulhat, hogy ennek a módszernek a teljesítményre gyakorolt hatása.</span><span class="sxs-lookup"><span data-stu-id="c7bea-308">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="c7bea-309">Példa: Idempotens műveletek</span><span class="sxs-lookup"><span data-stu-id="c7bea-309">Example: Idempotent operations</span></span>

<span data-ttu-id="c7bea-310">A HTTP-specifikációnak tájékoztatja, hogy a PUT módszerek idempotensnek kell lenniük.</span><span class="sxs-lookup"><span data-stu-id="c7bea-310">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="c7bea-311">A specifikációnak idempotens ily módon határozza meg:</span><span class="sxs-lookup"><span data-stu-id="c7bea-311">The specification defines idempotent this way:</span></span>

> <span data-ttu-id="c7bea-312">A kérelmi metódust "idempotens" számít, ha a tervezett hatása a kiszolgálón a a módszerrel több azonos kérések pedig ugyanaz, mint az egyetlen gyakorolt hatását kérelmet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-312">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request.</span></span> <span data-ttu-id="c7bea-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="c7bea-313">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="c7bea-314">Új entitás létrehozásakor PUT, POST és szemantika közötti különbségek megértése fontos.</span><span class="sxs-lookup"><span data-stu-id="c7bea-314">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="c7bea-315">Mindkét esetben az ügyfél elküldi az entitás reprezentációját a kérelem törzsében.</span><span class="sxs-lookup"><span data-stu-id="c7bea-315">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="c7bea-316">De értelmében az URI azonosító nem egyezik.</span><span class="sxs-lookup"><span data-stu-id="c7bea-316">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="c7bea-317">Egy POST-metódus az URI-t az új entitás, például egy gyűjteményt egy szülőerőforrás jelenti.</span><span class="sxs-lookup"><span data-stu-id="c7bea-317">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="c7bea-318">Például hozzon létre egy új szállítási, hogy az URI-t lehet `/api/deliveries`.</span><span class="sxs-lookup"><span data-stu-id="c7bea-318">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="c7bea-319">A kiszolgáló hoz létre az entitást, és hozzárendeli egy új URI-t, mint például `/api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="c7bea-319">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="c7bea-320">Ez az URI a válasz Location fejléce adja vissza.</span><span class="sxs-lookup"><span data-stu-id="c7bea-320">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="c7bea-321">Minden alkalommal, amikor az ügyfél elküld egy kérelmet, a kiszolgáló hoz létre egy új entitást egy új URI-t.</span><span class="sxs-lookup"><span data-stu-id="c7bea-321">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="c7bea-322">Az URI-t egy PUT metódust a azonosítja az entitást.</span><span class="sxs-lookup"><span data-stu-id="c7bea-322">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="c7bea-323">Ha már van egy entitás az URI-ra, a kiszolgáló felülírja a létező entitásba a változattal a kérésben.</span><span class="sxs-lookup"><span data-stu-id="c7bea-323">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="c7bea-324">Ha nem entitás létezik, az URI-ra, a kiszolgáló létrehoz egyet.</span><span class="sxs-lookup"><span data-stu-id="c7bea-324">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="c7bea-325">Tegyük fel, az ügyfél küld egy PUT kérelem a `api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="c7bea-325">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="c7bea-326">Feltételezve, hogy nincs kézbesítési az URI-ra, a kiszolgáló létrehoz egy újat.</span><span class="sxs-lookup"><span data-stu-id="c7bea-326">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="c7bea-327">Most már az ügyfél elküld a kérésben újra, ha a kiszolgáló felülírja a létező entitásba.</span><span class="sxs-lookup"><span data-stu-id="c7bea-327">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="c7bea-328">Íme a PUT metódust a kézbesítési szolgáltatás megvalósítását.</span><span class="sxs-lookup"><span data-stu-id="c7bea-328">Here is the Delivery service's implementation of the PUT method.</span></span>

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="c7bea-329">Valószínű, hogy a legtöbb kérelmek létrehoz egy új entitást, így optimistically metódushívások `CreateAsync` a tárház objektum majd kezeli az olyan ismétlődő-erőforrás kivételek, amelyek inkább az erőforrás frissítésével.</span><span class="sxs-lookup"><span data-stu-id="c7bea-329">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span>

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md