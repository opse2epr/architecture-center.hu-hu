---
title: Adatfeldolgozás és munkafolyamatok a mikroszolgáltatások
description: Adatfeldolgozás és munkafolyamatok a mikroszolgáltatások
author: MikeWasson
ms.date: 10/23/2018
ms.openlocfilehash: 8a6d2d3209ca61e0588c96ed92862c1a7b91109f
ms.sourcegitcommit: 1f4cdb08fe73b1956e164ad692f792f9f635b409
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 01/08/2019
ms.locfileid: "54112804"
---
# <a name="designing-microservices-ingestion-and-workflow"></a><span data-ttu-id="f9096-103">Mikroszolgáltatások tervezése: Adatfeldolgozás és munkafolyamatok</span><span class="sxs-lookup"><span data-stu-id="f9096-103">Designing microservices: Ingestion and workflow</span></span>

<span data-ttu-id="f9096-104">Mikroszolgáltatások gyakran rendelkeznek egy munkafolyamatot egy tranzakció több szolgáltatást is.</span><span class="sxs-lookup"><span data-stu-id="f9096-104">Microservices often have a workflow that spans multiple services for a single transaction.</span></span> <span data-ttu-id="f9096-105">A munkafolyamat megbízható; kell lennie. nem lehet tranzakció megszakad vagy részlegesen befejezett állapotban hagyja őket.</span><span class="sxs-lookup"><span data-stu-id="f9096-105">The workflow must be reliable; it can't lose transactions or leave them in a partially completed state.</span></span> <span data-ttu-id="f9096-106">Emellett fontos szabályozni azt a bejövő kérelmek feldolgozási sebességet.</span><span class="sxs-lookup"><span data-stu-id="f9096-106">It's also critical to control the ingestion rate of incoming requests.</span></span> <span data-ttu-id="f9096-107">Sok kis szolgáltatással kommunikál egymással a bejövő kérések hirtelen kiugrásai túlterhelhetik futó a szolgáltatások közötti kommunikációt eredményezhet.</span><span class="sxs-lookup"><span data-stu-id="f9096-107">With many small services communicating with each other, a burst of incoming requests can overwhelm the interservice communication.</span></span>

![A betöltési munkafolyamatának ábrája](./images/ingestion-workflow.png)

## <a name="the-drone-delivery-workflow"></a><span data-ttu-id="f9096-109">A drone delivery munkafolyamat</span><span class="sxs-lookup"><span data-stu-id="f9096-109">The drone delivery workflow</span></span>

<span data-ttu-id="f9096-110">A Drone Delivery alkalmazást a következő műveleteket kell elvégezni egy kézbesítési ütemezése:</span><span class="sxs-lookup"><span data-stu-id="f9096-110">In the Drone Delivery application, the following operations must be performed to schedule a delivery:</span></span>

1. <span data-ttu-id="f9096-111">Ellenőrizze a felhasználói fiókhoz (szolgáltatásának) állapotát.</span><span class="sxs-lookup"><span data-stu-id="f9096-111">Check the status of the customer's account (Account service).</span></span>
2. <span data-ttu-id="f9096-112">Hozzon létre egy új csomag entitás (csomag szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="f9096-112">Create a new package entity (Package service).</span></span>
3. <span data-ttu-id="f9096-113">Ellenőrzés külső bárminemű a szállítási, szükséges-e a begyűjtés és a továbbítás helyeken alapuló (külső közlekedési szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="f9096-113">Check whether any third-party transportation is required for this delivery, based on the pickup and delivery locations (Third-party Transportation service).</span></span>
4. <span data-ttu-id="f9096-114">Ütemezzen egy drónt felvételre (Drónos szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="f9096-114">Schedule a drone for pickup (Drone service).</span></span>
5. <span data-ttu-id="f9096-115">Hozzon létre egy új kézbesítési entitás (Tartalomkézbesítési szolgáltatás).</span><span class="sxs-lookup"><span data-stu-id="f9096-115">Create a new delivery entity (Delivery service).</span></span>

<span data-ttu-id="f9096-116">Ez a központi eleme a teljes alkalmazást, így a teljes körű folyamatot, valamint megbízható, nagy teljesítményű kell lennie.</span><span class="sxs-lookup"><span data-stu-id="f9096-116">This is the core of the entire application, so the end-to-end process must be performant as well as reliable.</span></span> <span data-ttu-id="f9096-117">Egyes adott kihívást vonhat:</span><span class="sxs-lookup"><span data-stu-id="f9096-117">Some particular challenges must be addressed:</span></span>

- <span data-ttu-id="f9096-118">**Terheléskiegyenlítés**.</span><span class="sxs-lookup"><span data-stu-id="f9096-118">**Load leveling**.</span></span> <span data-ttu-id="f9096-119">Túl sok ügyfél kérést túlterhelhetik eredményezhet hálózati forgalmat a rendszer.</span><span class="sxs-lookup"><span data-stu-id="f9096-119">Too many client requests can overwhelm the system with interservice network traffic.</span></span> <span data-ttu-id="f9096-120">Azt is túlterhelhetik háttérrendszer függőségeit, például a storage vagy a távoli szolgáltatások.</span><span class="sxs-lookup"><span data-stu-id="f9096-120">It can also overwhelm backend dependencies such as storage or remote services.</span></span> <span data-ttu-id="f9096-121">Ezek a szolgáltatások meghívása őket, a rendszer ellennyomás létrehozása szabályozás előfordulhat, hogy reagálni.</span><span class="sxs-lookup"><span data-stu-id="f9096-121">These may react by throttling the services calling them, creating backpressure in the system.</span></span> <span data-ttu-id="f9096-122">Ezért fontos a kérelmeket a rendszer egy puffer, vagy a feldolgozáshoz várólistára helyezésével érkező terhelés.</span><span class="sxs-lookup"><span data-stu-id="f9096-122">Therefore, it's important to load level the requests coming into the system, by putting them into a buffer or queue for processing.</span></span>

- <span data-ttu-id="f9096-123">**Garantált kézbesítés**.</span><span class="sxs-lookup"><span data-stu-id="f9096-123">**Guaranteed delivery**.</span></span> <span data-ttu-id="f9096-124">Az Adatbetöltési összetevő bármely ügyfél kérelmeket elkerüléséhez biztosítania kell, legalább egyszeri kézbesítési üzenetek.</span><span class="sxs-lookup"><span data-stu-id="f9096-124">To avoid dropping any client requests, the ingestion component must guarantee at-least-once delivery of messages.</span></span>

- <span data-ttu-id="f9096-125">**Hibakezelés**.</span><span class="sxs-lookup"><span data-stu-id="f9096-125">**Error handling**.</span></span> <span data-ttu-id="f9096-126">Ha a szolgáltatások egy hibakódot ad vissza, vagy nem átmeneti hibát tapasztal, a tartalomkézbesítési nem lehet ütemezni.</span><span class="sxs-lookup"><span data-stu-id="f9096-126">If any of the services returns an error code or experiences a non-transient failure, the delivery cannot be scheduled.</span></span> <span data-ttu-id="f9096-127">Egy hibakódot jelezheti a várt hibát (például a felhasználói fiók fel van függesztve) vagy egy váratlan kiszolgálóhiba (HTTP 5xx).</span><span class="sxs-lookup"><span data-stu-id="f9096-127">An error code might indicate an expected error condition (for example, the customer's account is suspended) or an unexpected server error (HTTP 5xx).</span></span> <span data-ttu-id="f9096-128">Elképzelhető, hogy egy szolgáltatás még nem érhető el, a hálózati hívás időtúllépés miatt.</span><span class="sxs-lookup"><span data-stu-id="f9096-128">A service might also be unavailable, causing the network call to time out.</span></span>

<span data-ttu-id="f9096-129">Először áttekintjük az Adatbetöltési oldala egyenlet &mdash; hogyan a rendszer a bejövő felhasználói kérések magasabb átviteli sebességen feldolgozására képes.</span><span class="sxs-lookup"><span data-stu-id="f9096-129">First we'll look at the ingestion side of the equation &mdash; how the system can ingest incoming user requests at high throughput.</span></span> <span data-ttu-id="f9096-130">Azt fogjuk fontolja meg a drone delivery alkalmazás hogyan valósíthat meg egy megbízható munkafolyamatot.</span><span class="sxs-lookup"><span data-stu-id="f9096-130">Then we'll consider how the drone delivery application can implement a reliable workflow.</span></span> <span data-ttu-id="f9096-131">Azt tapasztaltuk, hogy az Adatbetöltési alrendszer a kialakítás befolyásolja a munkafolyamat-háttérrendszer.</span><span class="sxs-lookup"><span data-stu-id="f9096-131">It turns out that the design of the ingestion subsystem affects the workflow backend.</span></span>

## <a name="ingestion"></a><span data-ttu-id="f9096-132">Adatbetöltési</span><span class="sxs-lookup"><span data-stu-id="f9096-132">Ingestion</span></span>

<span data-ttu-id="f9096-133">Üzleti követelmények alapján, a fejlesztői csapat azonosítja a következő nem funkcionális követelmények támogatunk:</span><span class="sxs-lookup"><span data-stu-id="f9096-133">Based on business requirements, the development team identified the following non-functional requirements for ingestion:</span></span>

- <span data-ttu-id="f9096-134">10e kérelmek/s folyamatos teljesítményt.</span><span class="sxs-lookup"><span data-stu-id="f9096-134">Sustained throughput of 10K requests/sec.</span></span>
- <span data-ttu-id="f9096-135">Tudja kezelni az adatforgalmi csúcsokhoz legfeljebb 50 ezer/mp nélkül ügyfél kérelmeket, vagy túllépik az időkorlátot.</span><span class="sxs-lookup"><span data-stu-id="f9096-135">Able to handle spikes of up to 50K/sec without dropping client requests or timing out.</span></span>
- <span data-ttu-id="f9096-136">Kisebb, mint 500ms késés 99 %-a.</span><span class="sxs-lookup"><span data-stu-id="f9096-136">Less than 500ms latency in the 99th percentile.</span></span>

<span data-ttu-id="f9096-137">A követelmény alkalmanként adatforgalmi kiugrások kezelésére tervezési kihívást mutat be.</span><span class="sxs-lookup"><span data-stu-id="f9096-137">The requirement to handle occasional spikes in traffic presents a design challenge.</span></span> <span data-ttu-id="f9096-138">Elméletileg a rendszer sikerült horizontálisan a maximális várt forgalom kezeléséhez.</span><span class="sxs-lookup"><span data-stu-id="f9096-138">In theory, the system could be scaled out to handle the maximum expected traffic.</span></span> <span data-ttu-id="f9096-139">Azonban kiépítése, hogy számos erőforrás nagyon hatékony.</span><span class="sxs-lookup"><span data-stu-id="f9096-139">However, provisioning that many resources would be very inefficient.</span></span> <span data-ttu-id="f9096-140">A legtöbb esetben az alkalmazás nem kell, hogy mekkora kapacitást, így lesz tétlen Processzormagok költségszámítási money érték hozzáadása nélkül.</span><span class="sxs-lookup"><span data-stu-id="f9096-140">Most of the time, the application will not need that much capacity, so there would be idle cores, costing money without adding value.</span></span>

<span data-ttu-id="f9096-141">Jobb módszer, hogy a bejövő kérelmek elhelyezi egy puffer, és lehetővé teszik a puffer terheléselosztóként jár el.</span><span class="sxs-lookup"><span data-stu-id="f9096-141">A better approach is to put the incoming requests into a buffer, and let the buffer act as a load leveler.</span></span> <span data-ttu-id="f9096-142">Ezzel a kialakítással kell, hogy a szolgáltatás tudja kezelni a maximális feldolgozási sebességét rövid időszakokra, de a háttérszolgáltatások csak a maximális fenntartható terhelés kezeléséhez van szükség.</span><span class="sxs-lookup"><span data-stu-id="f9096-142">With this design, the Ingestion service must be able to handle the maximum ingestion rate over short periods, but the backend services only need to handle the maximum sustained load.</span></span> <span data-ttu-id="f9096-143">Az előtér: pufferelés, a háttérszolgáltatások nem kell nagy adatforgalmi kiugrások kezelésére.</span><span class="sxs-lookup"><span data-stu-id="f9096-143">By buffering at the front end, the backend services shouldn't need to handle large spikes in traffic.</span></span> <span data-ttu-id="f9096-144">A Drone Delivery alkalmazást szükséges méreten [Azure Event Hubs](/azure/event-hubs/) terheléskiegyenlítési esetében megfelelő választás.</span><span class="sxs-lookup"><span data-stu-id="f9096-144">At the scale required for the Drone Delivery application, [Azure Event Hubs](/azure/event-hubs/) is a good choice for load leveling.</span></span> <span data-ttu-id="f9096-145">Az Event Hubs biztosít alacsony késéssel és nagy átviteli sebességet, és a egy költséghatékony megoldás Adatbetöltési nagy mennyiségben.</span><span class="sxs-lookup"><span data-stu-id="f9096-145">Event Hubs offers low latency and high throughput, and is a cost effective solution at high ingestion volumes.</span></span>

<span data-ttu-id="f9096-146">Tesztelés használtuk egy Standard szintű event hubs átviteli egységeket 100 és 32 partícióval.</span><span class="sxs-lookup"><span data-stu-id="f9096-146">For our testing, we used a Standard tier event hub with 32 partitions and 100 throughput units.</span></span> <span data-ttu-id="f9096-147">Megállapítottuk, hogy körülbelül 32 ezer esemény / s betöltési, körül 90ms késéssel.</span><span class="sxs-lookup"><span data-stu-id="f9096-147">We observed about 32K events / second ingestion, with latency around 90ms.</span></span> <span data-ttu-id="f9096-148">Az alapértelmezett korlát jelenleg 20 átviteli egység, de az Azure-ügyfelek kérhet további átviteli egységek ügyfélszolgálatunknak küldött támogatási kérést.</span><span class="sxs-lookup"><span data-stu-id="f9096-148">Currently the default limit is 20 throughput units, but Azure customers can request additional throughput units by filing a support request.</span></span> <span data-ttu-id="f9096-149">Lásd: [Event Hubs-kvótákról](/azure/event-hubs/event-hubs-quotas) további információt.</span><span class="sxs-lookup"><span data-stu-id="f9096-149">See [Event Hubs quotas](/azure/event-hubs/event-hubs-quotas) for more information.</span></span> <span data-ttu-id="f9096-150">A metrikák, a számos tényező befolyásolhatja a teljesítményt, például az üzenetek hasznos adatainak mérete, mivel így nem értelmezi őket alapként.</span><span class="sxs-lookup"><span data-stu-id="f9096-150">As with all performance metrics, many factors can affect performance, such as message payload size, so don't interpret these numbers as a benchmark.</span></span> <span data-ttu-id="f9096-151">További átviteli van szükség, ha a feldolgozó szolgáltatás szegmens egynél több eseményközpont között is.</span><span class="sxs-lookup"><span data-stu-id="f9096-151">If more throughput is needed, the Ingestion service can shard across more than one event hub.</span></span> <span data-ttu-id="f9096-152">A még nagyobb átviteli sebességet [Event Hubs dedikált](/azure/event-hubs/event-hubs-dedicated-overview) kínál egybérlős üzemelő példánya, amely a bejövő képes kezelni másodpercenként több mint 2 millió esemény.</span><span class="sxs-lookup"><span data-stu-id="f9096-152">For even higher throughput rates, [Event Hubs Dedicated](/azure/event-hubs/event-hubs-dedicated-overview) offers single-tenant deployments that can ingress over 2 million events per second.</span></span>

<span data-ttu-id="f9096-153">Fontos megérteni, hogyan érheti el az Event Hubs, az ilyen nagy teljesítményű, mert, amely hatással van, hogy egy ügyfél foglaljanak Event hubs szolgáltatástól érkező üzenetek.</span><span class="sxs-lookup"><span data-stu-id="f9096-153">It's important to understand how Event Hubs can achieve such high throughput, because that affects how a client should consume messages from Event Hubs.</span></span> <span data-ttu-id="f9096-154">Az Event Hubs nem valósít meg egy *várólista*.</span><span class="sxs-lookup"><span data-stu-id="f9096-154">Event Hubs does not implement a *queue*.</span></span> <span data-ttu-id="f9096-155">Ehelyett valósít meg egy *eseménystream*.</span><span class="sxs-lookup"><span data-stu-id="f9096-155">Rather, it implements an *event stream*.</span></span>

<span data-ttu-id="f9096-156">Az üzenetsor az egyes fogyasztók távolíthatja el egy üzenetet az üzenetsorból, és a következő fogyasztói az üzenet nem jelenik meg.</span><span class="sxs-lookup"><span data-stu-id="f9096-156">With a queue, an individual consumer can remove a message from the queue, and the next consumer won't see that message.</span></span> <span data-ttu-id="f9096-157">Üzenetsorok azt ezért lehetővé teszik, hogy egy [versengő felhasználók mintája](../patterns/competing-consumers.md) üzenetek párhuzamos feldolgozását, és a méretezhetőség javítása.</span><span class="sxs-lookup"><span data-stu-id="f9096-157">Queues therefore allow you to use a [Competing Consumers pattern](../patterns/competing-consumers.md) to process messages in parallel and improve scalability.</span></span> <span data-ttu-id="f9096-158">A nagyobb rugalmasság érdekében a fogyasztó az üzenet a zárolási tárolja, és a zárolás feloldása, ha az üzenet feldolgozása megtörtént.</span><span class="sxs-lookup"><span data-stu-id="f9096-158">For greater resiliency, the consumer holds a lock on the message and releases the lock when it's done processing the message.</span></span> <span data-ttu-id="f9096-159">Ha a feldolgozó meghibásodik &mdash; például a csomóponton futó szoftverleállások &mdash; zárolási túllépi az időkorlátot, és az üzenet vissza alakzatot a várólistára kerül.</span><span class="sxs-lookup"><span data-stu-id="f9096-159">If the consumer fails &mdash; for example, the node it's running on crashes &mdash; the lock times out and the message goes back onto the queue.</span></span>

![Várólista szemantika ábrája](./images/queue-semantics.png)

<span data-ttu-id="f9096-161">Az Event Hubs, másrészről, használja a streamelési szemantikáját.</span><span class="sxs-lookup"><span data-stu-id="f9096-161">Event Hubs, on the other hand, uses streaming semantics.</span></span> <span data-ttu-id="f9096-162">A fogyasztók olvashatja a streamet, egymástól függetlenül saját tempójában.</span><span class="sxs-lookup"><span data-stu-id="f9096-162">Consumers read the stream independently at their own pace.</span></span> <span data-ttu-id="f9096-163">Mindegyik felhasználó az aktuális pozícióját az adatfolyamban nyomon gondoskodik a felelős.</span><span class="sxs-lookup"><span data-stu-id="f9096-163">Each consumer is responsible for keeping track of its current position in the stream.</span></span> <span data-ttu-id="f9096-164">A fogyasztó kell írni az aktuális pozícióját adattárolásra néhány előre meghatározott időközönként.</span><span class="sxs-lookup"><span data-stu-id="f9096-164">A consumer should write its current position to persistent storage at some predefined interval.</span></span> <span data-ttu-id="f9096-165">Így ha az ügyfél egy tartalék (például a fogyasztói szoftverleállások vagy a gazdagép nem), majd egy új példányt folytathatja a utolsó feljegyzett beosztás érkező adatfolyam olvasása.</span><span class="sxs-lookup"><span data-stu-id="f9096-165">That way, if the consumer experiences a fault (for example, the consumer crashes, or the host fails), then a new instance can resume reading the stream from the last recorded position.</span></span> <span data-ttu-id="f9096-166">Ez a folyamat *ellenőrzőpontok*.</span><span class="sxs-lookup"><span data-stu-id="f9096-166">This process is called *checkpointing*.</span></span>

<span data-ttu-id="f9096-167">Teljesítménybeli megfontolások miatt az olyan fogyasztói általában nem ellenőrzőpont után minden üzenetet.</span><span class="sxs-lookup"><span data-stu-id="f9096-167">For performance reasons, a consumer generally doesn't checkpoint after each message.</span></span> <span data-ttu-id="f9096-168">Ehelyett azt rögzített időköz, például a feldolgozás után ad hozzá ellenőrzőpontokat *n* üzeneteket, vagy minden *n* másodperc.</span><span class="sxs-lookup"><span data-stu-id="f9096-168">Instead, it checkpoints at some fixed interval, for example after processing *n* messages, or every *n* seconds.</span></span> <span data-ttu-id="f9096-169">Következtében ha egy feldolgozó nem jár sikerrel, néhány esemény előfordulhat, hogy első feldolgozása kétszer, mert egy új példányt mindig szerzi be a legutóbbi ellenőrzőponttól.</span><span class="sxs-lookup"><span data-stu-id="f9096-169">As a consequence, if a consumer fails, some events may get processed twice, because a new instance always picks up from the last checkpoint.</span></span> <span data-ttu-id="f9096-170">Nincs a kompromisszummal jár: Gyakori ellenőrzőpontok összeállítása hátrányosan befolyásolhatja a teljesítményt, de a ritka ellenőrzőpontok jelenti azt, további események fog játszani hiba után.</span><span class="sxs-lookup"><span data-stu-id="f9096-170">There is a tradeoff: Frequent checkpoints can hurt performance, but sparse checkpoints mean you will replay more events after a failure.</span></span>

![A stream szemantika ábrája](./images/stream-semantics.png)

<span data-ttu-id="f9096-172">Az Event Hubs nem versengő fogyasztó számára készült.</span><span class="sxs-lookup"><span data-stu-id="f9096-172">Event Hubs is not designed for competing consumers.</span></span> <span data-ttu-id="f9096-173">Több fogyasztó tudja olvasni a stream, bár egyes is járja a stream egymástól függetlenül.</span><span class="sxs-lookup"><span data-stu-id="f9096-173">Although multiple consumers can read a stream, each traverses the stream independently.</span></span> <span data-ttu-id="f9096-174">Ehelyett az Event Hubs egy particionált felhasználói mintát használ.</span><span class="sxs-lookup"><span data-stu-id="f9096-174">Instead, Event Hubs uses a partitioned consumer pattern.</span></span> <span data-ttu-id="f9096-175">Az event hub legfeljebb 32 partícióval rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="f9096-175">An event hub has up to 32 partitions.</span></span> <span data-ttu-id="f9096-176">Horizontális skálázás külön fogyasztók rendel mindegyik partíció érhető el.</span><span class="sxs-lookup"><span data-stu-id="f9096-176">Horizontal scale is achieved by assigning a separate consumer to each partition.</span></span>

<span data-ttu-id="f9096-177">Ez mit jelent a drone delivery munkafolyamat?</span><span class="sxs-lookup"><span data-stu-id="f9096-177">What does this mean for the drone delivery workflow?</span></span> <span data-ttu-id="f9096-178">A teljes kiaknázásához az Event Hubs lekéréséhez a kézbesítési ütemezési minden üzenet feldolgozása után áthelyezni a következő nem várja.</span><span class="sxs-lookup"><span data-stu-id="f9096-178">To get the full benefit of Event Hubs, the Delivery Scheduler cannot wait for each message to be processed before moving onto the next.</span></span> <span data-ttu-id="f9096-179">Ebben az esetben, amely azt fogják tölteni legtöbbször a Várakozás a hálózati hívások végrehajtásához.</span><span class="sxs-lookup"><span data-stu-id="f9096-179">If it does that, it will spend most of its time waiting for network calls to complete.</span></span> <span data-ttu-id="f9096-180">Ehelyett azt kell feldolgoznia az üzenetek aszinkron hívásokat a háttérszolgáltatások használatával párhuzamosan kötegek.</span><span class="sxs-lookup"><span data-stu-id="f9096-180">Instead, it needs to process batches of messages in parallel, using asynchronous calls to the backend services.</span></span> <span data-ttu-id="f9096-181">Ahogy láthatjuk, a megfelelő ellenőrzőpont-stratégia kiválasztása az is fontos.</span><span class="sxs-lookup"><span data-stu-id="f9096-181">As we'll see, choosing the right checkpointing strategy is also important.</span></span>

## <a name="workflow"></a><span data-ttu-id="f9096-182">Munkafolyamat</span><span class="sxs-lookup"><span data-stu-id="f9096-182">Workflow</span></span>

<span data-ttu-id="f9096-183">Megvizsgáltunk, beolvasása, illetve az üzenetek feldolgozására három lehetőség: Event Processor Host, Service Bus-üzenetsorok és a IoTHub React könyvtárban.</span><span class="sxs-lookup"><span data-stu-id="f9096-183">We looked at three options for reading and processing the messages: Event Processor Host, Service Bus queues, and the IoTHub React library.</span></span> <span data-ttu-id="f9096-184">Választottuk IoTHub reagálni, de ennek megértéséhez segít az Event Processor Host indítása.</span><span class="sxs-lookup"><span data-stu-id="f9096-184">We chose IoTHub React, but to understand why, it helps to start with Event Processor Host.</span></span>

### <a name="event-processor-host"></a><span data-ttu-id="f9096-185">Event Processor Host</span><span class="sxs-lookup"><span data-stu-id="f9096-185">Event Processor Host</span></span>

<span data-ttu-id="f9096-186">Event Processor Host üzenet kötegelés lett tervezve.</span><span class="sxs-lookup"><span data-stu-id="f9096-186">Event Processor Host is designed for message batching.</span></span> <span data-ttu-id="f9096-187">Az alkalmazás megvalósítja a `IEventProcessor` felületet, és a processzor gazdagép hoz létre egy esemény processzorpéldány minden partíció esetében az eseményközpontban.</span><span class="sxs-lookup"><span data-stu-id="f9096-187">The application implements the `IEventProcessor` interface, and the Processor Host creates one event processor instance for each partition in the event hub.</span></span> <span data-ttu-id="f9096-188">Az Event Processor Host ekkor meghívja a minden egyes eseményfeldolgozó `ProcessEventsAsync` eseményüzenetek váró metódust.</span><span class="sxs-lookup"><span data-stu-id="f9096-188">The Event Processor Host then calls each event processor's `ProcessEventsAsync` method with batches of event messages.</span></span> <span data-ttu-id="f9096-189">Az ellenőrzőpont belül az Alkalmazásvezérlés a `ProcessEventsAsync` metódust, és az Event Processor Host ellenőrzőpontot ír az Azure storage.</span><span class="sxs-lookup"><span data-stu-id="f9096-189">The application controls when to checkpoint inside the `ProcessEventsAsync` method, and the Event Processor Host writes the checkpoints to Azure storage.</span></span>

<span data-ttu-id="f9096-190">Egy partíción belül Event Processor Host megvárja, amíg `ProcessEventsAsync` vissza úgy, a következő köteg meghívása előtt.</span><span class="sxs-lookup"><span data-stu-id="f9096-190">Within a partition, Event Processor Host waits for `ProcessEventsAsync` to return before calling again with the next batch.</span></span> <span data-ttu-id="f9096-191">Ez a megközelítés leegyszerűsíti a programozási modell, mert a feldolgozás eseménykód nem kell ismételten belépő.</span><span class="sxs-lookup"><span data-stu-id="f9096-191">This approach simplifies the programming model, because your event processing code doesn't need to be reentrant.</span></span> <span data-ttu-id="f9096-192">Azonban azt is jelenti, hogy az eseményfeldolgozó kezeli egy kötegelt egyszerre, és ez gates a sebesség, amellyel a Processor Host pump is a üzeneteket.</span><span class="sxs-lookup"><span data-stu-id="f9096-192">However, it also means that the event processor handles one batch at a time, and this gates the speed at which the Processor Host can pump messages.</span></span>

> [!NOTE]
> <span data-ttu-id="f9096-193">A processzor gazdagép ténylegesen nem *várjon* abban az értelemben, a szál blokkolása.</span><span class="sxs-lookup"><span data-stu-id="f9096-193">The Processor Host doesn't actually *wait* in the sense of blocking a thread.</span></span> <span data-ttu-id="f9096-194">A `ProcessEventsAsync` metódus aszinkron, ezért az Processor Host végezhet egyéb műveleteket, amíg befejeződik a metódus.</span><span class="sxs-lookup"><span data-stu-id="f9096-194">The `ProcessEventsAsync` method is asynchronous, so the Processor Host can do other work while the method is completing.</span></span> <span data-ttu-id="f9096-195">De azt nem az adott partíció egy másik üzenetköteget mindaddig, amíg a metódus adja vissza.</span><span class="sxs-lookup"><span data-stu-id="f9096-195">But it won't deliver another batch of messages for that partition until the method returns.</span></span>

<span data-ttu-id="f9096-196">A drone alkalmazásban egy üzenetköteget párhuzamosan lehet feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="f9096-196">In the drone application, a batch of messages can be processed in parallel.</span></span> <span data-ttu-id="f9096-197">De Várakozás a teljes kötegelt végrehajtásához a szűk keresztmetszetet is okozhatnak.</span><span class="sxs-lookup"><span data-stu-id="f9096-197">But waiting for the whole batch to complete can still cause a bottleneck.</span></span> <span data-ttu-id="f9096-198">Feldolgozási csak lehet olyan gyors kötegelt belül a leglassabb üzenetnek számít.</span><span class="sxs-lookup"><span data-stu-id="f9096-198">Processing can only be as fast as the slowest message within a batch.</span></span> <span data-ttu-id="f9096-199">Válaszidők bármilyen változása hozhat létre egy "hosszú tail," ahol néhány lassúak a válaszok húzza le az egész rendszert.</span><span class="sxs-lookup"><span data-stu-id="f9096-199">Any variation in response times can create a "long tail," where a few slow responses drag down the entire system.</span></span> <span data-ttu-id="f9096-200">A teljesítménytesztek kimutatta, hogy azt nem érte el a célként megadott átviteli sebességet, ezzel a megközelítéssel.</span><span class="sxs-lookup"><span data-stu-id="f9096-200">Our performance tests showed that we did not achieve our target throughput using this approach.</span></span> <span data-ttu-id="f9096-201">Ez a kód *nem* jelenti azt, hogy lehetőleg ne Event Processor Host használatával.</span><span class="sxs-lookup"><span data-stu-id="f9096-201">This does *not* mean that you should avoid using Event Processor Host.</span></span> <span data-ttu-id="f9096-202">A nagy teljesítményű, kerülje bármely hosszú lefutású feladat található, de a `ProcesssEventsAsync` metódust.</span><span class="sxs-lookup"><span data-stu-id="f9096-202">But for high throughput, avoid doing any long-running tasks inside the `ProcesssEventsAsync` method.</span></span> <span data-ttu-id="f9096-203">Az egyes kötegek gyorsan feldolgozni.</span><span class="sxs-lookup"><span data-stu-id="f9096-203">Process each batch quickly.</span></span>

### <a name="iothub-react"></a><span data-ttu-id="f9096-204">IotHub React</span><span class="sxs-lookup"><span data-stu-id="f9096-204">IotHub React</span></span>

<span data-ttu-id="f9096-205">[IotHub React](https://github.com/Azure/toketi-iothubreact) Akka Streamek könyvtár az Eseményközpontból érkező események olvasását.</span><span class="sxs-lookup"><span data-stu-id="f9096-205">[IotHub React](https://github.com/Azure/toketi-iothubreact) is an Akka Streams library for reading events from Event Hub.</span></span> <span data-ttu-id="f9096-206">Akka Streamek egy stream-alapú programozási keretrendszerről, amely megvalósítja a [reaktív Streamek](https://www.reactive-streams.org/) specifikációnak.</span><span class="sxs-lookup"><span data-stu-id="f9096-206">Akka Streams is a stream-based programming framework that implements the [Reactive Streams](https://www.reactive-streams.org/) specification.</span></span> <span data-ttu-id="f9096-207">Hatékony streamelési folyamatok létrehozásával, ahol az összes streamelési műveleteket aszinkron módon történik, és a folyamat szabályosan kezeli ellennyomás hozhat létre egy megoldást kínál.</span><span class="sxs-lookup"><span data-stu-id="f9096-207">It provides a way to build efficient streaming pipelines, where all streaming operations are performed asynchronously, and the pipeline gracefully handles backpressure.</span></span> <span data-ttu-id="f9096-208">Ellennyomás akkor történik, ha az eseményforrás eredményez, mint az alárendelt fogyasztók fogadhatja gyorsabb ütemben események &mdash; amelynek pontosan az a helyzet akkor, ha a a drone delivery rendszer nevű kategóriáé a forgalom.</span><span class="sxs-lookup"><span data-stu-id="f9096-208">Backpressure occurs when an event source produces events at a faster rate than the downstream consumers can receive them &mdash; which is exactly the situation when the drone delivery system has a spike in traffic.</span></span> <span data-ttu-id="f9096-209">Ha háttérszolgáltatások lassabban, IoTHub React lelassulnak.</span><span class="sxs-lookup"><span data-stu-id="f9096-209">If backend services go slower, IoTHub React will slow down.</span></span> <span data-ttu-id="f9096-210">Kapacitás nő, ha IoTHub React fogja leküldeni a további üzeneteket, a folyamat keresztül.</span><span class="sxs-lookup"><span data-stu-id="f9096-210">If capacity is increased, IoTHub React will push more messages through the pipeline.</span></span>

<span data-ttu-id="f9096-211">Streamelés az Event hubs-Eseményközpontok eseményeinek nagyon természetes programozási modellt Akka Streameket is.</span><span class="sxs-lookup"><span data-stu-id="f9096-211">Akka Streams is also a very natural programming model for streaming events from Event Hubs.</span></span> <span data-ttu-id="f9096-212">Helyett hurkolás események kötegelt keresztül, számos műveletet minden egyes esemény érvényesek, és lehetővé teszik a Akka Streamek kezelni, a streamelési határozza meg.</span><span class="sxs-lookup"><span data-stu-id="f9096-212">Instead of looping through a batch of events, you define a set of operations that will be applied to each event, and let Akka Streams handle the streaming.</span></span> <span data-ttu-id="f9096-213">Akka Streamek határozza meg, hogy a streamelési folyamat *források*, *folyamatok*, és *fogadók*.</span><span class="sxs-lookup"><span data-stu-id="f9096-213">Akka Streams defines a streaming pipeline in terms of *Sources*, *Flows*, and *Sinks*.</span></span> <span data-ttu-id="f9096-214">Egy adatforrás generál egy kimeneti adatfolyamba, egy folyamatot egy bemeneti stream feldolgozza, és létrehozza a kimeneti adatfolyamokat és egy fogadó felhasznál egy stream nélkül állít elő kimenetet.</span><span class="sxs-lookup"><span data-stu-id="f9096-214">A source generates an output stream, a flow processes an input stream and produces an output stream, and a sink consumes a stream without producing any output.</span></span>

<span data-ttu-id="f9096-215">A Scheduler szolgáltatás, amely beállítja a Akka Streamek folyamat a következő kódot:</span><span class="sxs-lookup"><span data-stu-id="f9096-215">Here is the code in the Scheduler service that sets up the Akka Streams pipeline:</span></span>

```java
IoTHub iotHub = new IoTHub();
Source<MessageFromDevice, NotUsed> messages = iotHub.source(options);

messages.map(msg -> DeliveryRequestEventProcessor.parseDeliveryRequest(msg))
        .filter(ad -> ad.getDelivery() != null).via(deliveryProcessor()).to(iotHub.checkpointSink())
        .run(streamMaterializer);
```

<span data-ttu-id="f9096-216">Ez a kód az Event Hubs konfigurálja a forrásaként.</span><span class="sxs-lookup"><span data-stu-id="f9096-216">This code configures Event Hubs as a source.</span></span> <span data-ttu-id="f9096-217">A `map` utasítás deserializes egyes eseményüzenet be egy Java-osztály, amely egy kézbesítési kérést jelöli.</span><span class="sxs-lookup"><span data-stu-id="f9096-217">The `map` statement deserializes each event message into a Java class that represents a delivery request.</span></span> <span data-ttu-id="f9096-218">A `filter` utasítás eltávolítja az összes `null` az adatfolyamból objektumokat; ez az eset, amikor egy üzenet nem lehet deszerializálni elleni őröket.</span><span class="sxs-lookup"><span data-stu-id="f9096-218">The `filter` statement removes any `null` objects from the stream; this guards against the case where a message can't be deserialized.</span></span> <span data-ttu-id="f9096-219">A `via` utasítás csatlakoztatja a forrás egy folyamatot, amely minden egyes kézbesítési kérést dolgoz fel.</span><span class="sxs-lookup"><span data-stu-id="f9096-219">The `via` statement joins the source to a flow that processes each delivery request.</span></span> <span data-ttu-id="f9096-220">A `to` metódus csatlakoztatja a ellenőrzőpont gyűjtő, amely IoTHub React be van építve a folyamatot.</span><span class="sxs-lookup"><span data-stu-id="f9096-220">The `to` method joins the flow to the checkpoint sink, which is built into IoTHub React.</span></span>

<span data-ttu-id="f9096-221">IoTHub React eseményfeldolgozó állomás, mint más ellenőrzőpontok stratégiát alkalmaz.</span><span class="sxs-lookup"><span data-stu-id="f9096-221">IoTHub React uses a different checkpointing strategy than Event Host Processor.</span></span> <span data-ttu-id="f9096-222">Ellenőrzőpontok a ellenőrzőpont gyűjtő, amely az a folyamat leállítása szakasz által írt.</span><span class="sxs-lookup"><span data-stu-id="f9096-222">Checkpoints are written by the checkpoint sink, which is the terminating stage in the pipeline.</span></span> <span data-ttu-id="f9096-223">Akka Streamek kialakítása lehetővé teszi, hogy a folyamat folytatásához a streamelési adatok, miközben a fogadó ír az ellenőrző pont.</span><span class="sxs-lookup"><span data-stu-id="f9096-223">The design of Akka Streams allows the pipeline to continue streaming data while the sink is writing the checkpoint.</span></span> <span data-ttu-id="f9096-224">Ez azt jelenti, hogy a felsőbb rétegbeli feldolgozás szakaszában nem várja meg, megtörténjen ellenőrzőpontok használata szükséges.</span><span class="sxs-lookup"><span data-stu-id="f9096-224">That means the upstream processing stages don't need to wait for checkpointing to happen.</span></span> <span data-ttu-id="f9096-225">Konfigurálhatja az ellenőrzőpontok használata után időtúllépés vagy után adott számú üzenetet dolgozott.</span><span class="sxs-lookup"><span data-stu-id="f9096-225">You can configure checkpointing to occur after a timeout or after a certain number of messages have been processed.</span></span>

<span data-ttu-id="f9096-226">A `deliveryProcessor` metódus a Akka Streamek folyamatot hoz létre:</span><span class="sxs-lookup"><span data-stu-id="f9096-226">The `deliveryProcessor` method creates the Akka Streams flow:</span></span>

```java
private static Flow<AkkaDelivery, MessageFromDevice, NotUsed> deliveryProcessor() {
    return Flow.of(AkkaDelivery.class).map(delivery -> {
        CompletableFuture<DeliverySchedule> completableSchedule = DeliveryRequestEventProcessor
                .processDeliveryRequestAsync(delivery.getDelivery(),
                        delivery.getMessageFromDevice().properties());

        completableSchedule.whenComplete((deliverySchedule,error) -> {
            if (error!=null){
                Log.info("failed delivery" + error.getStackTrace());
            }
            else{
                Log.info("Completed Delivery",deliverySchedule.toString());
            }

        });
        completableSchedule = null;
        return delivery.getMessageFromDevice();
    });
}
```

<span data-ttu-id="f9096-227">A folyamat meghívja a statikus `processDeliveryRequestAsync` metódushoz, amely a tényleges munkát üzenetek feldolgozására.</span><span class="sxs-lookup"><span data-stu-id="f9096-227">The flow calls a static `processDeliveryRequestAsync` method that does the actual work of processing each message.</span></span>

### <a name="scaling-with-iothub-react"></a><span data-ttu-id="f9096-228">IoTHub reacttel méretezése</span><span class="sxs-lookup"><span data-stu-id="f9096-228">Scaling with IoTHub React</span></span>

<span data-ttu-id="f9096-229">A Scheduler szolgáltatás célja, hogy az egyes tárolópéldányok egyetlen partícióról olvas.</span><span class="sxs-lookup"><span data-stu-id="f9096-229">The Scheduler service is designed so that each container instance reads from a single partition.</span></span> <span data-ttu-id="f9096-230">Például, ha az Event Hubs 32 partícióval rendelkezik, a Feladatütemező szolgáltatás üzembe helyezése 32 replikákkal rendelkező.</span><span class="sxs-lookup"><span data-stu-id="f9096-230">For example, if the Event Hub has 32 partitions, the Scheduler service is deployed with 32 replicas.</span></span> <span data-ttu-id="f9096-231">Ez lehetővé teszi nagy rugalmasságot biztosít a horizontális skálázást tekintetében.</span><span class="sxs-lookup"><span data-stu-id="f9096-231">This allows for a lot of flexibility in terms of horizontal scaling.</span></span>

<span data-ttu-id="f9096-232">Attól függően, a fürt méretét a fürtben egy csomópont lehet egynél több Scheduler szolgáltatás pod rajta való futtatásához.</span><span class="sxs-lookup"><span data-stu-id="f9096-232">Depending on the size of the cluster, a node in the cluster might have more than one Scheduler service pod running on it.</span></span> <span data-ttu-id="f9096-233">Azonban ha a Scheduler szolgáltatás több erőforrást igényel, a fürt kiterjeszthető, annak érdekében, hogy a podok szét több csomópontot.</span><span class="sxs-lookup"><span data-stu-id="f9096-233">But if the Scheduler service needs more resources, the cluster can be scaled out, in order to distribute the pods across more nodes.</span></span> <span data-ttu-id="f9096-234">A teljesítménytesztek kimutatta, hogy a Scheduler szolgáltatás memória és a hozzászóláslánc-kötött, így teljesítmény nagy mértékben alárendelve, a virtuális gép mérete és a csomópontonként podok számát.</span><span class="sxs-lookup"><span data-stu-id="f9096-234">Our performance tests showed that the Scheduler service is memory- and thread-bound, so performance depended greatly on the VM size and the number of pods per node.</span></span>

<span data-ttu-id="f9096-235">Minden példány tudnia kell, amely az Event Hubs particionálása olvasni.</span><span class="sxs-lookup"><span data-stu-id="f9096-235">Each instance needs to know which Event Hubs partition to read from.</span></span> <span data-ttu-id="f9096-236">A partíciószám konfigurálásához meggyőződtünk előnye a [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) erőforrástípust a Kubernetesben.</span><span class="sxs-lookup"><span data-stu-id="f9096-236">To configure the partition number, we took advantage of the [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) resource type in Kubernetes.</span></span> <span data-ttu-id="f9096-237">Egy StatefulSet podok egy állandó azonosítója, amely tartalmaz egy numerikus indexszel rendelkezik.</span><span class="sxs-lookup"><span data-stu-id="f9096-237">Pods in a StatefulSet have a persistent identifier that includes a numeric index.</span></span> <span data-ttu-id="f9096-238">Pontosabban, a pod név `<statefulset name>-<index>`, és ez az érték érhető el a tárolóhoz, a Kubernetes használatával [lefelé irányuló API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span><span class="sxs-lookup"><span data-stu-id="f9096-238">Specifically, the pod name is `<statefulset name>-<index>`, and this value is available to the container through the Kubernetes [Downward API](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information/).</span></span> <span data-ttu-id="f9096-239">Futási időben a Scheduler szolgáltatás beolvassa a podnév, és a pod index használja, mint a partícióazonosító.</span><span class="sxs-lookup"><span data-stu-id="f9096-239">At run time, the Scheduler services reads the pod name and uses the pod index as the partition ID.</span></span>

<span data-ttu-id="f9096-240">Ha horizontális felskálázási még tovább a Scheduler szolgáltatás, hozzárendelhet egynél több pod event hub partíciónként, úgy, hogy az egyes partíciók több podok olvas.</span><span class="sxs-lookup"><span data-stu-id="f9096-240">If you needed to scale out the Scheduler service even further, you could assign more than one pod per event hub partition, so that multiple pods are reading each partition.</span></span> <span data-ttu-id="f9096-241">Azonban ebben az esetben minden példány volna olvasni az események a hozzárendelt partícióban.</span><span class="sxs-lookup"><span data-stu-id="f9096-241">However, in that case, each instance would read all of the events in the assigned partition.</span></span> <span data-ttu-id="f9096-242">Ismétlődő feldolgozási elkerülése érdekében kell egy kivonatoló algoritmus használatára, hogy minden példány kihagyja az üzeneteket egy része felett.</span><span class="sxs-lookup"><span data-stu-id="f9096-242">To avoid duplicate processing, you would need to use a hashing algorithm, so that each instance skips over a portion of the messages.</span></span> <span data-ttu-id="f9096-243">Ezzel a módszerrel több olvasók használhatnak fel, a streamet, de minden üzenetet csak egy példány dolgoz fel.</span><span class="sxs-lookup"><span data-stu-id="f9096-243">That way, multiple readers can consume the stream, but every message is processed by only one instance.</span></span>

![Event hub-kivonatolás ábrája](./images/eventhub-hashing.png)

### <a name="service-bus-queues"></a><span data-ttu-id="f9096-245">Service Bus-üzenetsorok</span><span class="sxs-lookup"><span data-stu-id="f9096-245">Service Bus queues</span></span>

<span data-ttu-id="f9096-246">Egy harmadik lehetőség, hogy mi számít az Event hubs szolgáltatástól érkező üzenetek másolása egy Service Bus-üzenetsorba, és majd a Scheduler szolgáltatás elolvasta az üzenetet a Service Bus.</span><span class="sxs-lookup"><span data-stu-id="f9096-246">A third option that we considered was to copy messages from Event Hubs into a Service Bus queue, and then have the Scheduler service read the messages from Service Bus.</span></span> <span data-ttu-id="f9096-247">Úgy tűnhet, meglepő írásakor a bejövő kérelmek csak, hogy másolja őket a Service Bus Event hubsba.</span><span class="sxs-lookup"><span data-stu-id="f9096-247">It might seem strange to writing the incoming requests into Event Hubs only to copy them in Service Bus.</span></span>  <span data-ttu-id="f9096-248">Azonban a cél volt, hogy az egyes szolgáltatások különböző előnyeit kihasználva: Az Event Hubs használatával a Service Bus egy versengő felhasználók mintája a számítási feladatok feldolgozásához a várólista szemantikát kihasználva számára a nagy forgalom, az adatforgalmi csúcsokhoz.</span><span class="sxs-lookup"><span data-stu-id="f9096-248">However, the idea was to leverage the different strengths of each service: Use Event Hubs to absorb spikes of heavy traffic, while taking advantage of the queue semantics in Service Bus to process the workload with a competing consumers pattern.</span></span> <span data-ttu-id="f9096-249">Ne feledje, hogy a célt a vendégteljesítmény kisebb, mint a várható terhelés, így feldolgozási a Service Bus-üzenetsorba nem kell lennie olyan gyors üzenetbetöltés.</span><span class="sxs-lookup"><span data-stu-id="f9096-249">Remember that our target for sustained throughput is less than our expected peak load, so processing the Service Bus queue would not need to be as fast the message ingestion.</span></span>

<span data-ttu-id="f9096-250">Ezzel a módszerrel proof-of-concept-implementáció érhető el, a 4 KB műveletek száma másodpercenként.</span><span class="sxs-lookup"><span data-stu-id="f9096-250">With this approach, our proof-of-concept implementation achieved about 4K operations per second.</span></span> <span data-ttu-id="f9096-251">Ezeket a teszteket, amelyek bármely valós munkát nem tette meg, de egyszerűen hozzáadott egy rögzített mértékű késés szolgáltatásonként utánzatként funkcionáló háttérszolgáltatások használja.</span><span class="sxs-lookup"><span data-stu-id="f9096-251">These tests used mock backend services that did not do any real work, but simply added a fixed amount of latency per service.</span></span> <span data-ttu-id="f9096-252">Vegye figyelembe, hogy a teljesítmény-számok is sokkal kevesebb, mint a Service Bus elméleti maximális.</span><span class="sxs-lookup"><span data-stu-id="f9096-252">Note that our performance numbers were much less than the theoretical maximum for Service Bus.</span></span> <span data-ttu-id="f9096-253">Az eltérés okai a következők:</span><span class="sxs-lookup"><span data-stu-id="f9096-253">Possible reasons for the discrepancy include:</span></span>

- <span data-ttu-id="f9096-254">Nem rendelkezik a különböző ügyfél-paraméterek, például a készlet kapcsolathoz megadott korlátot, a párhuzamos feldolgozás, a lehívott száma és a kötegméret fokú optimális értékeit.</span><span class="sxs-lookup"><span data-stu-id="f9096-254">Not having optimal values for various client parameters, such as the connection pool limit, the degree of parallelization, the prefetch count, and the batch size.</span></span>

- <span data-ttu-id="f9096-255">A hálózati szűk I/O keresztmetszetek.</span><span class="sxs-lookup"><span data-stu-id="f9096-255">Network I/O bottlenecks.</span></span>

- <span data-ttu-id="f9096-256">Felhasználása [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mód helyett [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), amely volt szükség, legalább egyszeri kézbesítési üzenetek biztosítása érdekében.</span><span class="sxs-lookup"><span data-stu-id="f9096-256">Use of [PeekLock](/rest/api/servicebus/peek-lock-message-non-destructive-read) mode rather than [ReceiveAndDelete](/rest/api/servicebus/receive-and-delete-message-destructive-read), which was needed to ensure at-least-once delivery of messages.</span></span>

<span data-ttu-id="f9096-257">További teljesítménytesztek előfordulhat, hogy az alapvető ok felderítése és számunkra, hogy a problémák megoldásához.</span><span class="sxs-lookup"><span data-stu-id="f9096-257">Further performance tests might have discovered the root cause and allowed us to resolve these issues.</span></span> <span data-ttu-id="f9096-258">Azonban IotHub React teljesül, a teljesítmény célt, ezért választottuk ezt a lehetőséget.</span><span class="sxs-lookup"><span data-stu-id="f9096-258">However, IotHub React met our performance target, so we chose that option.</span></span> <span data-ttu-id="f9096-259">Mindemellett a Service Bus az ebben a forgatókönyvben kivitelezhető lehetőség.</span><span class="sxs-lookup"><span data-stu-id="f9096-259">That said, Service Bus is a viable option for this scenario.</span></span>

## <a name="handling-failures"></a><span data-ttu-id="f9096-260">Hibák</span><span class="sxs-lookup"><span data-stu-id="f9096-260">Handling failures</span></span>

<span data-ttu-id="f9096-261">Nincsenek fontolja meg a hiba három általános osztályba.</span><span class="sxs-lookup"><span data-stu-id="f9096-261">There are three general classes of failure to consider.</span></span>

1. <span data-ttu-id="f9096-262">Előfordulhat, hogy az alárendelt szolgáltatás nem átmeneti hiba, amely minden hiba, amely nem valószínű, hogy megszabadítja önmagában.</span><span class="sxs-lookup"><span data-stu-id="f9096-262">A downstream service may have a non-transient failure, which is any failure that's unlikely to go away by itself.</span></span> <span data-ttu-id="f9096-263">Nem átmeneti hibák közé tartozik a normál hiba feltételek, például egy érvénytelen bemenet.</span><span class="sxs-lookup"><span data-stu-id="f9096-263">Non-transient failures include normal error conditions, such as invalid input to a method.</span></span> <span data-ttu-id="f9096-264">Is, nem kezelt kivételeket az alkalmazáskód vagy egy folyamat összeomlik.</span><span class="sxs-lookup"><span data-stu-id="f9096-264">They also include unhandled exceptions in application code or a process crashing.</span></span> <span data-ttu-id="f9096-265">Az ilyen típusú hiba akkor fordul elő, ha a teljes üzleti tranzakció sikertelen kell megjelölni.</span><span class="sxs-lookup"><span data-stu-id="f9096-265">If this type of error occurs, the entire business transaction must be marked as a failure.</span></span> <span data-ttu-id="f9096-266">Ugyanabban a tranzakcióban, amely sikeresen további lépések visszavonása szükség lehet.</span><span class="sxs-lookup"><span data-stu-id="f9096-266">It may be necessary to undo other steps in the same transaction that already succeeded.</span></span> <span data-ttu-id="f9096-267">(A kompenzáló tranzakció, lásd alább.)</span><span class="sxs-lookup"><span data-stu-id="f9096-267">(See Compensating Transactions, below.)</span></span>

2. <span data-ttu-id="f9096-268">Egy alárendelt szolgáltatás például egy hálózati időtúllépés átmeneti hibát tapasztalhat.</span><span class="sxs-lookup"><span data-stu-id="f9096-268">A downstream service may experience a transient failure such as a network timeout.</span></span> <span data-ttu-id="f9096-269">Ezek a hibák gyakran megoldhatók egyszerűen hívása újrapróbálása.</span><span class="sxs-lookup"><span data-stu-id="f9096-269">These errors can often be resolved simply by retrying the call.</span></span> <span data-ttu-id="f9096-270">Ha a művelet egy bizonyos számú kísérlet után is sikertelen, figyelembe vette nem átmeneti hiba.</span><span class="sxs-lookup"><span data-stu-id="f9096-270">If the operation still fails after a certain number of attempts, it's considered a non-transient failure.</span></span>

3. <span data-ttu-id="f9096-271">A Scheduler szolgáltatás előfordulhat, hogy tartalék (például azért, mert összeomlik, egy csomópont).</span><span class="sxs-lookup"><span data-stu-id="f9096-271">The Scheduler service itself might fault (for example, because a node crashes).</span></span> <span data-ttu-id="f9096-272">Ebben az esetben a Kubernetes megjelenik a szolgáltatás egy új példányát.</span><span class="sxs-lookup"><span data-stu-id="f9096-272">In that case, Kubernetes will bring up a new instance of the service.</span></span> <span data-ttu-id="f9096-273">Azonban már folyamatban lévő tranzakciók kell folytatni.</span><span class="sxs-lookup"><span data-stu-id="f9096-273">However, any transactions that were already in progress must be resumed.</span></span>

## <a name="compensating-transactions"></a><span data-ttu-id="f9096-274">Kompenzáló tranzakciók</span><span class="sxs-lookup"><span data-stu-id="f9096-274">Compensating transactions</span></span>

<span data-ttu-id="f9096-275">Nem átmeneti hiba történik, ha az aktuális tranzakció lehet egy *részben sikertelen* állapot, ahol egy vagy több lépést már sikeresen befejeződött.</span><span class="sxs-lookup"><span data-stu-id="f9096-275">If a non-transient failure happens, the current transaction might be in a *partially failed* state, where one or more steps already completed successfully.</span></span> <span data-ttu-id="f9096-276">Például ha a Drone szolgáltatás már ütemezve egy drónt, a drone kell megszakítva.</span><span class="sxs-lookup"><span data-stu-id="f9096-276">For example, if the Drone service already scheduled a drone, the drone must be canceled.</span></span> <span data-ttu-id="f9096-277">Ebben az esetben az alkalmazásnak kell, hogy sikeres volt-e, a lépések visszavonása egy [kompenzáló tranzakció](../patterns/compensating-transaction.md).</span><span class="sxs-lookup"><span data-stu-id="f9096-277">In that case, the application needs to undo the steps that succeeded, by using a [Compensating Transaction](../patterns/compensating-transaction.md).</span></span> <span data-ttu-id="f9096-278">Bizonyos esetekben ez kell elvégezni egy külső rendszer, vagy akár egy manuális folyamat.</span><span class="sxs-lookup"><span data-stu-id="f9096-278">In some cases, this must be done by an external system or even by a manual process.</span></span>

<span data-ttu-id="f9096-279">Ha a kompenzáló tranzakciók logika összetett, érdemes lehet külön szolgáltatás létrehozása felelős a folyamat.</span><span class="sxs-lookup"><span data-stu-id="f9096-279">If the logic for compensating transactions is complex, consider creating a separate service that is responsible for this process.</span></span> <span data-ttu-id="f9096-280">A Drone Delivery alkalmazás a Scheduler szolgáltatás sikertelen műveletek be egy dedikált üzenetsorba helyezi.</span><span class="sxs-lookup"><span data-stu-id="f9096-280">In the Drone Delivery application, the Scheduler service puts failed operations onto a dedicated queue.</span></span> <span data-ttu-id="f9096-281">Külön mikroszolgáltatások, a felügyelő nevű ebből az üzenetsorból olvas, és meghívja a lemondás API a meghiúsult lépések kompenzációjához szükséges szolgáltatásokat.</span><span class="sxs-lookup"><span data-stu-id="f9096-281">A separate microservice, called the Supervisor, reads from this queue and calls a cancellation API on the services that need to compensate.</span></span> <span data-ttu-id="f9096-282">Ez a kapcsolat egy változata a [Feladatütemező ügynök felügyeleti mintájának][scheduler-agent-supervisor].</span><span class="sxs-lookup"><span data-stu-id="f9096-282">This is a variation of the [Scheduler Agent Supervisor pattern][scheduler-agent-supervisor].</span></span> <span data-ttu-id="f9096-283">A felügyeleti szolgáltatás előfordulhat, hogy más műveletek is, például szöveg vagy e-mailt a felhasználó értesítése, vagy riasztást küldeni a műveleti irányítópult.</span><span class="sxs-lookup"><span data-stu-id="f9096-283">The Supervisor service might take other actions as well, such as notify the user by text or email, or send an alert to an operations dashboard.</span></span>

![A felügyelő mikroszolgáltatás bemutató ábra.](./images/supervisor.png)

## <a name="idempotent-vs-non-idempotent-operations"></a><span data-ttu-id="f9096-285">Idempotens vs nem idempotens műveletek</span><span class="sxs-lookup"><span data-stu-id="f9096-285">Idempotent vs non-idempotent operations</span></span>

<span data-ttu-id="f9096-286">Kérések elveszhetnek, a Feladatütemező szolgáltatás biztosítania kell, hogy minden üzenet legalább egyszer feldolgozása.</span><span class="sxs-lookup"><span data-stu-id="f9096-286">To avoid losing any requests, the Scheduler service must guarantee that all messages are processed at least once.</span></span> <span data-ttu-id="f9096-287">Az Event Hubs tud garantálni, legalább egyszeri kézbesítési, ha az ügyfél ellenőrzőpontokat megfelelően.</span><span class="sxs-lookup"><span data-stu-id="f9096-287">Event Hubs can guarantee at-least-once delivery if the client checkpoints correctly.</span></span>

<span data-ttu-id="f9096-288">A Scheduler szolgáltatás összeomlik, ha lehet feldolgozni az egy vagy több ügyfél küldött kérelmeket közepén.</span><span class="sxs-lookup"><span data-stu-id="f9096-288">If the Scheduler service crashes, it may be in the middle of processing one or more client requests.</span></span> <span data-ttu-id="f9096-289">Ezeket az üzeneteket fog dolgozza fel az ütemező egy másik példánya, és újra fel kell dolgozni.</span><span class="sxs-lookup"><span data-stu-id="f9096-289">Those messages will be picked up by another instance of the Scheduler and reprocessed.</span></span> <span data-ttu-id="f9096-290">Mi történik, ha a kérés feldolgozása kétszer van?</span><span class="sxs-lookup"><span data-stu-id="f9096-290">What happens if a request is processed twice?</span></span> <span data-ttu-id="f9096-291">Fontos elkerülhető a munka.</span><span class="sxs-lookup"><span data-stu-id="f9096-291">It's important to avoid duplicating any work.</span></span> <span data-ttu-id="f9096-292">Amikor az összes a rendszer két drónok esetében ugyanaz a csomag küldése nem szeretnénk.</span><span class="sxs-lookup"><span data-stu-id="f9096-292">After all, we don't want the system to send two drones for the same package.</span></span>

<span data-ttu-id="f9096-293">Egyik lehetőség, hogy úgy tervezze meg az összes, hogy idempotensek legyenek.</span><span class="sxs-lookup"><span data-stu-id="f9096-293">One approach is to design all operations to be idempotent.</span></span> <span data-ttu-id="f9096-294">Egy művelet idempotens esetén többször hívható az első hívása után további mellékhatásai előállító nélkül.</span><span class="sxs-lookup"><span data-stu-id="f9096-294">An operation is idempotent if it can be called multiple times without producing additional side-effects after the first call.</span></span> <span data-ttu-id="f9096-295">Más szóval egy ügyfél hívhat meg a műveletet egyszer, kétszer, vagy több alkalommal, és az eredmény ugyanaz lesz.</span><span class="sxs-lookup"><span data-stu-id="f9096-295">In other words, a client can invoke the operation once, twice, or many times, and the result will be the same.</span></span> <span data-ttu-id="f9096-296">A szolgáltatás lényegében, figyelmen kívül hagyja ismétlődő hívásokat.</span><span class="sxs-lookup"><span data-stu-id="f9096-296">Essentially, the service should ignore duplicate calls.</span></span> <span data-ttu-id="f9096-297">Az, hogy idempotensek lesznek hatásai mód esetén a szolgáltatás képes észlelni a duplikált hívások kell lennie.</span><span class="sxs-lookup"><span data-stu-id="f9096-297">For a method with side effects to be idempotent, the service must be able to detect duplicate calls.</span></span> <span data-ttu-id="f9096-298">Például rendelkezhet a hívó hozzárendelése a azonosító ahelyett, hogy a szolgáltatás hozzon létre egy új.</span><span class="sxs-lookup"><span data-stu-id="f9096-298">For example, you can have the caller assign the ID, rather than having the service generate a new ID.</span></span> <span data-ttu-id="f9096-299">A szolgáltatás is tekintse meg az ismétlődő azonosítók.</span><span class="sxs-lookup"><span data-stu-id="f9096-299">The service can then check for duplicate IDs.</span></span>

> [!NOTE]
> <span data-ttu-id="f9096-300">A HTTP-specifikációnak megállapítja, hogy a GET, PUT és DELETE-metódusok idempotensnek kell lenniük.</span><span class="sxs-lookup"><span data-stu-id="f9096-300">The HTTP specification states that GET, PUT, and DELETE methods must be idempotent.</span></span> <span data-ttu-id="f9096-301">POST metódus nem garantált, hogy idempotensek legyenek.</span><span class="sxs-lookup"><span data-stu-id="f9096-301">POST methods are not guaranteed to be idempotent.</span></span> <span data-ttu-id="f9096-302">Ha egy POST-metódus új erőforrást hoz létre, nincs általánosan garancia arra, hogy-e a művelet idempotens.</span><span class="sxs-lookup"><span data-stu-id="f9096-302">If a POST method creates a new resource, there is generally no guarantee that this operation is idempotent.</span></span>

<span data-ttu-id="f9096-303">Nem mindig idempotens metódus írása könnyen érthető megjegyzésblokkok írására.</span><span class="sxs-lookup"><span data-stu-id="f9096-303">It's not always straightforward to write idempotent method.</span></span> <span data-ttu-id="f9096-304">Egy másik lehetőség, a Scheduler az olyan tartós tárban minden egyes tranzakciót az előrehaladását úgy követheti nyomon.</span><span class="sxs-lookup"><span data-stu-id="f9096-304">Another option is for the Scheduler to track the progress of every transaction in a durable store.</span></span> <span data-ttu-id="f9096-305">Minden alkalommal, amikor feldolgozza az üzenetet, lenne az állapotát a tartós tárolóban.</span><span class="sxs-lookup"><span data-stu-id="f9096-305">Whenever it processes a message, it would look up the state in the durable store.</span></span> <span data-ttu-id="f9096-306">Minden lépése után azt kellene írni a az eredményt.</span><span class="sxs-lookup"><span data-stu-id="f9096-306">After each step, it would write the result to the store.</span></span> <span data-ttu-id="f9096-307">Előfordulhat, hogy ennek a módszernek a teljesítményre gyakorolt hatása.</span><span class="sxs-lookup"><span data-stu-id="f9096-307">There may be performance implications to this approach.</span></span>

## <a name="example-idempotent-operations"></a><span data-ttu-id="f9096-308">Példa: Idempotens műveletek</span><span class="sxs-lookup"><span data-stu-id="f9096-308">Example: Idempotent operations</span></span>

<span data-ttu-id="f9096-309">A HTTP-specifikációnak tájékoztatja, hogy a PUT módszerek idempotensnek kell lenniük.</span><span class="sxs-lookup"><span data-stu-id="f9096-309">The HTTP specification states that PUT methods must be idempotent.</span></span> <span data-ttu-id="f9096-310">A specifikációnak idempotens ily módon határozza meg:</span><span class="sxs-lookup"><span data-stu-id="f9096-310">The specification defines idempotent this way:</span></span>

> <span data-ttu-id="f9096-311">A kérelmi metódust "idempotens" számít, ha a tervezett hatása a kiszolgálón a a módszerrel több azonos kérések pedig ugyanaz, mint az egyetlen gyakorolt hatását kérelmet.</span><span class="sxs-lookup"><span data-stu-id="f9096-311">A request method is considered "idempotent" if the intended effect on the server of multiple identical requests with that method is the same as the effect for a single such request.</span></span> <span data-ttu-id="f9096-312">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span><span class="sxs-lookup"><span data-stu-id="f9096-312">([RFC 7231](https://tools.ietf.org/html/rfc7231#section-4))</span></span>

<span data-ttu-id="f9096-313">Új entitás létrehozásakor PUT, POST és szemantika közötti különbségek megértése fontos.</span><span class="sxs-lookup"><span data-stu-id="f9096-313">It's important to understand the difference between PUT and POST semantics when creating a new entity.</span></span> <span data-ttu-id="f9096-314">Mindkét esetben az ügyfél elküldi az entitás reprezentációját a kérelem törzsében.</span><span class="sxs-lookup"><span data-stu-id="f9096-314">In both cases, the client sends a representation of an entity in the request body.</span></span> <span data-ttu-id="f9096-315">De értelmében az URI azonosító nem egyezik.</span><span class="sxs-lookup"><span data-stu-id="f9096-315">But the meaning of the URI is different.</span></span>

- <span data-ttu-id="f9096-316">Egy POST-metódus az URI-t az új entitás, például egy gyűjteményt egy szülőerőforrás jelenti.</span><span class="sxs-lookup"><span data-stu-id="f9096-316">For a POST method, the URI represents a parent resource of the new entity, such as a collection.</span></span> <span data-ttu-id="f9096-317">Például hozzon létre egy új szállítási, hogy az URI-t lehet `/api/deliveries`.</span><span class="sxs-lookup"><span data-stu-id="f9096-317">For example, to create a new delivery, the URI might be `/api/deliveries`.</span></span> <span data-ttu-id="f9096-318">A kiszolgáló hoz létre az entitást, és hozzárendeli egy új URI-t, mint például `/api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="f9096-318">The server creates the entity and assigns it a new URI, such as `/api/deliveries/39660`.</span></span> <span data-ttu-id="f9096-319">Ez az URI a válasz Location fejléce adja vissza.</span><span class="sxs-lookup"><span data-stu-id="f9096-319">This URI is returned in the Location header of the response.</span></span> <span data-ttu-id="f9096-320">Minden alkalommal, amikor az ügyfél elküld egy kérelmet, a kiszolgáló hoz létre egy új entitást egy új URI-t.</span><span class="sxs-lookup"><span data-stu-id="f9096-320">Each time the client sends a request, the server will create a new entity with a new URI.</span></span>

- <span data-ttu-id="f9096-321">Az URI-t egy PUT metódust a azonosítja az entitást.</span><span class="sxs-lookup"><span data-stu-id="f9096-321">For a PUT method, the URI identifies the entity.</span></span> <span data-ttu-id="f9096-322">Ha már van egy entitás az URI-ra, a kiszolgáló felülírja a létező entitásba a változattal a kérésben.</span><span class="sxs-lookup"><span data-stu-id="f9096-322">If there already exists an entity with that URI, the server replaces the existing entity with the version in the request.</span></span> <span data-ttu-id="f9096-323">Ha nem entitás létezik, az URI-ra, a kiszolgáló létrehoz egyet.</span><span class="sxs-lookup"><span data-stu-id="f9096-323">If no entity exists with that URI, the server creates one.</span></span> <span data-ttu-id="f9096-324">Tegyük fel, az ügyfél küld egy PUT kérelem a `api/deliveries/39660`.</span><span class="sxs-lookup"><span data-stu-id="f9096-324">For example, suppose the client sends a PUT request to `api/deliveries/39660`.</span></span> <span data-ttu-id="f9096-325">Feltételezve, hogy nincs kézbesítési az URI-ra, a kiszolgáló létrehoz egy újat.</span><span class="sxs-lookup"><span data-stu-id="f9096-325">Assuming there is no delivery with that URI, the server creates a new one.</span></span> <span data-ttu-id="f9096-326">Most már az ügyfél elküld a kérésben újra, ha a kiszolgáló felülírja a létező entitásba.</span><span class="sxs-lookup"><span data-stu-id="f9096-326">Now if the client sends the same request again, the server will replace the existing entity.</span></span>

<span data-ttu-id="f9096-327">Íme a PUT metódust a kézbesítési szolgáltatás megvalósítását.</span><span class="sxs-lookup"><span data-stu-id="f9096-327">Here is the Delivery service's implementation of the PUT method.</span></span>

```csharp
[HttpPut("{id}")]
[ProducesResponseType(typeof(Delivery), 201)]
[ProducesResponseType(typeof(void), 204)]
public async Task<IActionResult> Put([FromBody]Delivery delivery, string id)
{
    logger.LogInformation("In Put action with delivery {Id}: {@DeliveryInfo}", id, delivery.ToLogInfo());
    try
    {
        var internalDelivery = delivery.ToInternal();

        // Create the new delivery entity.
        await deliveryRepository.CreateAsync(internalDelivery);

        // Create a delivery status event.
        var deliveryStatusEvent = new DeliveryStatusEvent { DeliveryId = delivery.Id, Stage = DeliveryEventType.Created };
        await deliveryStatusEventRepository.AddAsync(deliveryStatusEvent);

        // Return HTTP 201 (Created)
        return CreatedAtRoute("GetDelivery", new { id= delivery.Id }, delivery);
    }
    catch (DuplicateResourceException)
    {
        // This method is mainly used to create deliveries. If the delivery already exists then update it.
        logger.LogInformation("Updating resource with delivery id: {DeliveryId}", id);

        var internalDelivery = delivery.ToInternal();
        await deliveryRepository.UpdateAsync(id, internalDelivery);

        // Return HTTP 204 (No Content)
        return NoContent();
    }
}
```

<span data-ttu-id="f9096-328">Valószínű, hogy a legtöbb kérelmek létrehoz egy új entitást, így optimistically metódushívások `CreateAsync` a tárház objektum majd kezeli az olyan ismétlődő-erőforrás kivételek, amelyek inkább az erőforrás frissítésével.</span><span class="sxs-lookup"><span data-stu-id="f9096-328">It's expected that most requests will create a new entity, so the method optimistically calls `CreateAsync` on the repository object, and then handles any duplicate-resource exceptions by updating the resource instead.</span></span>

> [!div class="nextstepaction"]
> [<span data-ttu-id="f9096-329">API-átjárókat</span><span class="sxs-lookup"><span data-stu-id="f9096-329">API gateways</span></span>](./gateway.md)

<!-- links -->

[scheduler-agent-supervisor]: ../patterns/scheduler-agent-supervisor.md