---
title: "Kötegelt feldolgozás"
description: 
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: 55113b61c2684a7826fa6c0034503f842cdb840f
ms.sourcegitcommit: 90cf2de795e50571d597cfcb9b302e48933e7f18
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 02/14/2018
---
# <a name="batch-processing"></a><span data-ttu-id="189b0-102">Kötegelt feldolgozás</span><span class="sxs-lookup"><span data-stu-id="189b0-102">Batch processing</span></span>

<span data-ttu-id="189b0-103">Big Data típusú adatok forgatókönyve az inaktív adatok kötegelt feldolgozása.</span><span class="sxs-lookup"><span data-stu-id="189b0-103">A common big data scenario is batch processing of data at rest.</span></span> <span data-ttu-id="189b0-104">Ebben a forgatókönyvben az adatok tárolására, vagy az alkalmazás saját magát vagy egy vezénylési munkafolyamat betöltődik.</span><span class="sxs-lookup"><span data-stu-id="189b0-104">In this scenario, the source data is loaded into data storage, either by the source application itself or by an orchestration workflow.</span></span> <span data-ttu-id="189b0-105">Az adatfeldolgozás majd egy parallelized feladat, és a vezénylési munkafolyamat is kezdeményezheti helyben.</span><span class="sxs-lookup"><span data-stu-id="189b0-105">The data is then processed in-place by a parallelized job, which can also be initiated by the orchestration workflow.</span></span> <span data-ttu-id="189b0-106">A feldolgozási tartalmazhatják több iteratív lépés előtt az átalakítani kívánt eredmények be vannak töltve az analitikus adatok tárolóba, amely lekérdezhetők, elemzés és a jelentéskészítési összetevőket.</span><span class="sxs-lookup"><span data-stu-id="189b0-106">The processing may include multiple iterative steps before the transformed results are loaded into an analytical data store, which can be queried by analytics and reporting components.</span></span>

<span data-ttu-id="189b0-107">Például a webkiszolgáló naplói mappába másolt előfordulhat, hogy, és majd feldolgozásra éjszaka a webkiszolgáló tevékenységének napi jelentések készítése.</span><span class="sxs-lookup"><span data-stu-id="189b0-107">For example, the logs from a web server might be copied to a folder and then processed overnight to generate daily reports of web activity.</span></span>

![](./images/batch-pipeline.png)

## <a name="when-to-use-this-solution"></a><span data-ttu-id="189b0-108">Ez a megoldás használatával</span><span class="sxs-lookup"><span data-stu-id="189b0-108">When to use this solution</span></span>

<span data-ttu-id="189b0-109">Kötegfeldolgozási lehetőségeket, egyszerű adatátalakítást jóval összetettebb ETL (extract-átalakítási-betöltés)-feldolgozási folyamat különböző használatban van.</span><span class="sxs-lookup"><span data-stu-id="189b0-109">Batch processing is used in a variety of scenarios, from simple data transformations to a more complete ETL (extract-transform-load) pipeline.</span></span> <span data-ttu-id="189b0-110">A big Data típusú adatok környezetben kötegfeldolgozási előfordulhat, hogy hatnak a nagyon nagy méretű adatkészletekhez, ahol a számítási jelentős időt vesz igénybe.</span><span class="sxs-lookup"><span data-stu-id="189b0-110">In a big data context, batch processing may operate over very large data sets, where the computation takes significant time.</span></span> <span data-ttu-id="189b0-111">(Lásd például: [Lambda architektúra](../concepts/big-data.md##lambda-architecture).) Kötegfeldolgozási általában további interaktív adatkutatási vezet, a modellezési használatra kész adatokat biztosít a gépi tanulás, vagy a adatokat ír az adattároló, amely elemzés és -megjelenítésre van optimalizálva.</span><span class="sxs-lookup"><span data-stu-id="189b0-111">(For example, see [Lambda architecture](../concepts/big-data.md##lambda-architecture).) Batch processing typically leads to further interactive exploration, provides the modeling-ready data for machine learning, or writes the data to a data store that is optimized for analytics and visualization.</span></span>

<span data-ttu-id="189b0-112">Egy példa a köteges feldolgozás van átalakítása egyszerű, félig strukturált CSV- vagy JSON-fájlok számos olyan formátumra sematizált és strukturált, amely készen áll a további lekérdezése.</span><span class="sxs-lookup"><span data-stu-id="189b0-112">One example of batch processing is transforming a large set of flat, semi-structured CSV or JSON files into a schematized and structured format that is ready for further querying.</span></span> <span data-ttu-id="189b0-113">Általában az adatok alakul a nyers formátumok adatfeldolgozást (például a fürt megosztott kötetei szolgáltatás) használatos bináris formátum, amelyek több performant lekérdezése, mert az adat tárolása oszlopos formátumot, és gyakran biztosítanak az indexek és az adatok beágyazott statisztikája.</span><span class="sxs-lookup"><span data-stu-id="189b0-113">Typically the data is converted from the raw formats used for ingestion (such as CSV) into binary formats that are more performant for querying because they store data in a columnar format, and often provide indexes and inline statistics about the data.</span></span>

## <a name="challenges"></a><span data-ttu-id="189b0-114">Kihívásai</span><span class="sxs-lookup"><span data-stu-id="189b0-114">Challenges</span></span>

- <span data-ttu-id="189b0-115">**Adatok formázása és kódolás**.</span><span class="sxs-lookup"><span data-stu-id="189b0-115">**Data format and encoding**.</span></span> <span data-ttu-id="189b0-116">A legbonyolultabb problémák hibakeresési fordulhat elő, ha a fájlok használata érvénytelen formátumú vagy kódolást.</span><span class="sxs-lookup"><span data-stu-id="189b0-116">Some of the most difficult issues to debug happen when files use an unexpected format or encoding.</span></span> <span data-ttu-id="189b0-117">Például forrásfájlok előfordulhat, hogy az UTF-16 és UTF-8 kódolását, vagy váratlan elválasztó karaktert (hely és a lapon) tartalmaz, vagy használni nem várt karakter.</span><span class="sxs-lookup"><span data-stu-id="189b0-117">For example, source files might use a mix of UTF-16 and UTF-8 encoding, or contain unexpected delimiters (space versus tab), or include unexpected characters.</span></span> <span data-ttu-id="189b0-118">Egy másik közös: tartalmazó lapokat, szóközök és vesszővel válassza el egymástól, amelyeket az elválasztó karakterként szöveg mezők.</span><span class="sxs-lookup"><span data-stu-id="189b0-118">Another common example is text fields that contain tabs, spaces, or commas that are interpreted as delimiters.</span></span> <span data-ttu-id="189b0-119">Adatok betöltése és értelmezése logika vajon elég rugalmas az észlelésére, és ezek a problémák kezelésére kell lennie.</span><span class="sxs-lookup"><span data-stu-id="189b0-119">Data loading and parsing logic must be flexible enough to detect and handle these issues.</span></span>

- <span data-ttu-id="189b0-120">**Időszeletek megvalósításában.**</span><span class="sxs-lookup"><span data-stu-id="189b0-120">**Orchestrating time slices.**</span></span> <span data-ttu-id="189b0-121">Gyakran a forrásadatok el van helyezve a mappahierarchiában, amely tükrözi a feldolgozási windows év, hónap, nap, óra, és így tovább szerint vannak rendezve.</span><span class="sxs-lookup"><span data-stu-id="189b0-121">Often source data is placed in a folder hierarchy that reflects processing windows, organized by year, month, day, hour, and so on.</span></span> <span data-ttu-id="189b0-122">Bizonyos esetekben adatok előfordulhat, hogy az ügyfélszámítógépekre érkeznek késői.</span><span class="sxs-lookup"><span data-stu-id="189b0-122">In some cases, data may arrive late.</span></span> <span data-ttu-id="189b0-123">Tegyük fel például, hogy a webkiszolgáló nem, és a naplókat. március 7. március 9-ig feldolgozásra a mappában nem végződhet.</span><span class="sxs-lookup"><span data-stu-id="189b0-123">For example, suppose that a web server fails, and the logs for March 7th don't end up in the folder for processing until March 9th.</span></span> <span data-ttu-id="189b0-124">Ezek csak figyelmen kívül hagyja, mert túl későn fontosságúak?</span><span class="sxs-lookup"><span data-stu-id="189b0-124">Are they just ignored because they're too late?</span></span> <span data-ttu-id="189b0-125">Az alárendelt feldolgozási logikai kezelni tud a soron rekordok?</span><span class="sxs-lookup"><span data-stu-id="189b0-125">Can the downstream processing logic handle out-of-order records?</span></span>

## <a name="architecture"></a><span data-ttu-id="189b0-126">Architektúra</span><span class="sxs-lookup"><span data-stu-id="189b0-126">Architecture</span></span>

<span data-ttu-id="189b0-127">A kötegelt architektúrákban rendelkezik a következő logikai összetevők, a fenti ábrán is látható.</span><span class="sxs-lookup"><span data-stu-id="189b0-127">A batch processing architecture has the following logical components, shown in the diagram above.</span></span>

- <span data-ttu-id="189b0-128">**Adattárolás.**</span><span class="sxs-lookup"><span data-stu-id="189b0-128">**Data storage.**</span></span> <span data-ttu-id="189b0-129">Általában egy elosztott szolgáltatásfájl-tároló, amely a különböző formátumokban nagy fájlok jelentős mennyiségű tára szolgálhatnak.</span><span class="sxs-lookup"><span data-stu-id="189b0-129">Typically a distributed file store that can serve as a repository for high volumes of large files in various formats.</span></span> <span data-ttu-id="189b0-130">Általános az ilyen tároló gyakran nevezik data lake.</span><span class="sxs-lookup"><span data-stu-id="189b0-130">Generically, this kind of store is often referred to as a data lake.</span></span> 

- <span data-ttu-id="189b0-131">**Kötegfeldolgozási.**</span><span class="sxs-lookup"><span data-stu-id="189b0-131">**Batch processing.**</span></span> <span data-ttu-id="189b0-132">A big Data típusú adatok nagy mennyiségű jellege gyakran azt jelenti, hogy a megoldások kell feldolgozni az adatfájlok hosszan futó kötegelt feladatok segítségével szűréséhez, összesített és ellenkező esetben az adatok előkészítése az analysis.</span><span class="sxs-lookup"><span data-stu-id="189b0-132">The high-volume nature of big data often means that solutions must process data files using long-running batch jobs to filter, aggregate, and otherwise prepare the data for analysis.</span></span> <span data-ttu-id="189b0-133">Általában ezeket a feladatokat tartalmaz, amely forrásfájlok olvasása, őket, és a kimeneti új fájlok írása.</span><span class="sxs-lookup"><span data-stu-id="189b0-133">Usually these jobs involve reading source files, processing them, and writing the output to new files.</span></span> 

- <span data-ttu-id="189b0-134">**Analitikai adatokat tároló.**</span><span class="sxs-lookup"><span data-stu-id="189b0-134">**Analytical data store.**</span></span> <span data-ttu-id="189b0-135">Adatok előkészítése az elemzési és a feldolgozott adatok szolgáljanak strukturált formátuma nem kérdezhetők le analitikai eszközeivel sok big data-megoldások tervezték.</span><span class="sxs-lookup"><span data-stu-id="189b0-135">Many big data solutions are designed to prepare data for analysis and then serve the processed data in a structured format that can be queried using analytical tools.</span></span> 

- <span data-ttu-id="189b0-136">**Elemzési és jelentéskészítési.**</span><span class="sxs-lookup"><span data-stu-id="189b0-136">**Analysis and reporting.**</span></span> <span data-ttu-id="189b0-137">A legtöbb big data-megoldások célja az adatok elemzési és jelentéskészítési betekintést.</span><span class="sxs-lookup"><span data-stu-id="189b0-137">The goal of most big data solutions is to provide insights into the data through analysis and reporting.</span></span> 

- <span data-ttu-id="189b0-138">**Orchestration.**</span><span class="sxs-lookup"><span data-stu-id="189b0-138">**Orchestration.**</span></span> <span data-ttu-id="189b0-139">Kötegfeldolgozási, általában néhány vezénylési szükség, áttelepítése vagy az adatait átmásolja az adatokat tároló, a batch-feldolgozás, analitikai adatok, és jelentéskészítés rétegek.</span><span class="sxs-lookup"><span data-stu-id="189b0-139">With batch processing, typically some orchestration is required to migrate or copy the data into your data storage, batch processing, analytical data store, and reporting layers.</span></span>

## <a name="technology-choices"></a><span data-ttu-id="189b0-140">Technológiai lehetőségek</span><span class="sxs-lookup"><span data-stu-id="189b0-140">Technology choices</span></span>

<span data-ttu-id="189b0-141">A következő technológiákat lehetőségek kötegfeldolgozási megoldások Azure-ban a használata ajánlott.</span><span class="sxs-lookup"><span data-stu-id="189b0-141">The following technologies are recommended choices for batch processing solutions in Azure.</span></span>

### <a name="data-storage"></a><span data-ttu-id="189b0-142">Adattárolás</span><span class="sxs-lookup"><span data-stu-id="189b0-142">Data storage</span></span>

- <span data-ttu-id="189b0-143">**Az Azure Storage-Blob tárolók**.</span><span class="sxs-lookup"><span data-stu-id="189b0-143">**Azure Storage Blob Containers**.</span></span> <span data-ttu-id="189b0-144">Meglévő Azure üzleti folyamatok már igénybe az Azure blob-tároló, így ez nagy adattároló jó választás.</span><span class="sxs-lookup"><span data-stu-id="189b0-144">Many existing Azure business processes already make use of Azure blob storage, making this a good choice for a big data store.</span></span>
- <span data-ttu-id="189b0-145">**Az Azure Data Lake Store**.</span><span class="sxs-lookup"><span data-stu-id="189b0-145">**Azure Data Lake Store**.</span></span> <span data-ttu-id="189b0-146">Azure Data Lake Store bármilyen méretű fájlt, és a széles körű biztonsági beállítások, az gyakorlatilag korlátlan tárterületet biztosít, így jól funkcionálnak a rendkívül nagy méretű big data-megoldások, amely egy központi tárolóban igényel a heterogén formátumú adatok.</span><span class="sxs-lookup"><span data-stu-id="189b0-146">Azure Data Lake Store offers virtually unlimited storage for any size of file, and extensive security options, making it a good choice for extremely large-scale big data solutions that require a centralized store for data in heterogeneous formats.</span></span>

<span data-ttu-id="189b0-147">További információkért lásd: [adattárolás](../technology-choices/data-storage.md).</span><span class="sxs-lookup"><span data-stu-id="189b0-147">For more information, see [Data storage](../technology-choices/data-storage.md).</span></span>

### <a name="batch-processing"></a><span data-ttu-id="189b0-148">Kötegelt feldolgozás</span><span class="sxs-lookup"><span data-stu-id="189b0-148">Batch processing</span></span>

- <span data-ttu-id="189b0-149">**U-SQL**.</span><span class="sxs-lookup"><span data-stu-id="189b0-149">**U-SQL**.</span></span> <span data-ttu-id="189b0-150">U-SQL Ez a lekérdezés feldolgozása az Azure Data Lake Analytics nyelvét.</span><span class="sxs-lookup"><span data-stu-id="189b0-150">U-SQL is the query processing language used by Azure Data Lake Analytics.</span></span> <span data-ttu-id="189b0-151">SQL deklaratív természetét a C# eljárási bővítési egyesíti, és kihasználja a párhuzamos végrehajtás engedélyezése a nagy méretű adatok hatékony kezelésére.</span><span class="sxs-lookup"><span data-stu-id="189b0-151">It combines the declarative nature of SQL with the procedural extensibility of C#, and takes advantage of parallelism to enable efficient processing of data at massive scale.</span></span>
- <span data-ttu-id="189b0-152">**Hive**.</span><span class="sxs-lookup"><span data-stu-id="189b0-152">**Hive**.</span></span> <span data-ttu-id="189b0-153">Hive a legtöbb Hadoop terjesztéseket, beleértve a HDInsight a támogatott SQL-szerű nyelven.</span><span class="sxs-lookup"><span data-stu-id="189b0-153">Hive is a SQL-like language that is supported in most Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="189b0-154">Feldolgozott adatok a HDFS-kompatibilis áruházból, például az Azure blob storage és az Azure Data Lake Store használható.</span><span class="sxs-lookup"><span data-stu-id="189b0-154">It can be used to process data from any HDFS-compatible store, including Azure blob storage and Azure Data Lake Store.</span></span>
- <span data-ttu-id="189b0-155">**A Pig**.</span><span class="sxs-lookup"><span data-stu-id="189b0-155">**Pig**.</span></span> <span data-ttu-id="189b0-156">A Pig egy deklaratív nagy adatfeldolgozási Hadoop terjesztések, beleértve a HDInsight-ben használt nyelvhez.</span><span class="sxs-lookup"><span data-stu-id="189b0-156">Pig is a declarative big data processing language used in many Hadoop distributions, including HDInsight.</span></span> <span data-ttu-id="189b0-157">Különösen célszerű strukturálatlan és félig strukturált adatok feldolgozására.</span><span class="sxs-lookup"><span data-stu-id="189b0-157">It is particularly useful for processing data that is unstructured or semi-structured.</span></span>
- <span data-ttu-id="189b0-158">**Spark**.</span><span class="sxs-lookup"><span data-stu-id="189b0-158">**Spark**.</span></span> <span data-ttu-id="189b0-159">A Spark-motor számos különböző nyelveken, többek között a Java, Scala és Python nyelven írt kötegfeldolgozási programok támogatja.</span><span class="sxs-lookup"><span data-stu-id="189b0-159">The Spark engine supports batch processing programs written in a range of languages, including Java, Scala, and Python.</span></span> <span data-ttu-id="189b0-160">Spark párhuzamosan adatfeldolgozásra történő egy felosztott architektúrában több munkavégző csomópontokhoz használ.</span><span class="sxs-lookup"><span data-stu-id="189b0-160">Spark uses a distributed architecture to process data in parallel across multiple worker nodes.</span></span>

<span data-ttu-id="189b0-161">További információkért lásd: [kötegfeldolgozási](../technology-choices/batch-processing.md).</span><span class="sxs-lookup"><span data-stu-id="189b0-161">For more information, see [Batch processing](../technology-choices/batch-processing.md).</span></span>

### <a name="analytical-data-store"></a><span data-ttu-id="189b0-162">Analitikai adatokat tároló</span><span class="sxs-lookup"><span data-stu-id="189b0-162">Analytical data store</span></span>

- <span data-ttu-id="189b0-163">**Az SQL Data Warehouse**.</span><span class="sxs-lookup"><span data-stu-id="189b0-163">**SQL Data Warehouse**.</span></span> <span data-ttu-id="189b0-164">Az SQL Data Warehouse egy olyan felügyelt szolgáltatás SQL Server adatbázis technológiák alapján, és nagy méretű adatraktározás számítási feladatainál támogatása optimalizált.</span><span class="sxs-lookup"><span data-stu-id="189b0-164">Azure SQL Data Warehouse is a managed service based on SQL Server database technologies and optimized to support large-scale data warehousing workloads.</span></span>
- <span data-ttu-id="189b0-165">**Spark SQL**.</span><span class="sxs-lookup"><span data-stu-id="189b0-165">**Spark SQL**.</span></span> <span data-ttu-id="189b0-166">Spark SQL az API-k, amely támogatja a létrehozása dataframes és -táblázatot, amely az SQL-szintaxis használatával lehet lekérdezni a Spark épül.</span><span class="sxs-lookup"><span data-stu-id="189b0-166">Spark SQL is an API built on Spark that supports the creation of dataframes and tables that can be queried using SQL syntax.</span></span>
- <span data-ttu-id="189b0-167">**A HBase**.</span><span class="sxs-lookup"><span data-stu-id="189b0-167">**HBase**.</span></span> <span data-ttu-id="189b0-168">A HBase a kis késleltetésű NoSQL tárolóban, vagy félig strukturált adatok lekérdezése egy nagy teljesítményű, rugalmas lehetőséget is kínál.</span><span class="sxs-lookup"><span data-stu-id="189b0-168">HBase is a low-latency NoSQL store that offers a high-performance, flexible option for querying structured and semi-structured data.</span></span>
- <span data-ttu-id="189b0-169">**Hive**.</span><span class="sxs-lookup"><span data-stu-id="189b0-169">**Hive**.</span></span> <span data-ttu-id="189b0-170">Hasznosak lehetnek a köteges feldolgozás alatt álló, Hive elméleti szinten hasonló egy tipikus relációs adatbázis-kezelő rendszer egy adatbázis-architektúra lehetőséget biztosít.</span><span class="sxs-lookup"><span data-stu-id="189b0-170">In addition to being useful for batch processing, Hive offers a database architecture that is conceptually similar to that of a typical relational database management system.</span></span> <span data-ttu-id="189b0-171">Fejlesztések a Hive-lekérdezések teljesítményét innovációinak keresztül, például a Tez-motor és, hogy Hive táblák használható hatékonyan forrásként bizonyos esetekben elemzési lekérdezések Stinger kezdeményezésére közepét.</span><span class="sxs-lookup"><span data-stu-id="189b0-171">Improvements in Hive query performance through innovations like the Tez engine and Stinger initiative mean that Hive tables can be used effectively as sources for analytical queries in some scenarios.</span></span>

<span data-ttu-id="189b0-172">További információkért lásd: [analitikai adattárolókhoz](../technology-choices/analytical-data-stores.md).</span><span class="sxs-lookup"><span data-stu-id="189b0-172">For more information, see [Analytical data stores](../technology-choices/analytical-data-stores.md).</span></span>

### <a name="analytics-and-reporting"></a><span data-ttu-id="189b0-173">Elemzés és jelentéskészítés</span><span class="sxs-lookup"><span data-stu-id="189b0-173">Analytics and reporting</span></span>

- <span data-ttu-id="189b0-174">**Az Azure Analysis Services**.</span><span class="sxs-lookup"><span data-stu-id="189b0-174">**Azure Analysis Services**.</span></span> <span data-ttu-id="189b0-175">Sok big data-megoldások hagyományos vállalati üzleti intelligencia architektúrák emulálni (más néven a kocka) központi online analitikus feldolgozási (OLAP) adatmodell-ot a jelentéseket, irányítópultok, és interaktív "részletekbe menően" Analysis-alapú lehet.</span><span class="sxs-lookup"><span data-stu-id="189b0-175">Many big data solutions emulate traditional enterprise business intelligence architectures by including a centralized online analytical processing (OLAP) data model (often referred to as a cube) on which reports, dashboards, and interactive “slice and dice” analysis can be based.</span></span> <span data-ttu-id="189b0-176">Az Azure Analysis Services többdimenziós és táblázatos modellek az igénynek a kielégítése létrehozását támogatja.</span><span class="sxs-lookup"><span data-stu-id="189b0-176">Azure Analysis Services supports the creation of multidimensional and tabular models to meet this need.</span></span>
- <span data-ttu-id="189b0-177">**Power BI**.</span><span class="sxs-lookup"><span data-stu-id="189b0-177">**Power BI**.</span></span> <span data-ttu-id="189b0-178">A Power BI lehetővé teszi, hogy az adatelemzők, az adatok interaktív képi megjelenítéseket készíthet, az OLAP-modell, vagy közvetlenül az analitikus adatok áruházból adatmodellekben alapján.</span><span class="sxs-lookup"><span data-stu-id="189b0-178">Power BI enables data analysts to create interactive data visualizations based on data models in an OLAP model or directly from an analytical data store.</span></span>
- <span data-ttu-id="189b0-179">**Microsoft Excel**.</span><span class="sxs-lookup"><span data-stu-id="189b0-179">**Microsoft Excel**.</span></span> <span data-ttu-id="189b0-180">Microsoft Excel a világ a legszélesebb körben használt szoftverek alkalmazáshoz, és számos olyan adatok elemzése és a képi megjelenítés lehetőségeket kínál.</span><span class="sxs-lookup"><span data-stu-id="189b0-180">Microsoft Excel is one of the most widely used software applications in the world, and offers a wealth of data analysis and visualization capabilities.</span></span> <span data-ttu-id="189b0-181">Adatelemzők használható Excel dokumentum adatmodelleket építhetnek analitikai adatok áruházakból, illetve OLAP adatmodellekben interaktív kimutatások és diagramokat az adatok lekérése.</span><span class="sxs-lookup"><span data-stu-id="189b0-181">Data analysts can use Excel to build document data models from analytical data stores, or to retrieve data from OLAP data models into interactive PivotTables and charts.</span></span>

<span data-ttu-id="189b0-182">További információkért lásd: [elemzési és jelentéskészítési](../technology-choices/analysis-visualizations-reporting.md).</span><span class="sxs-lookup"><span data-stu-id="189b0-182">For more information, see [Analytics and reporting](../technology-choices/analysis-visualizations-reporting.md).</span></span>

### <a name="orchestration"></a><span data-ttu-id="189b0-183">Adat-előkészítés</span><span class="sxs-lookup"><span data-stu-id="189b0-183">Orchestration</span></span>

- <span data-ttu-id="189b0-184">**Az Azure Data Factory**.</span><span class="sxs-lookup"><span data-stu-id="189b0-184">**Azure Data Factory**.</span></span> <span data-ttu-id="189b0-185">Az Azure Data Factory folyamatok használható tevékenységek, ismétlődő historikus windows az ütemezett sorrendje határozza meg.</span><span class="sxs-lookup"><span data-stu-id="189b0-185">Azure Data Factory pipelines can be used to define a sequence of activities, scheduled for recurring temporal windows.</span></span> <span data-ttu-id="189b0-186">Ezek a tevékenységek adatok másolási műveleteket, valamint az igény szerinti HDInsight-fürtök; Hive, Pig, MapReduce vagy Spark feladatok is kezdeményezhető. U-SQL feladatok Azure dátum Lake Analytics; és tárolt eljárások az Azure SQL Data Warehouse vagy az Azure SQL Database.</span><span class="sxs-lookup"><span data-stu-id="189b0-186">These activities can initiate data copy operations as well as Hive, Pig, MapReduce, or Spark jobs in on-demand HDInsight clusters; U-SQL jobs in Azure Date Lake Analytics; and stored procedures in Azure SQL Data Warehouse or Azure SQL Database.</span></span>
- <span data-ttu-id="189b0-187">**Oozie** és **Sqoop**.</span><span class="sxs-lookup"><span data-stu-id="189b0-187">**Oozie** and **Sqoop**.</span></span> <span data-ttu-id="189b0-188">Oozie szolgáló feladat automation motor az Apache Hadoop-ökoszisztéma és adatok másolási műveleteket, valamint a Hive, Pig és MapReduce feladatokat dolgoz fel adatokat és a Sqoop feladatok, másolja az adatokat HDFS és SQL-adatbázisok között kezdeményezheti használható.</span><span class="sxs-lookup"><span data-stu-id="189b0-188">Oozie is a job automation engine for the Apache Hadoop ecosystem and can be used to initiate data copy operations as well as Hive, Pig, and MapReduce jobs to process data and Sqoop jobs to copy data between HDFS and SQL databases.</span></span>

<span data-ttu-id="189b0-189">További információkért lásd: [orchestration-feldolgozási folyamat](../technology-choices/pipeline-orchestration-data-movement.md)</span><span class="sxs-lookup"><span data-stu-id="189b0-189">For more information, see [Pipeline orchestration](../technology-choices/pipeline-orchestration-data-movement.md)</span></span>