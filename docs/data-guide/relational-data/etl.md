---
title: Kinyerés, átalakítás és betöltés (ETL)
description: ''
author: zoinerTejada
ms:date: 02/12/2018
ms.openlocfilehash: 1879b649fa3dfdf5c00f8ee30e53b83f7139fbf0
ms.sourcegitcommit: 51f49026ec46af0860de55f6c082490e46792794
ms.translationtype: MT
ms.contentlocale: hu-HU
ms.lasthandoff: 04/03/2018
ms.locfileid: "30301113"
---
# <a name="extract-transform-and-load-etl"></a><span data-ttu-id="9139d-102">Kinyerés, átalakítás és betöltés (ETL)</span><span class="sxs-lookup"><span data-stu-id="9139d-102">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="9139d-103">A szervezetek szembesülhetnek gyakori probléma az adatgyűjtés több adatok több formátumban adatforrásokat, és helyezze az egy vagy több adatok tárolási módja.</span><span class="sxs-lookup"><span data-stu-id="9139d-103">A common problem that organizations face is how to gathering data from multiple sources, in multiple formats, and move it to one or more data stores.</span></span> <span data-ttu-id="9139d-104">A cél nem lehet adattár ugyanolyan típusú, mint a forráskiszolgálón, és gyakran a formátum nem egyezik, vagy alakú, vagy az azokat a végső rendeltetési hely betöltése előtt törölni kell az adatokat.</span><span class="sxs-lookup"><span data-stu-id="9139d-104">The destination may not be the same type of data store as the source, and often the format is different, or the data needs to be shaped or cleaned before loading it into its final destination.</span></span>

<span data-ttu-id="9139d-105">Különböző eszközök, szolgáltatások és folyamatok ezekkel a kihívásokkal fejlesztettek az évek cím segítségével.</span><span class="sxs-lookup"><span data-stu-id="9139d-105">Various tools, services, and processes have been developed over the years to help address these challenges.</span></span> <span data-ttu-id="9139d-106">Függetlenül attól, a folyamat használja szükség van a közös koordinálja a munkahelyi és bizonyos fokú adatok átalakítása a adatok feldolgozási folyamat belül érvényesek.</span><span class="sxs-lookup"><span data-stu-id="9139d-106">No matter the process used, there is a common need to coordinate the work and apply some level of data transformation within the data pipeline.</span></span> <span data-ttu-id="9139d-107">A következő szakaszok kiemelnek gyakran a feladatok végrehajtásához használt módszer.</span><span class="sxs-lookup"><span data-stu-id="9139d-107">The following sections highlight the common methods used to perform these tasks.</span></span>

## <a name="extract-transform-and-load-etl"></a><span data-ttu-id="9139d-108">Kinyerés, átalakítás és betöltés (ETL)</span><span class="sxs-lookup"><span data-stu-id="9139d-108">Extract, transform, and load (ETL)</span></span>

<span data-ttu-id="9139d-109">Kinyerési, átalakítási és betöltési (ETL) egy adatok feldolgozási folyamat különböző forrásokból származó adatok összegyűjtése, az adatok üzleti szabályok szerint, és töltse be a cél-tárolóban.</span><span class="sxs-lookup"><span data-stu-id="9139d-109">Extract, transform, and load (ETL) is a data pipeline used to collect data from various sources, transform the data according to business rules, and load it into a destination data store.</span></span> <span data-ttu-id="9139d-110">Az átalakítási munkahelyi az ETL történik, egy speciális motor, és gyakran a ideiglenesen fenntartási adatok átmeneti tárolási táblák használata, mert folyamatban van szükséges át legyenek-e, és végső soron a rendeltetési betölteni.</span><span class="sxs-lookup"><span data-stu-id="9139d-110">The transformation work in ETL takes place in a specialized engine, and often involves using staging tables to temporarily hold data as it is being transformed and ultimately loaded to its destination.</span></span>

<span data-ttu-id="9139d-111">Az adatok átalakítása, általában akkor történik, magában foglalja a különböző műveletek, például a szűrési, rendezési, összesítése, adatok csatlakoztatása, adattisztításon, deduplikálása és az adatok.</span><span class="sxs-lookup"><span data-stu-id="9139d-111">The data transformation that takes place usually involves various operations, such as filtering, sorting, aggregating, joining data, cleaning data, deduplicating, and validating data.</span></span>

![Kivonat-átalakítási-betöltési (ETL) folyamat](../images/etl.png)

<span data-ttu-id="9139d-113">ETL folyamat három szakaszból gyakran, időt takaríthat párhuzamosan futnak.</span><span class="sxs-lookup"><span data-stu-id="9139d-113">Often, the three ETL phases are run in parallel to save time.</span></span> <span data-ttu-id="9139d-114">Például adatok kibontása folyamatban van, amíg egy átalakítási folyamat is működik-e a már fogadott adatok és előkészíthető a betöltése, és egy betöltése folyamat elkezdheti az előkészített adatok a ahelyett, hogy a teljes kinyerési folyamat befejezésére történő várakozáskor végezze el.</span><span class="sxs-lookup"><span data-stu-id="9139d-114">For example, while data is being extracted, a transformation process could be working on data already received and prepare it for loading, and a loading process can begin working on the prepared data, rather than waiting for the entire extraction process to complete.</span></span>

<span data-ttu-id="9139d-115">Kapcsolódó Azure-szolgáltatás:</span><span class="sxs-lookup"><span data-stu-id="9139d-115">Relevant Azure service:</span></span>
- [<span data-ttu-id="9139d-116">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="9139d-116">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="9139d-117">Más eszközök:</span><span class="sxs-lookup"><span data-stu-id="9139d-117">Other tools:</span></span>
- [<span data-ttu-id="9139d-118">Az SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="9139d-118">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="extract-load-and-transform-elt"></a><span data-ttu-id="9139d-119">Kinyerési, betöltés és átalakítás (ELT)</span><span class="sxs-lookup"><span data-stu-id="9139d-119">Extract, load, and transform (ELT)</span></span>

<span data-ttu-id="9139d-120">Kinyerési, betöltés és átalakítás (ELT) eltér az ETL kizárólag a ahol az átalakítás történik.</span><span class="sxs-lookup"><span data-stu-id="9139d-120">Extract, load, and transform (ELT) differs from ETL solely in where the transformation takes place.</span></span> <span data-ttu-id="9139d-121">Az átalakítás a ELT sorban, a cél adattár következik be.</span><span class="sxs-lookup"><span data-stu-id="9139d-121">In the ELT pipeline, the transformation occurs in the target data store.</span></span> <span data-ttu-id="9139d-122">Egy külön átalakító motor helyett a feldolgozási képességek a cél adattár segítségével adatok.</span><span class="sxs-lookup"><span data-stu-id="9139d-122">Instead of using a separate transformation engine, the processing capabilities of the target data store are used to transform data.</span></span> <span data-ttu-id="9139d-123">Ez leegyszerűsíti a architektúra az átalakító motor eltávolításával a láncból.</span><span class="sxs-lookup"><span data-stu-id="9139d-123">This simplifies the architecture by removing the transformation engine from the pipeline.</span></span> <span data-ttu-id="9139d-124">Ezt a módszert használja egy másik előnye az, hogy a cél adattár skálázás is méretezze át a ELT csővezeték teljesítmény.</span><span class="sxs-lookup"><span data-stu-id="9139d-124">Another benefit to this approach is that scaling the target data store also scales the ELT pipeline performance.</span></span> <span data-ttu-id="9139d-125">Azonban ELT csak akkor működik jól esetén elég erős hatékonyan átalakíthatja az adatokat a célrendszeren.</span><span class="sxs-lookup"><span data-stu-id="9139d-125">However, ELT only works well when the target system is powerful enough to transform the data efficiently.</span></span>

![Kivonat-betöltési-átalakítás (ELT) folyamat](../images/elt.png)

<span data-ttu-id="9139d-127">A big Data típusú adatok tartomány ELT a tipikus használati esetek tartoznak.</span><span class="sxs-lookup"><span data-stu-id="9139d-127">Typical use cases for ELT fall within the big data realm.</span></span> <span data-ttu-id="9139d-128">Például előfordulhat, hogy megkezdéséhez valamennyi egybesimított fájlokba, a Hadoop elosztott fájlrendszer (HDFS) például méretezhető tárolás a forrásadatok és az Azure Data Lake Store kinyeréséhez.</span><span class="sxs-lookup"><span data-stu-id="9139d-128">For example, you might start by extracting all of the source data to flat files in scalable storage such as Hadoop distributed file system (HDFS) or Azure Data Lake Store.</span></span> <span data-ttu-id="9139d-129">Technológiák, például a Spark, a Hive és a PolyBase használható az adatok lekérdezésére.</span><span class="sxs-lookup"><span data-stu-id="9139d-129">Technologies such as Spark, Hive, or PolyBase can then be used to query the source data.</span></span> <span data-ttu-id="9139d-130">A kulcs ELT pontra az, hogy az átalakítás végrehajtásához használt adattár a ugyanazt az adattárat, ahol végső soron használt adatok.</span><span class="sxs-lookup"><span data-stu-id="9139d-130">The key point with ELT is that the data store used to perform the transformation is the same data store where the data is ultimately consumed.</span></span> <span data-ttu-id="9139d-131">Az adattároló közvetlenül a méretezhető tárolás, az adatok betöltése a saját védett tároló helyett olvassa be.</span><span class="sxs-lookup"><span data-stu-id="9139d-131">This data store reads directly from the scalable storage, instead of loading the data into its own proprietary storage.</span></span> <span data-ttu-id="9139d-132">Ez a megközelítés kihagyja az adatok másolása lépés ETL, szerepel, amely lehet egy nagy méretű adatkészletekhez időigényes művelet.</span><span class="sxs-lookup"><span data-stu-id="9139d-132">This approach skips the data copy step present in ETL, which can be a time consuming operation for large data sets.</span></span>

<span data-ttu-id="9139d-133">A gyakorlatban a cél adattár van egy [adatraktár](./data-warehousing.md) a Hadoop-fürtök (a Hive vagy Spark használatával) vagy egy SQL Data Warehouse használatával.</span><span class="sxs-lookup"><span data-stu-id="9139d-133">In practice, the target data store is a [data warehouse](./data-warehousing.md) using either a Hadoop cluster (using Hive or Spark) or a SQL Data Warehouse.</span></span> <span data-ttu-id="9139d-134">Általában a séma, időben a strukturálatlan fájladatok az átfedett és a rendszer táblaként, engedélyezi az adatok kérdezhető le, mint a szerepel az adattárban.</span><span class="sxs-lookup"><span data-stu-id="9139d-134">In general, a schema is overlaid on the flat file data at query time and stored as a table, enabling the data to be queried like any other table in the data store.</span></span> <span data-ttu-id="9139d-135">Ezek hivatkozunk, külső táblákra mert az adatok nem kezeli az adatokat tároló tárolja saját magát, de az egyes külső méretezhető tárolókhoz.</span><span class="sxs-lookup"><span data-stu-id="9139d-135">These are referred to as external tables because the data does not reside in storage managed by the data store itself, but on some external scalable storage.</span></span> 

<span data-ttu-id="9139d-136">Az adattár csak a Adatséma kezeli, és alkalmazza a séma olvasási.</span><span class="sxs-lookup"><span data-stu-id="9139d-136">The data store only manages the schema of the data and applies the schema on read.</span></span> <span data-ttu-id="9139d-137">Például a Hive eszközzel Hadoop-fürtök le olyan Hive táblát, ahol az adatforrás az hatékonyan a fájlokat a HDFS elérési útját.</span><span class="sxs-lookup"><span data-stu-id="9139d-137">For example, a Hadoop cluster using Hive would describe a Hive table where the data source is effectively a path to a set of files in HDFS.</span></span> <span data-ttu-id="9139d-138">Az SQL Data Warehouse PolyBase érhető el ugyanazt az eredményt &mdash; külsőleg maga az adatbázis tárolt adatok alapján a táblázatok létrehozásáról.</span><span class="sxs-lookup"><span data-stu-id="9139d-138">In SQL Data Warehouse, PolyBase can achieve the same result &mdash; creating a table against data stored externally to the database itself.</span></span> <span data-ttu-id="9139d-139">Miután a forrásadatok be van töltve, levő adatok külső táblái feldolgozási az adattár képességek segítségével.</span><span class="sxs-lookup"><span data-stu-id="9139d-139">Once the source data is loaded, the data present in the external tables can be processed using the capabilities of the data store.</span></span> <span data-ttu-id="9139d-140">A big data forgatókönyvéhez Ez azt jelenti, hogy az adattár képesnek kell lennie a nagymértékben párhuzamos feldolgozási (MPP), amely az adatok bontja kisebb csoportjai, majd továbbítja az adattömbök feldolgozása párhuzamosan több számítógépen.</span><span class="sxs-lookup"><span data-stu-id="9139d-140">In big data scenarios, this means the data store must be capable of massively parallel processing (MPP), which breaks the data into smaller chunks and distributes processing of the chunks across multiple machines in parallel.</span></span>

<span data-ttu-id="9139d-141">A ELT folyamatának utolsó szakaszában általában az adatok átalakítására végleges formátumra, amely támogatja lekérdezések típusú hatékonyabb.</span><span class="sxs-lookup"><span data-stu-id="9139d-141">The final phase of the ELT pipeline is typically to transform the source data into a final format that is more efficient for the types of queries that need to be supported.</span></span> <span data-ttu-id="9139d-142">Például az adatok lehetnek particionálva.</span><span class="sxs-lookup"><span data-stu-id="9139d-142">For example, the data may be partitioned.</span></span> <span data-ttu-id="9139d-143">Emellett ELT Parquet, amely tárolja az adatokat soros oszlopos módon és optimalizált providess indexelő optimalizált tárolási formátumok előfordulhat, hogy használja.</span><span class="sxs-lookup"><span data-stu-id="9139d-143">Also, ELT might use optimized storage formats like Parquet, which stores row-oriented data in a columnar fashion and providess optimized indexing.</span></span> 

<span data-ttu-id="9139d-144">Kapcsolódó Azure-szolgáltatás:</span><span class="sxs-lookup"><span data-stu-id="9139d-144">Relevant Azure service:</span></span>

- [<span data-ttu-id="9139d-145">Azure SQL Data Warehouse</span><span class="sxs-lookup"><span data-stu-id="9139d-145">Azure SQL Data Warehouse</span></span>](/azure/sql-data-warehouse/sql-data-warehouse-overview-what-is)
- [<span data-ttu-id="9139d-146">A Hive HDInsight</span><span class="sxs-lookup"><span data-stu-id="9139d-146">HDInsight with Hive</span></span>](/azure/hdinsight/hadoop/hdinsight-use-hive)
- [<span data-ttu-id="9139d-147">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="9139d-147">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)
- [<span data-ttu-id="9139d-148">A HDInsight Oozie</span><span class="sxs-lookup"><span data-stu-id="9139d-148">Oozie on HDInsight</span></span>](/azure/hdinsight/hdinsight-use-oozie-linux-mac)

<span data-ttu-id="9139d-149">Más eszközök:</span><span class="sxs-lookup"><span data-stu-id="9139d-149">Other tools:</span></span>

- [<span data-ttu-id="9139d-150">Az SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="9139d-150">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="data-flow-and-control-flow"></a><span data-ttu-id="9139d-151">Az adatfolyamnak és folyamata</span><span class="sxs-lookup"><span data-stu-id="9139d-151">Data flow and control flow</span></span>

<span data-ttu-id="9139d-152">Adatok folyamatok keretében a folyamatábrán feladatokhoz rendezett feldolgozása biztosítja.</span><span class="sxs-lookup"><span data-stu-id="9139d-152">In the context of data pipelines, the control flow ensures orderly processing of a set of tasks.</span></span> <span data-ttu-id="9139d-153">Ezeket a feladatokat a megfelelő feldolgozási sorrendben kényszerítéséhez sorrend megkötések használata.</span><span class="sxs-lookup"><span data-stu-id="9139d-153">To enforce the correct processing order of these tasks, precedence constraints are used.</span></span> <span data-ttu-id="9139d-154">Az eltolásokat tekintheti összekötők a munkafolyamat-diagrammal, ezek a megkötések az alábbi ábrán látható módon.</span><span class="sxs-lookup"><span data-stu-id="9139d-154">You can think of these constraints as connectors in a workflow diagram, as shown in the image below.</span></span> <span data-ttu-id="9139d-155">Minden tevékenység rendelkezik az eredménye, például sikeres, sikertelen vagy létrehozása után.</span><span class="sxs-lookup"><span data-stu-id="9139d-155">Each task has an outcome, such as success, failure, or completion.</span></span> <span data-ttu-id="9139d-156">A következő feladatokat nem kezdeményez a folyamatot, amíg az elődjéhez művelete befejeződött, ezek az eredmények közül.</span><span class="sxs-lookup"><span data-stu-id="9139d-156">Any subsequent task does not initiate processing until its predecessor has completed with one of these outcomes.</span></span>

<span data-ttu-id="9139d-157">Vezérlő adatfolyamok adatfolyamok feladatként hajtható végre.</span><span class="sxs-lookup"><span data-stu-id="9139d-157">Control flows execute data flows as a task.</span></span> <span data-ttu-id="9139d-158">Az adatfolyam-feladathoz adatok kibontani a forrás, át legyenek-e, vagy töltse be a tárolóban.</span><span class="sxs-lookup"><span data-stu-id="9139d-158">In a data flow task, data is extracted from a source, transformed, or loaded into a data store.</span></span> <span data-ttu-id="9139d-159">Egy adatfolyam-feladat kimenete a következő adatfolyam-feladat bemeneti, és adatok flowss párhuzamosan futtatható.</span><span class="sxs-lookup"><span data-stu-id="9139d-159">The output of one data flow task can be the input to the next data flow task, and data flowss can run in parallel.</span></span> <span data-ttu-id="9139d-160">Eltérően vezérlő adatfolyamok nem adhat hozzá korlátozásokat az adatfolyam a tevékenységek között.</span><span class="sxs-lookup"><span data-stu-id="9139d-160">Unlike control flows, you cannot add constraints between tasks in a data flow.</span></span> <span data-ttu-id="9139d-161">Hozzáadhat azonban egy adatokat megjelenítő, és figyelje meg az adatokat, minden feladat feldolgozása.</span><span class="sxs-lookup"><span data-stu-id="9139d-161">You can, however, add a data viewer to observe the data as it is processed by each task.</span></span>

![Adatfolyam-az belül vezérlő egymást követő feladatok végrehajtása zajlik](../images/control-flow-data-flow.png)

<span data-ttu-id="9139d-163">A fenti ábrán vannak a folyamatábrán, melyek egyike adatfolyam-feladathoz belül több feladatot.</span><span class="sxs-lookup"><span data-stu-id="9139d-163">In the diagram above, there are several tasks within the control flow, one of which is a data flow task.</span></span> <span data-ttu-id="9139d-164">A feladatok közül van beágyazva egy tárolót.</span><span class="sxs-lookup"><span data-stu-id="9139d-164">One of the tasks is nested within a container.</span></span> <span data-ttu-id="9139d-165">Tárolók segítségével feladatok, így munkaegység alapot biztosítanak.</span><span class="sxs-lookup"><span data-stu-id="9139d-165">Containers can be used to provide structure to tasks, providing a unit of work.</span></span> <span data-ttu-id="9139d-166">Ilyen például az ismétlődő elemeket, például egy mappa vagy adatbázis utasításokban fájlokat egy gyűjteményen belül van.</span><span class="sxs-lookup"><span data-stu-id="9139d-166">One such example is for repeating elements within a collection, such as files in a folder or database statements.</span></span>

<span data-ttu-id="9139d-167">Kapcsolódó Azure-szolgáltatás:</span><span class="sxs-lookup"><span data-stu-id="9139d-167">Relevant Azure service:</span></span>
- [<span data-ttu-id="9139d-168">Azure Data Factory v2</span><span class="sxs-lookup"><span data-stu-id="9139d-168">Azure Data Factory v2</span></span>](https://azure.microsoft.com/services/data-factory/)

<span data-ttu-id="9139d-169">Más eszközök:</span><span class="sxs-lookup"><span data-stu-id="9139d-169">Other tools:</span></span>
- [<span data-ttu-id="9139d-170">Az SQL Server Integration Services (SSIS)</span><span class="sxs-lookup"><span data-stu-id="9139d-170">SQL Server Integration Services (SSIS)</span></span>](/sql/integration-services/sql-server-integration-services)

## <a name="technology-choices"></a><span data-ttu-id="9139d-171">Technológiai lehetőségek</span><span class="sxs-lookup"><span data-stu-id="9139d-171">Technology choices</span></span>

- [<span data-ttu-id="9139d-172">Online tranzakciófeldolgozási (OLTP) adattároló</span><span class="sxs-lookup"><span data-stu-id="9139d-172">Online Transaction Processing (OLTP) data stores</span></span>](./online-transaction-processing.md#oltp-in-azure)
- [<span data-ttu-id="9139d-173">Online analitikus feldolgozási (OLAP) adattároló</span><span class="sxs-lookup"><span data-stu-id="9139d-173">Online Analytical Processing (OLAP) data stores</span></span>](./online-analytical-processing.md#olap-in-azure)
- [<span data-ttu-id="9139d-174">Az adatraktárak</span><span class="sxs-lookup"><span data-stu-id="9139d-174">Data warehouses</span></span>](./data-warehousing.md)
- [<span data-ttu-id="9139d-175">Vezénylési folyamat</span><span class="sxs-lookup"><span data-stu-id="9139d-175">Pipeline orchestration</span></span>](../technology-choices/pipeline-orchestration-data-movement.md)
